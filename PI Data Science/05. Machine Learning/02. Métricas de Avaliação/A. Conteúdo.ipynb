{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métricas de Avaliação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Introdução      \n",
    "É possível ver que uma das variáveis de fato é mais importante que as outras, mas será que o modelo de fato melhora com a adição dessas variáveis? Como podemos mensurar que um modelo é melhor que outro?\n",
    "    \n",
    "Nessa seara, entra o que chamamos de métricas para avaliação de modelo de classificação. Existem diversas formas de realizar tais avaliações, cada uma observando o problema de um ponto de vista diferente.\n",
    "    \n",
    "2. Métricas de Classificação    \n",
    "2.1. Acurácia    \n",
    "Também conhecida como taxa de acerto, essa medida de desempenho traz a proporção de acertos sobre o total de observações. Assumindo que, dado um conjunto de variáveis explicativas x associados a um conjunto de variável resposta y um modelo M foi treinado, temos que a acurácia do modelo M (ac(M)) pode ser descrita matematicamente como:\n",
    "    \n",
    "$ac(M)=1n∑i=1nI(yi=M(xi))$     \n",
    "    \n",
    "A taxa de acerto é um número limitado entre 0 e 1. Quanto maior for o seu valor, melhor é o modelo M.\n",
    "    \n",
    "De forma similar, podemos obter a taxa de erro com:\n",
    "    \n",
    "$err(M)=1−ac(M)$    \n",
    "Nesse caso, quanto menor a taxa de erro, melhor o modelo M.\n",
    "    \n",
    "2.2. Matriz de Confusão    \n",
    "Uma alternativa para visualizar o desempenho de um modelo é analisar sua matriz de confusão, a qual ilustra o número de predições corretas e incorretas para cada classe do modelo. As linhas dessa matriz representam as classes verdadeiras, enquanto as colunas representam as classes preditas pelo modelo. Logo, casa elemento mij de uma matriz de confusão MMC apresenta o número de exemplos da classe i classificados como classe j. Dessa forma, os elementos na diagonal principal indicam as classificações feitas de forma correta, enquanto os outros elementos são os classificados de forma incorreta.\n",
    "      \n",
    "      \n",
    "<img src=\"https://s3-sa-east-1.amazonaws.com/lcpi/3960b0bd-1028-4710-8022-507110fc974a.png\" style=\"width: 300px;\">    \n",
    "    \n",
    "    \n",
    "Por meio dela, temos as medidas quantitativas de quais classes possuem maior dificuldade de serem corretamente classificadas, se existe alguma \"confusão\" recorrente entre duas classes e mais uma série de medidas quantitativas sobre o modelo (a ser visto mais adiante).\n",
    "    \n",
    "2.3. Medidas de Desempenho Derivadas da Matriz de Confusão    \n",
    "Dado a matriz de confusão mostranda no item anterior, podemos extrair, entre outras, as seguintes medidas de desempenho.\n",
    "    \n",
    "2.3.1. Precisão    \n",
    "É a proporção de exemplos positivos classificados corretamente entre todos aqueles preditos como positivos pelo modelo M.\n",
    "    \n",
    "$prec(M)=VPVP + FP$        \n",
    "Pode ser vista como uma medida de exatidão do modelo. Uma precisão de 1 para uma determinada classe C1 significa que cada item predito como pertencene a essa classe de fato pertence ela; porém, não nos trás informações sobre as predições das classes C2.\n",
    "    \n",
    "2.3.2. Sensibilidade    \n",
    "Taxa de acerto na classe positiva, também conhecida como revocação ou taxa de verdadeiros positivos (TVP).\n",
    "    \n",
    "$sens(M)=VPVP + FN$    \n",
    "$TVP(M)=sens(M)$    \n",
    "Pode ser vista como uma medida de completude do modelo. Uma sensibilidade de 1 para uma determinada classe C1 significa que todos os itens que deveriam ser previstos como tal, de fato foram; mas não nos trás informações sobre as outras predições erradas dentro da própria classes C1.\n",
    "    \n",
    "2.3.3. Especificidade    \n",
    "Taxa de acerto na classe negativa, sendo o complementar a taxa de falsos positivos (TFP).\n",
    "    \n",
    "$esp(M)=VNVN + FP$  \n",
    "       \n",
    "$TFP(M)=1−esp(M)$ \n",
    "        \n",
    "2.3.4. Generalização para problemas multiclasse\n",
    "Essas medidas podem facilmente ser expandidas para problemas de classificação não binários ao considerar cada classe como positiva em relação ao conjunto das demais classes, sendo obtido um valor de desempenho para cada classe.\n",
    "    \n",
    "2.4. F-Score    \n",
    "Uma forma de unificar a exatidão (precisão) e completude (sensibilidade) de um modelo é por meio do cálculo do F-Score, que é uma média harmônica ponderada da precisão e sensibilidade, dada por:\n",
    "    \n",
    "F$w(M)=w+1×sens(M)×prec(M)sens(M)+w×prec(M)$    \n",
    "No geral, é comum usar w=1, dando o mesmo grau de importância para a precisão e sensiblidade. Dessa forma, temos o F1-Score dado por:\n",
    "    \n",
    "$F1(M)=2×sens(M)×prec(M)sens(M)+prec(M)$   \n",
    "      \n",
    "2.5. Análise ROC e Coeficiente de Gini    \n",
    "Uma forma alternativa e comum de avaliar classificadores em problemas binários é por meio do uso das curvas ROC (Receiving Operating Characteristics). Seu gráfico é bidimensional, no qual o eixo X está a TFP e no Y a TVP. Na próxima figura, temos um exemplo desse tipo de análise. Se um modelo se encontra na diagonal, dizemos que ele possui comportamento similar ao lançamento de uma moeda não viciada. Modelos abaixo dessa linha são piores que o aleatório, enquanto que acima são modelos melhores que o aleatório. Se um modelo está na ponta superior esquerda, chamada de céu ROC, dizemos que é um modelo perfeito; se está na ponta superior direita ou inferior esqueda, o modelo sempre classificará novos itens como positivos ou negativos, respectivamente; se está na ponta inferior direita, chamada de inferno ROC, esse modelo estará sempre errando. Um fator importante de ser notado é que se um modelo de classificação binária está sempre errado, basta invertermos sua predição para que seu desempenho perfeito.\n",
    "\n",
    "     \n",
    "<img src=\"https://s3-sa-east-1.amazonaws.com/lcpi/f6554123-1ee9-4838-8105-e0e32ab4c412.png\" style=\"width: 300px;\">    \n",
    "        \n",
    "    \n",
    "Apesar dessa análise gerar uma boa visualização para comparação de diferentes modelos, o processO mais usual é gerar uma curva ROC. Tomemos o seguinte exempplo: apesar da variável resposta ser binária em uma Regressão Logística, sua resposta é dado em um valor contínuo entre 0 e 1, que depois é aplicado um limiar de corte para definir se aquele caso pertence a classe positiva ou negativa; logo, temos um valor de TVP e TFP para cada ponto limiar, gerando assim uma curva para cada modelo de classificação, no formato das curvas na próxima figura.\n",
    "\n",
    "     \n",
    "<img src=\"https://s3-sa-east-1.amazonaws.com/lcpi/f1b7f22d-1f3b-460c-b53f-7f605e5d1bc9.png\" style=\"width: 300px;\">    \n",
    "        \n",
    "    \n",
    "Quando não há interseções entre as curvas de dois modelos, signica que o modelo que possui sua curva mais próxima do céu ROC é o que oferece melhor desempenho. Ao existir cruzamentos, cada um terá um desempenho melhor que o outro de acordo com a região. Entrentao, o mais comum é trazer a área abaixo da curva ROC (AUC-ROC) para cada modelo e compará-los com essa medida única, que é compreendida enre 0 e 1. Valores próximos de 1 são considerados os melhores; valores próximos a 0,5 são considerados aleatórios.\n",
    "    \n",
    "A AUC-ROC trás duas grandes vantagens:\n",
    "        \n",
    "Análise única independente do limiar;\n",
    "Robustez contra o desbalanceamento.\n",
    "Uma outra medida bastante comum, especialmente em econometria, é o Gini. Originalmente foi criada para calcular a distribuição da renda de uma determinada população, mas pode ser aplicado também em análises de modelos preditivos por meio da fórmula:\n",
    "    \n",
    "$Gini=(2×AUC)−1$    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.8 32-bit",
   "metadata": {
    "interpreter": {
     "hash": "04635d289a519a1410467dd0afb0db42f9184808881ca68b2eb5a687a20a5a94"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
