{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 8 - Modelos de árvore\n",
    "\n",
    "Na aula de hoje, vamos explorar os seguintes tópicos em Python:\n",
    "\n",
    "- 1) Introdução\n",
    "- 2) Árvores de decisão\n",
    "- 4) Utilizando dados categóricos\n",
    "- 5) Métodos de Ensemble\n",
    "- 6) Árvores de regressão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "____\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Métodos de Ensemble\n",
    "\n",
    "\n",
    "Há uma classe de algoritmos de Machine Learning, os chamados **métodos de ensemble** que tem como objetivo **combinar as predições de diversos estimadores mais simples** para gerar uma **predição final mais robusta**\n",
    "\n",
    "Os métodos de ensemble são ainda divididos em duas classes:\n",
    "\n",
    "- **Métodos de média**: têm como procedimento geral construir diversos estimadores independentes, e tomar a média de suas predições como a predição final. O principal objetivo do método é reduzir variância, de modo que o modelo final seja melhor que todos os modelos individuais. Ex.: **random forest.**\n",
    "\n",
    "<br>\n",
    "\n",
    "- **Métodos de boosting**: têm como procedimento geral a construção de estimadores de forma sequencial, de modo que estimadores posteriores tentam reduzir o viés do estimador conjunto, que leva em consideração estimadores anteriores. Ex.: **adaboost**.\n",
    "\n",
    "Para mais detalhes, [clique aqui!](https://scikit-learn.org/stable/modules/ensemble.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________\n",
    "\n",
    "### Random Forest\n",
    "\n",
    "É possível melhorar ainda mais o resultado obtido acima?\n",
    "\n",
    "Uma técnica muito interessante baseada em árvores é o **Random Forest**.\n",
    "\n",
    "Neste modelo, são criadas varias árvores diferentes aleatoriamente, e a predição final é tomada através do voto majoritário de todas as árvores!\n",
    "\n",
    "<img src=\"https://i.ytimg.com/vi/goPiwckWE9M/maxresdefault.jpg\" width=700>\n",
    "\n",
    "O modelo de Random Forest utiliza os conceitos de **bootstraping** e **aggregation** (ou então, o procedimento composto **bagging**) para criar um modelo composto que é melhor que uma única árvore!\n",
    "\n",
    "<img src=\"https://c.mql5.com/2/33/image1__1.png\" width=600>\n",
    "\n",
    "Para maiores detalhes sobre como o modelo funciona, sugiro os vídeos do canal [StatQuest](https://www.youtube.com/watch?v=J4Wdy0Wc_xQ). \n",
    "\n",
    "Obs.: toda a [playlist de machine learning](https://www.youtube.com/playlist?list=PLblh5JKOoLUICTaGLRoHQDuF_7q2GfuJF) é muitíssimo interessante, com vídeos super claros e ilustrativos! Além disso, há outros vídeos de estatística que são muito bons! Este é um dos melhores canais no youtube para se aprender de forma clara e descontraída sobre estatística e machine learning!\n",
    "\n",
    "Aqui, vamos ver o Random Forest em ação!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_resamp.copy()\n",
    "\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "X = df.drop(columns=\"y_yes\")\n",
    "y = df[\"y_yes\"]\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "estimador = RandomForestClassifier()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "    \n",
    "modelo = estimador.fit(X_train, y_train)\n",
    "\n",
    "y_pred = modelo.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opcional: construa um pipeline com o randomsearch para achar o melhor random forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______\n",
    "\n",
    "### Adaboost\n",
    "\n",
    "O Adaboost significa **Adaptive Boosting**, e tem como procedimento geral **a criação sucessiva de árvores de um único nó (stumps - modelos fracos) que utiliza dos erros da árvore anterior para melhorar a próxima árvore**. As predições finais são feitas com base **nos pesos de cada stump**, cuja determinação faz parte do algoritmo.\n",
    "\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1744/1*nJ5VrsiS1yaOR77d4h8gyw.png\" width=300>\n",
    "\n",
    "De forma resumida, as principais ideias por trás deste algoritmo são:\n",
    "\n",
    "- O algoritmo cria e combina um conjunto de **modelos fracos** (em geral, stumps);\n",
    "- Cada stump é criado **levando em consideração os erros do stump anterior**;\n",
    "- Alguns dos stumps têm **maior peso de decisão** do que outros na predição final;\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"https://www.researchgate.net/profile/Zhuo_Wang8/publication/288699540/figure/fig9/AS:668373486686246@1536364065786/Illustration-of-AdaBoost-algorithm-for-creating-a-strong-classifier-based-on-multiple.png\" width=500>\n",
    "\n",
    "<img src=\"https://static.packt-cdn.com/products/9781788295758/graphics/image_04_046-1.png\" width=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_resamp.copy()\n",
    "\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "X = df.drop(columns=\"y_yes\")\n",
    "y = df[\"y_yes\"]\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "estimador = AdaBoostClassifier()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "    \n",
    "modelo = estimador.fit(X_train, y_train)\n",
    "\n",
    "y_pred = modelo.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opcional: construa um pipeline com o gridsearch para achar o melhor adaboost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______\n",
    "________\n",
    "_________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Árvores de regressão\n",
    "\n",
    "Alguns algoritmos de classificação podem ser utilizados como algoritmos de regressão, inclusive árvores de decisão!\n",
    "\n",
    "As **árvores de regressão** consistem em funções com valores discretos, similar a uma escada, onde cada degrau é o valor de uma folha. [Aqui](https://scikit-learn.org/stable/auto_examples/tree/plot_tree_regression.html) há detalhes sobre a classe do sklearn; e [aqui](https://www.youtube.com/watch?v=g9c66TUylZ4) está o StatQuest sobre árvores de regressão!\n",
    "\n",
    "Considere o seguinte dataset:\n",
    "\n",
    "<img src='https://s3-sa-east-1.amazonaws.com/lcpi/800a4332-e709-4ea3-8c24-959c05c8fd65.png' width=500>\n",
    "\n",
    "O algoritmo irá obter os valores do target como sendo **a média dos valores de cada folha da árvore final**. \n",
    "\n",
    "Visualmente: \n",
    "\n",
    "<img src='https://s3-sa-east-1.amazonaws.com/lcpi/64cb4edd-20e1-486a-8fc9-60e60e1485d5.png' width=500>\n",
    "\n",
    "Para a escolha das melhores divisões: \n",
    "\n",
    "- o algoritmo percorre a médida entre cada par de pontos das features; \n",
    "- define estes valores como divisões (sequencialmente); \n",
    "- para cada divisão experimentada, o algoritmo calcula o MSE;\n",
    "- a melhor divisão é aquela que apresentar o menor erro!\n",
    "\n",
    "Visualmente:\n",
    "\n",
    "<img src='https://s3-sa-east-1.amazonaws.com/lcpi/be58ac8b-5c59-4b9f-be79-e000d060e9e3.png' width=500>\n",
    "\n",
    "<img src='https://s3-sa-east-1.amazonaws.com/lcpi/1f317afd-6119-41a5-849d-cee038403cf2.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outro exemplo de árvore de regressão treinada:\n",
    "\n",
    "<img src=\"https://res.cloudinary.com/practicaldev/image/fetch/s--YryIJN_o--/c_imagga_scale,f_auto,fl_progressive,h_900,q_auto,w_1600/https://thepracticaldev.s3.amazonaws.com/i/7oxf0e3cggdj9jayxeig.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos fazer um modelo de árvore de regressão para precificação de casas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../datasets/house_prices.csv\")\n",
    "\n",
    "df = df.select_dtypes(include=[np.number])\n",
    "df = df.dropna(axis=\"columns\", how=\"any\")\n",
    "\n",
    "X = df.drop(columns=[\"Id\",\"SalePrice\"])\n",
    "y = df['SalePrice']\n",
    "\n",
    "# 1)\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# 2)\n",
    "estimador = DecisionTreeRegressor(max_depth=10)\n",
    "\n",
    "# 3)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 4)\n",
    "modelo = estimador.fit(X_train, y_train)\n",
    "\n",
    "# # print(\"Intercepto:\", modelo.intercept_)\n",
    "# print(\"Coeficienter angular:\", modelo.coef_)\n",
    "\n",
    "print(\"\\n####################################################\\n\")\n",
    "\n",
    "# 5)\n",
    "predictions = modelo.predict(X_test)\n",
    "\n",
    "plt.title(\"valor predito vs valor real\")\n",
    "sns.scatterplot(x=predictions, y=y_test)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n####################################################\\n\")\n",
    "\n",
    "print(\"\\nMétricas de avaliação:\")\n",
    "\n",
    "# 6)\n",
    "from sklearn import metrics\n",
    "\n",
    "print('R^2:', metrics.r2_score(y_test, predictions))\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "tree.plot_tree(modelo, feature_names=X_train.columns)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
