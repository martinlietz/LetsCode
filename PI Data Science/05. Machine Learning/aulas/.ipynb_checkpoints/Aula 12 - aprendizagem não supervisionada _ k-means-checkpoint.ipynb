{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 12 - Aprendizagem não-supervisionada & k-means\n",
    "\n",
    "Na aula de hoje, vamos explorar os seguintes tópicos em Python:\n",
    "\n",
    "- 1) Aprendizagem não-supervisionada\n",
    "- 2) K-means\n",
    "- 3) Exemplo real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T21:10:38.707882Z",
     "start_time": "2021-09-20T21:10:37.022170Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "____\n",
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Aprendizagem não-supervisionada\n",
    "\n",
    "Chegamos ao nosso último tópico do módulo: **aprendizagem não-supervisionada (unsurpervised learning)**.\n",
    "\n",
    "Este tipo de aprendizagem se diferencia da aprendizagem supervisionada de modo muito simples: **os targets não fazem parte da base de treino!**\n",
    "\n",
    "> Na aprendizagem não-supervisionada, temos acesso apenas ao conjunto de features, $\\{\\vec{x}_i\\}_{i=1}^N$\n",
    "\n",
    "A perda que temos com relação à aprendizagem supervisionada é gigante: sem os targets, torna-se impossível a estimação do processo teórico $\\mathcal{F}$ que gerou os dados!\n",
    "\n",
    "Assim, o máximo que podemos fazer na aprendizagem não-supervisionada é a **determinação de estrutura nos dados**:\n",
    "\n",
    "<img src=https://www.researchgate.net/profile/Zhenyu-Wen-2/publication/336642133/figure/fig3/AS:815304842170368@1571395230317/Examples-of-Supervised-Learning-Linear-Regression-and-Unsupervised-Learning.png width=500>\n",
    "\n",
    "Para muitas aplicações, isso já é suficiente: basta saber que os dados estão estruturados (agrupados/segmentados), sendo o significado de cada grupo/segmento de menor interesse, ou facilmente estimado de outra forma; ou, então, determinar aspectos importantes das features por si só, sem qualquer preocupação com o target.\n",
    "\n",
    "Neste curso, veremos dois grandes grupos de **técnicas não-supervisionadas**:\n",
    "\n",
    "- Clusterização - forma de encontrar grupos (clusters) nos dados;\n",
    "- Redução de dimensionalidade - importante processo de pré-processamento que visa reduzir o número de dimensões (features) de um dataset.\n",
    "\n",
    "Na aula de hoje, veremos técnicas de clusterização!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______\n",
    "\n",
    "### Clusterização\n",
    "\n",
    "Este tipo de problema consiste em __agrupar__ itens semelhantes, isto é, criar __grupos__ (ou __clusters__) dos dados que são parecidos entre si.\n",
    "\n",
    "> O objetivo central é **dividir os dados em grupos distintos**, tais que **membros de cada grupo sejam similares entre si**\n",
    "\n",
    "Problemas como estes podem aparecer em diversos contextos:\n",
    "\n",
    "- Identificação de tipos de clientes parecidos, para o direcionamento de marketing;\n",
    "- Agrupamento de cidades próximas para melhor logística de entrega de produtos;\n",
    "- Identificação de padrões climáticos;\n",
    "- Identificação de genes relacionados à determinada doença;\n",
    "- Identificação de documentos semelhantes em processos legais;\n",
    "\n",
    "...e qualquer outro problema em que você deseje **agrupar dados similares** ou ainda **encontrar alguma estrutura nos seus dados!**, mas tudo isso no que diz respeito ùnicamente **às features**!\n",
    "\n",
    "Veremos agora um dos principais algoritmos de clusterização, o **k-means**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) K-means\n",
    "\n",
    "Documentação: [clique aqui!](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans)\n",
    "\n",
    "O k-means é utilizado para a determinação de um número **$k$ de clusters em nossos dados** (na parte 2.3 explicamos melhor como este algoritmo funciona!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O primeiro passo pra aplicar o $k$-means é:\n",
    "\n",
    "- Determinar o número $k$ de clusters!\n",
    "\n",
    "Por exemplo, só de olhar pros dados plotados a seguir, fica fácil de identificar 4 grupos distintos, não é mesmo? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T21:48:59.647687Z",
     "start_time": "2021-09-20T21:48:59.419327Z"
    }
   },
   "outputs": [],
   "source": [
    "# geracao dos dados\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "X, _ = make_blobs(n_samples=300, centers=4, cluster_std=0.60, random_state=0)\n",
    "\n",
    "plt.scatter(X[:,0], X[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T21:12:52.796009Z",
     "start_time": "2021-09-20T21:12:52.779998Z"
    }
   },
   "outputs": [],
   "source": [
    "# dando uma olhada em X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Mas, como o computador pode identificar estes grupos? É isso que o algoritmo responde!\n",
    "\n",
    "Uma vez determinado o número k de clusters, podemos construir nosso modelo!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construindo o modelo\n",
    "\n",
    "Note que temos apenas as **features** dos dados (no caso, $x_1$ e $x_2$). Iso caracteriza um problema de clusterização **não-supervisionado**: quando nossos dados **não têm targets**, apenas features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T21:12:54.462877Z",
     "start_time": "2021-09-20T21:12:54.448888Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1) - importando a classe Kmeans do sklearn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos vários argumentos na classe, mas os principais são:\n",
    "\n",
    "- n_clusters: quantos clusters queremos (o número k);\n",
    "- max_iter: é o número máximos de iterações que o algoritmo fará, se ele não convergir antes disso. É uma boa ideia não colocar um número tão grande, ou o algoritmo pode ficar bem lento. Algo da ordem de 1000, em geral é uma boa escolha.\n",
    "\n",
    "Por fim, pra fitar o modelo, fazemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T21:13:07.359214Z",
     "start_time": "2021-09-20T21:13:07.353221Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2) instanciando o modelo\n",
    "# use k = 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em algoritmos **não supervisionados**, não existe a divisão em dados de treino e dados de teste, porque **não há o que testar!**. Queremos apenas **econtrar estrutura** nos dados!\n",
    "\n",
    "Então, basta fitar o modelo com nossos dados todos (no caso, o array X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T21:13:11.618557Z",
     "start_time": "2021-09-20T21:13:11.605567Z"
    }
   },
   "outputs": [],
   "source": [
    "# 3) e 4) treinando o modelo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que o modelo está treinado, podemos fazer predições:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T21:13:18.792268Z",
     "start_time": "2021-09-20T21:13:18.775275Z"
    }
   },
   "outputs": [],
   "source": [
    "# 5) fazendo previsões\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isto retorna uma lista com número de elementos igual ao número de pontos do dataset, e com valores entre 0 e k-1, indicando qual é o número do cluster (a contagem começa com zero). \n",
    "\n",
    "No nosso caso, como k = 4, teremos os clusters 0, 1, 2 e 3.\n",
    "\n",
    "Pra visualizarmos os clusters, basta plotar os dados iniciais com o hue adequado!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aqui eu crio um dataframe com as coordenadas dos pontos (\"x1\" e \"x2\"), e com as labels dos clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T21:14:31.169562Z",
     "start_time": "2021-09-20T21:14:31.160571Z"
    }
   },
   "outputs": [],
   "source": [
    "#aqui eu faço o scatterplot/jointplot com o hue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determinando o $k$\n",
    "\n",
    "Mas e se não for tão fácil de plotar os dados para determinar o $k$?\n",
    "\n",
    "Pode ser que não consigamos visualizar nossos dados em 2D, se, por exemplo, tivermos mais de 2 features em nossos dados...\n",
    "\n",
    "> Quase sempre, uma boa metodologia para a determinaçãodo número de clusters é **conhecimento do negócio**! Muitas vezes, o próprio problema nos indica a quantidade de clusters que esperamos encontrar!\n",
    "\n",
    "No entanto, há situações em que o número de clusters não é conhecido a priori.\n",
    "\n",
    "Neste caso, podemos usar o __método do cotovelo__, que consiste em rodar o k-means várias vezes, para diferentes valores de k, e depois plotar um gráfico com a **inércia** de cada uma das rodadas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inércia (WCSS) e método do cotovelo\n",
    "\n",
    "A inércia também é chamada de **WCSS** (Within-Cluster-Sum-of-Squares), isto é, \"soma de quadrados intra-cluster\", que é calculada como a soma das distâncias (ao quadrado) entre os pontos e os centróides dos clusters.\n",
    "\n",
    "Quanto menor o WCSS, mais eficiente foi a clusterização, **mas até certo ponto!**\n",
    "\n",
    "Conforme o número de clusters ($k$) aumenta, o WCSS diminui, sendo mínimo quando cada ponto é seu próprio cluster isolado (o que não é nada útil, pois se cada ponto for um cluster, não há clusterização alguma!).\n",
    "\n",
    "Assim, o que queremos não é encontrar um $k$ que minimize o WCSS, mas sim um k a partir do qual o WCSS **para de decrescer tão rapidamente!**\n",
    "\n",
    "Quando encontramos este $k$, encontramos o número ideal de clusters!\n",
    "\n",
    "Ao plotarmos o WCSS (inércia) em função de $k$, o que buscaremos será então o valor de $k$ onde **o gráfico deixa de ser tão inclinado**. Esses pontos são visualizados como \"quinas\", ou **cotovelos** no gráfico -- e daí vem o nome do método!\n",
    "\n",
    "Para aplicar o método, fazemos:\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicializamos uma lista vazia para armazenar a inercia de cada modelo com um k diferente\n",
    "# a inercia é a soma dos quadrados das distâncias dos pontos ao cluster mais próximo, e funciona como uma espécie de erro.\n",
    "\n",
    "# criamos um iterável para os valores de k que vamos testar. Neste caso, testaremos de 1 a 10!\n",
    "\n",
    "# aqui vamos fitar o modelo e atualizar nossa lista de inercias, apendando a inercia à lista\n",
    "# a inercia é obtida com o atributo .inertia_ do modelo treinado!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui plotamos a inercia em função do k!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O valor de $k$ mais adequado é aquele em que o gráfico tem uma \"quina\" bem abrupta: no exemplo acima, $k = 4$, como já sabíamos!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______\n",
    "\n",
    "### Método da silhueta\n",
    "\n",
    "Um método alternativo ao método do cotovelo para o cálculo do número adequado de clusters é o método da silhueta.\n",
    "\n",
    "Neste método, é calculado para cada ponto um score conhecido como **coeficiente de silhueta**, que é dado por:\n",
    "\n",
    "$s = \\frac{b - a}{max(a, b)} \\ , $\n",
    "\n",
    "onde:\n",
    "\n",
    "- $a$ é a **distância média entre um dado ponto e os pontos de seu próprio cluster**. Portanto, essa é uma medida de **similaridade entre um ponto e seu cluster**;\n",
    "- $b$ é a **distância média entre um dado ponto e os pontos do cluster mais próximo (em ser o próprio).** Portanto, essa é uma medida de **dissimilaridade entre um ponto e os demais clusters**;\n",
    "\n",
    "Graficamente:\n",
    "\n",
    "<img src=https://miro.medium.com/max/712/1*cUcY9jSBHFMqCmX-fp8BvQ.jpeg width=400>\n",
    "\n",
    "Note que $-1 < s < 1$, sendo mais próximo de $1$ quando um ponto está no cluster correto ($a \\ll b$); e mais próximo de $-1$ quando um ponto está no custer errado ($b \\gg a$).\n",
    "\n",
    "Na prática, é costumeiro olhar para **a média do coeficiente $s$ para todos os pontos, denotado $\\bar{s}$**, e apresentar uma única métrica. A ideia é que se, em média, tivermos pontos em clusters corretos, teremos $\\bar{s} \\rightarrow 1$; enquanto, se em média tivermos muitos pontos em clusters incorretos, teremos $\\bar{s} \\rightarrow -1$.\n",
    "\n",
    "Este score é calculado com a função [silhouette_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html) do sklearn.\n",
    "\n",
    "Uma vez que é possível calcularmos o score para um dado $k$, a decisão sobre o melhor $k$ segue similar ao método do cotovelo: basta calcular o score de silhueta para vários valores de $k$, e selecionar aquele que dá **a silueta mais próxima de $1$**!\n",
    "\n",
    "Isto é facilmente feito:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T21:50:36.589062Z",
     "start_time": "2021-09-20T21:50:35.879990Z"
    }
   },
   "outputs": [],
   "source": [
    "# importando a função da silueta\n",
    "\n",
    "# lista vazia pra guardar os scores\n",
    "\n",
    "# intervalo de k's a serem testados (pelo menos 2 clusters!)\n",
    "\n",
    "# iterando e guardando as silhuetas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui novamente, fica claro que o ideal é $k=4$!\n",
    "\n",
    "Para entender o porquê do método receber o nome \"silueta\", podemos utilizar o seguinte código do sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T21:58:16.643192Z",
     "start_time": "2021-09-20T21:58:14.554974Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "\n",
    "range_n_clusters = [2, 3, 4, 5, 6]\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    \n",
    "    # Create a subplot with 1 row and 2 columns\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(18, 7)\n",
    "\n",
    "    # The 1st subplot is the silhouette plot\n",
    "    # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "    # lie within [-0.1, 1]\n",
    "    ax1.set_xlim([-0.1, 1])\n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "    # plots of individual clusters, to demarcate them clearly.\n",
    "    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "\n",
    "    # Initialize the clusterer with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility.\n",
    "    clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "    cluster_labels = clusterer.fit_predict(X)\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    \n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    \n",
    "    for i in range(n_clusters):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "    # 2nd Plot showing the actual clusters formed\n",
    "    colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
    "    ax2.scatter(X[:, 0], X[:, 1], marker='.', s=30, lw=0, alpha=0.7,\n",
    "                c=colors, edgecolor='k')\n",
    "\n",
    "    # Labeling the clusters\n",
    "    centers = clusterer.cluster_centers_\n",
    "    # Draw white circles at cluster centers\n",
    "    ax2.scatter(centers[:, 0], centers[:, 1], marker='o',\n",
    "                c=\"white\", alpha=1, s=200, edgecolor='k')\n",
    "\n",
    "    for i, c in enumerate(centers):\n",
    "        ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1,\n",
    "                    s=50, edgecolor='k')\n",
    "\n",
    "    ax2.set_title(\"The visualization of the clustered data.\")\n",
    "    ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
    "    ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
    "\n",
    "    title = \"Silhouette analysis for KMeans clustering on sample data \"\n",
    "    title += \"with n_clusters = {}\\nSilhouette score = {:.2f}\".format(n_clusters, silhouette_avg)\n",
    "    plt.suptitle(title, fontsize=14, fontweight='bold')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na prática, é recomendável usar ambos os métodos, do cotovelo e da silhueta, pra apoiar a tomada de decisão quanto ao valor adequado de $k$.\n",
    "\n",
    "No entanto, lembre-se: sempre que possível, guie esta decisão segundo o contexto do problema de negócio!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos fazer o exemplo com mais features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "X, y = make_blobs(n_samples=500, n_features=4, centers=6, cluster_std=1.3, random_state=0)\n",
    "\n",
    "df = pd.DataFrame(X, columns=[\"x1\", \"x2\", \"x3\", \"x4\"])\n",
    "\n",
    "sns.pairplot(data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aplicando o método do cotovelo...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T21:19:21.166335Z",
     "start_time": "2021-09-20T21:19:21.155340Z"
    }
   },
   "outputs": [],
   "source": [
    "# método do cotovelo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aplicando o método da silhueta...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T22:00:56.117245Z",
     "start_time": "2021-09-20T22:00:56.114250Z"
    }
   },
   "outputs": [],
   "source": [
    "# método da silhueta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vamos tentar separadamente $k=3$ e $k=6$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T21:20:08.762658Z",
     "start_time": "2021-09-20T21:20:08.744670Z"
    }
   },
   "outputs": [],
   "source": [
    "# treine o modelo, junte as labels em um dataframe e use o pairplot com o hue\n",
    "# k=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treine o modelo, junte as labels em um dataframe e use o pairplot com o hue\n",
    "# k=6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As projeções em duas dimensões mostram que $k=6$ de fato é a melhor escolha! (O que faz sentido, pois nossos dados artificiais foram preparados para conter 6 clusters!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E como o k-means funciona?\n",
    "\n",
    "Uma vez escolhido o número de clusters, o k-means segue as seguintes etapas:\n",
    "\n",
    "- 1) k pontos são escolhidos aleatoriamente como sendo os centroides dos clusters (centroide é o centro do cluster);\n",
    "\n",
    "- 2) Para cada ponto, vamos calcular qual é a distância entre ele e os k centroides. Aquele centroide que estiver mais perto, será o cluster ao qual este ponto pertencerá. Fazemos isso para todos os pontos!\n",
    "\n",
    "- 3) Ao fim do passo 2, teremos k clusters, cada um com seu centroide, e todos os pontos pertencerão a determinado cluster!\n",
    "\n",
    "- 4) Uma vez que temos os clusters, calculamos qual é de fato o centro de cada um deles. Isso é feito tomando a média da posição de todos os pontos;\n",
    "\n",
    "- 5) Após determinar os novos k centroides, repetimos o processo!\n",
    "\n",
    "- 6) E o processo se repete até que os centroides não mudem mais. Quando esta convergência for alcançada (ou após o número determinado de iterações), o algoritmo termina!\n",
    "\n",
    "<img src=\"https://stanford.edu/~cpiech/cs221/img/kmeansViz.png\" width=700>\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1280/1*rwYaxuY-jeiVXH0fyqC_oA.gif\" width=500>\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/670/1*JUm9BrH21dEiGpHg76AImw.gif\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Quando uso algoritmos de clusterização, e em que casos eles não são uma boa ideia?**\n",
    "\n",
    "\n",
    "De certa fora, algoritmos de clusterização podem ser vistos como classificadores, uma vez que os clusters podem caracterizar um grupo, ou uma classe.\n",
    "\n",
    "No entanto, há uma diferença bem importante entre problemas de classificação e clusterização:\n",
    "\n",
    "- **Problemas de classificação** são **supervisionados**, isto é, as amostras de treino que utilizamos têm tanto as features como os **targets**. Em outras palavras, neste tipo de problema, sabemos de antemão quais são as classes de interesse - Isto é, temos $\\{\\vec{x}_i, y_i \\}_{i=1}^N$; <br><br>\n",
    "\n",
    "- **Problemas de clusterização**, por outro lado, são **não-supervisionados**. Ou seja, a amostra **não contêm** targets, temos apenas as features! O nosso objetivo é justamente descobrir **alguma estrutura de agrupamento** nos dados, mas sem qualquer informação prévia quanto aos grupos a serem formados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi exatamente o caso do nosso exemplo: nós tínhamos apenas as **features** dos dados, e **nenhuma** informação quanto aos grupos que seriam formados.\n",
    "\n",
    "Foi só depois que fizemos a análise exploratória dos dados (plot), que pudemos identificar alguma estrutura (4 clusters), para então aplicar o k-means!\n",
    "\n",
    "No segundo caso, só pudemos determinar o número de clusters de forma segura utilizando o **método do cotovelo**.\n",
    "\n",
    "Assim sendo, via de regra, a utilização ou não de algoritmos de clusterização, além do tipo de problema, depende dos **dados disponíveis**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Além do k-means, há outros algoritmos de clusterização que são muito utilizados, e que se baseiam em princípios bem diferentes do k-means.\n",
    "\n",
    "Na aula que vem, olharemos para um algoritmo bem importante: [DBSCAN](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html#sklearn.cluster.DBSCAN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "____\n",
    "____"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
