{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Aula 9 - métodos de ensemble\n",
    "\n",
    "Na aula de hoje, vamos explorar os seguintes tópicos em Python:\n",
    "\n",
    "- 1) Métodos de ensemble\n",
    "- 2) Bagging & Random Forest\n",
    "- 3) Boosting & AdaBoost\n",
    "- 4) Gradient Boosting\n",
    "- 5) XGBoost"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "_________________"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "\r\n",
    "# desabilita os warnings\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings('ignore')\r\n",
    "\r\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-17T22:02:46.910203Z",
     "start_time": "2021-09-17T22:02:22.356366Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "____\n",
    "____\n",
    "____"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1) Métodos de Ensemble\n",
    "\n",
    "\n",
    "Há uma classe de algoritmos de Machine Learning, os chamados **métodos de ensemble** que tem como objetivo **combinar as predições de diversos estimadores mais simples** para gerar uma **predição final mais robusta**\n",
    "\n",
    "Os métodos de ensemble costuman ser divididos em duas classes:\n",
    "\n",
    "- **Métodos de média**: têm como procedimento geral construir diversos estimadores independentes, e tomar a média de suas predições como a predição final. O principal objetivo do método é reduzir **variância**, de modo que o modelo final seja melhor que todos os modelos individuais. Ex.: **random forest.**\n",
    "<br>\n",
    "\n",
    "- **Métodos de boosting**: têm como procedimento geral a construção de estimadores de forma sequencial, de modo que estimadores posteriores tentam reduzir o **viés** do estimador conjunto, que leva em consideração estimadores anteriores. Ex.: **adaboost**.\n",
    "\n",
    "Há, ainda, uma terceira classe de método de ensemble, o chamado [stacking ensemble](https://machinelearningmastery.com/stacking-ensemble-machine-learning-with-python/), que consiste em \"empilhar\" modelos de modo a produzir a mistura. Não veremos esta modalidade em detalhes, mas deixo como sugestão para estudos posteriores! :)\n",
    "\n",
    "Para mais detalhes sobre métodos de ensemble no contexto do sklearn, [clique aqui!](https://scikit-learn.org/stable/modules/ensemble.html)\n",
    "\n",
    "Na aula de hoje, vamos conhecer em detalhes os procedimentos de bagging e boosting, ilustrados pelos métodos Random Forest e AdaBoost, respectivamente. Vamos lá!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "_________\n",
    "_______\n",
    "_________"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2) Bagging & Random Forest\n",
    "\n",
    "Uma técnica muito interessante (e muito performática!) baseada em árvores é o **Random Forest**.\n",
    "\n",
    "Neste método, são criadas varias **árvores diferentes e independentes entre si**, através de um processo **aleatório**, e a predição final é tomada através da média das predições individuais!\n",
    "\n",
    "<img src=\"https://i.ytimg.com/vi/goPiwckWE9M/maxresdefault.jpg\" width=700>\n",
    "\n",
    "O Random Forest utiliza os conceitos de **bootstrapping** e **aggregation** (ou então, o procedimento composto **bagging**) para criar um modelo composto que é melhor que uma única árvore!\n",
    "\n",
    "<img src=\"https://c.mql5.com/2/33/image1__1.png\" width=600>\n",
    "\n",
    "Vamos entrender um pouco melhor cada componente do método!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Bootstrapping\n",
    "\n",
    "O procedimento de **bootstrapping** é utilizado no contexto do random forest para gerar os chamados **bootstrapped datasets**.\n",
    "\n",
    "A ideia é bem simples! Para a criação de cada bootstrapped dataset, primeiro:\n",
    "\n",
    "> Selecionamos **aleatoriamente com reposição** algumas linhas da base original. Isso gera um novo dataset (reamostrado), chamado de **bootstrapped dataset**. O número de linhas do dataset reamostrado é controlável.\n",
    "\n",
    "Logo após, fazemos uma árvore de decisão **treinada neste dataset reamostrado**. Mas, com um detalhe:\n",
    "\n",
    "> Usamos apenas um **subconjunto aleatório das features** em cada avaliação de quebras (isso equivale ao `splitter=\"random\"`). A quantidade de features a serem consideradas é controlável.\n",
    "\n",
    "Com isso, muitas árvores são geradas (a quantidade também é controlável), cada uma seguindo o procedimento de bootstrap!\n",
    "\n",
    "Note que o o procedimento de bootstrapping introduz **duas fontes de aleatoriedade**, cujo objetivo é **diminuir a variância** (tendência a overfitting) do modelo.\n",
    "\n",
    "De fato, árvores individuais são facilmente overfitadas, como discutimos em aula (lembre-se da grande flexibilidade da hipótese em encontrar condições favoráveis à aprendizagem dos ruídos!).\n",
    "\n",
    "Com esta aleatorização introduzida pelo bootstrapping, o objetivo é que as árvores construídas sejam **independentes**, de modo que **os erros cometidos por cada uma sejam independentes**. \n",
    "\n",
    "Deste modo, se considerarmos as previsões isoladas e de alguma forma **agregar** as previsões, a expectativa é que o modelo final seja **menos propenso a overfitting**! Mas, uma pergunta natural é: o que é essa \"agragação\"? Aqui entra o segundo elemento do bagging..."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Aggregation\n",
    "\n",
    "Entendemos como o bootstrap é utilizado para gerar várias árvores independentes. \n",
    "\n",
    "Então, quando temos uma nova observação para atribuir o target, passamos as features **por cada uma das árvores**, e, naturalmente, cada árvore produz **o seu target**, que pode muito bem não ser o mesmo!\n",
    "\n",
    "A **agregação** é utilizada para tomar a decisão final:\n",
    "\n",
    "> No caso de classificação, a classe final é atribuída como **a classe majoritária**, isso é, **a classe que foi o output $\\hat{y}$ mais vezes dentre todas as árvores**;\n",
    "\n",
    "> No caso de regressão, o valor final é atribuído como **a média dos valores preditos $\\hat{y}$ por cada árvore**.\n",
    "\n",
    "Note que em ambos os casos, o procedimento de agregação pode ser visto como uma **média**, e o sklearn deixa isso explícito: \"*In contrast to the original publication, the scikit-learn implementation combines classifiers by averaging their probabilistic prediction, instead of letting each classifier vote for a single class.*\"\n",
    "\n",
    "Tomando a média como procedimento de agregação, a expectativa é que **alguns erros sejam anulados**, garantindo uma previsão final **mais estável e mais generalizável**, dado que os ruídos são eliminados.\n",
    "\n",
    "Juntando o bootstrapping com o aggregation, temos então o..."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Bagging\n",
    "\n",
    "> Bagging: **b**ootstrap **agg**regat**ing**\n",
    "\n",
    "Esquematicamente:\n",
    "\n",
    "<img src=https://media.geeksforgeeks.org/wp-content/uploads/20210707140912/Bagging.png width=500>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As classes do random forest são:\n",
    "\n",
    "- [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier)\n",
    "\n",
    "- [RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor)\n",
    "\n",
    "Ambos os métodos têm hiperparâmetros similares aos hiperparâmetros das árvores convencionais, aplicados a cada uma das árvores independentes.\n",
    "\n",
    "Além destes, há dois hiperparâmetros bem importantes, referentes ao método de ensemble em si:\n",
    "\n",
    "- `n_estimators` : controla quantas árvores independentes serão construídas (i.e., o número de árvores na floresta). Em geral, quanto mais árvores melhor (mas mais tempo vai demorar). Além disso, depois de uma determinade quantidade de árvores, os resultados vão parar de melhorar, pois há um limite para o bootstrap: depois de uma certa quantidade, as árvores deixam de ser tão independentes assim...\n",
    "<br>\n",
    "\n",
    "- `max_features`: o número de features no subconjunto aleatório de candidata a serem utilizadas em cada quebra. Quanto menor for o valor, mais conseguimos reduzir o overfitting, mas o underfitting é favorecido. Uma boa heurística é `max_features=None` para regressão e `max_features=\"sqrt\"`para classificação, embora estratégias diferentes podem (e devem) ser testadas com o CV.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "\n",
    "Para uma explicação bem visual sobre o funcionamento deste método, sugiro os vídeos do canal [StatQuest](https://www.youtube.com/watch?v=J4Wdy0Wc_xQ). \n",
    "\n",
    "Obs.: toda a [playlist de machine learning](https://www.youtube.com/playlist?list=PLblh5JKOoLUICTaGLRoHQDuF_7q2GfuJF) é muitíssimo interessante, com vídeos super claros e ilustrativos! Além disso, há outros vídeos de estatística que são muito bons! Este é um dos melhores canais no youtube para se aprender de forma clara e descontraída sobre estatística e machine learning!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Agora, vamos ver o Random Forest em ação!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Modelo baseline de Random Forest (dropando NaNs e features categóricas):"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# random forest baseline (adapte da aula 8)\r\n",
    "\r\n",
    "df = pd.read_csv('../datasets/german_credit_data.csv', index_col=0)\r\n",
    "\r\n",
    "# dropando NaNs e features categóricas\r\n",
    "df_aux = df.dropna().select_dtypes(include=np.number)\r\n",
    "df = pd.concat([df_aux, df.dropna()[\"Risk\"]], axis=1)          \r\n",
    "\r\n",
    "X = df.drop(columns=\"Risk\")\r\n",
    "y = df[\"Risk\"]\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \r\n",
    "                                                    y, \r\n",
    "                                                    test_size=0.2, \r\n",
    "                                                    random_state=42,\r\n",
    "                                                    stratify=y)\r\n",
    "\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "\r\n",
    "estimador = RandomForestClassifier(random_state=42)\r\n",
    "\r\n",
    "# to-do: implemente o cross_validate\r\n",
    "modelo = estimador.fit(X_train, y_train)\r\n",
    "\r\n",
    "y_pred = modelo.predict(X_test)\r\n",
    "\r\n",
    "from sklearn.metrics import confusion_matrix, classification_report, plot_confusion_matrix\r\n",
    "\r\n",
    "print(confusion_matrix(y_test, y_pred))\r\n",
    "\r\n",
    "plot_confusion_matrix(modelo, X_test, y_test)\r\n",
    "plt.show()\r\n",
    "\r\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[29 17]\n",
      " [15 44]]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.66      0.63      0.64        46\n",
      "        good       0.72      0.75      0.73        59\n",
      "\n",
      "    accuracy                           0.70       105\n",
      "   macro avg       0.69      0.69      0.69       105\n",
      "weighted avg       0.69      0.70      0.69       105\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-17T22:02:59.995685Z",
     "start_time": "2021-09-17T22:02:46.915203Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Será que dá pra melhorar?? Podemos construir uma pipeline e fazer o grid/random search para buscar o melhor modelo!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# construa um pipeline com o grid/randomsearch para achar o melhor random forest\r\n",
    "# (adapte da aula 8 a pipeline)\r\n",
    "\r\n",
    "# gridsearch com a PIPELINE MAIS GENERICA - processamento diferente em colunas diferentes!\r\n",
    "\r\n",
    "df = pd.read_csv('../datasets/german_credit_data.csv', index_col=0)          \r\n",
    "\r\n",
    "X = df.drop(columns=\"Risk\")\r\n",
    "y = df[\"Risk\"]\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \r\n",
    "                                                    y, \r\n",
    "                                                    test_size=0.2, \r\n",
    "                                                    random_state=42,\r\n",
    "                                                    stratify=y)\r\n",
    "\r\n",
    "\r\n",
    "######################## PIPELINE\r\n",
    "\r\n",
    "from sklearn.pipeline import Pipeline\r\n",
    "from sklearn.compose import ColumnTransformer\r\n",
    "\r\n",
    "# ==========================================\r\n",
    "# transformer das features numericas (pipeline de processamento)\r\n",
    "\r\n",
    "from sklearn.impute import SimpleImputer\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "\r\n",
    "transf_feat_nums = Pipeline([(\"simple_imput_num\", SimpleImputer(strategy=\"mean\")), \r\n",
    "                             (\"std_scaler\", StandardScaler())])\r\n",
    "\r\n",
    "features_nums = X.select_dtypes(include=np.number).columns.tolist()\r\n",
    "\r\n",
    "# ==========================================\r\n",
    "# transformer das features categoricas (pipeline de processamento)\r\n",
    "\r\n",
    "from sklearn.preprocessing import OneHotEncoder\r\n",
    "\r\n",
    "transf_feat_cats = Pipeline([(\"simple_imput_cat\", SimpleImputer(strategy=\"most_frequent\")),\r\n",
    "                             (\"onehot\", OneHotEncoder())])\r\n",
    "\r\n",
    "features_cats = X.select_dtypes(exclude=np.number).columns.tolist()\r\n",
    "\r\n",
    "# ==========================================\r\n",
    "\r\n",
    "pre_processador = ColumnTransformer([(\"transf_num\", transf_feat_nums, features_nums), \r\n",
    "                                     (\"transf_cat\", transf_feat_cats, features_cats)])\r\n",
    "\r\n",
    "\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "\r\n",
    "# pipeline final, com pre-processamento, e depois a modelagem\r\n",
    "pipe = Pipeline([('pre_process', pre_processador),\r\n",
    "                 ('rf', RandomForestClassifier(random_state=42))])\r\n",
    "\r\n",
    "######################## GRID SEARCH\r\n",
    "\r\n",
    "from sklearn.model_selection import GridSearchCV\r\n",
    "\r\n",
    "param_grid_rf = {\"rf__criterion\" : [\"gini\", \"entropy\"],\r\n",
    "                 \"rf__max_depth\" : [2, 3, 4, 5],\r\n",
    "                 \"rf__max_features\" : [\"sqrt\", \"log2\"],\r\n",
    "                 \"rf__n_estimators\" : [100, 150]}\r\n",
    "\r\n",
    "# PRA OTIMIZAR UMA METRICA QUE TEM DUAS OPÇOES\r\n",
    "from sklearn.metrics import recall_score, make_scorer\r\n",
    "\r\n",
    "metrica = make_scorer(recall_score, pos_label=\"good\")\r\n",
    "\r\n",
    "grid_rf = GridSearchCV(pipe, param_grid_rf, scoring=metrica, cv=5, verbose=1.5)\r\n",
    "\r\n",
    "grid_rf.fit(X_train, y_train)\r\n",
    "\r\n",
    "y_pred = grid_rf.predict(X_test)\r\n",
    "\r\n",
    "from sklearn.metrics import classification_report, confusion_matrix\r\n",
    "\r\n",
    "print(\"Matriz de confusão do modelo nos dados de teste:\\n\")\r\n",
    "print(confusion_matrix(y_test, y_pred))\r\n",
    "\r\n",
    "plot_confusion_matrix(grid_rf, X_test, y_test)\r\n",
    "plt.show()\r\n",
    "\r\n",
    "print(\"\\nMatriz de confusão do modelo nos dados de teste:\\n\")\r\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "[CV] END rf__criterion=gini, rf__max_depth=2, rf__max_features=sqrt, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=2, rf__max_features=sqrt, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=2, rf__max_features=sqrt, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=2, rf__max_features=sqrt, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=2, rf__max_features=sqrt, rf__n_estimators=100; total time=   0.0s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=2, rf__max_features=sqrt, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=2, rf__max_features=sqrt, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=2, rf__max_features=sqrt, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=2, rf__max_features=sqrt, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=2, rf__max_features=sqrt, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=2, rf__max_features=log2, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=2, rf__max_features=log2, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=2, rf__max_features=log2, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=2, rf__max_features=log2, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=2, rf__max_features=log2, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=2, rf__max_features=log2, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=2, rf__max_features=log2, rf__n_estimators=150; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=2, rf__max_features=log2, rf__n_estimators=150; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=2, rf__max_features=log2, rf__n_estimators=150; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=2, rf__max_features=log2, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=3, rf__max_features=sqrt, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=3, rf__max_features=sqrt, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=3, rf__max_features=sqrt, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=3, rf__max_features=sqrt, rf__n_estimators=100; total time=   0.2s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=3, rf__max_features=sqrt, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=3, rf__max_features=sqrt, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=3, rf__max_features=sqrt, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=3, rf__max_features=sqrt, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=3, rf__max_features=sqrt, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=3, rf__max_features=sqrt, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=3, rf__max_features=log2, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=3, rf__max_features=log2, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=3, rf__max_features=log2, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=3, rf__max_features=log2, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=3, rf__max_features=log2, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=3, rf__max_features=log2, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=3, rf__max_features=log2, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=3, rf__max_features=log2, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=3, rf__max_features=log2, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=3, rf__max_features=log2, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=4, rf__max_features=sqrt, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=4, rf__max_features=sqrt, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=4, rf__max_features=sqrt, rf__n_estimators=100; total time=   0.2s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=4, rf__max_features=sqrt, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=4, rf__max_features=sqrt, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=4, rf__max_features=sqrt, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=4, rf__max_features=sqrt, rf__n_estimators=150; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=4, rf__max_features=sqrt, rf__n_estimators=150; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=4, rf__max_features=sqrt, rf__n_estimators=150; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=4, rf__max_features=sqrt, rf__n_estimators=150; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=4, rf__max_features=log2, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=4, rf__max_features=log2, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=4, rf__max_features=log2, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=4, rf__max_features=log2, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=4, rf__max_features=log2, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=4, rf__max_features=log2, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=4, rf__max_features=log2, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=4, rf__max_features=log2, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=4, rf__max_features=log2, rf__n_estimators=150; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=4, rf__max_features=log2, rf__n_estimators=150; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=5, rf__max_features=sqrt, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=5, rf__max_features=sqrt, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=5, rf__max_features=sqrt, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=5, rf__max_features=sqrt, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=5, rf__max_features=sqrt, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=5, rf__max_features=sqrt, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=5, rf__max_features=sqrt, rf__n_estimators=150; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=5, rf__max_features=sqrt, rf__n_estimators=150; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=5, rf__max_features=sqrt, rf__n_estimators=150; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=5, rf__max_features=sqrt, rf__n_estimators=150; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=5, rf__max_features=log2, rf__n_estimators=100; total time=   0.2s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=5, rf__max_features=log2, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=5, rf__max_features=log2, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=5, rf__max_features=log2, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=5, rf__max_features=log2, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=5, rf__max_features=log2, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=5, rf__max_features=log2, rf__n_estimators=150; total time=   0.1s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=5, rf__max_features=log2, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=5, rf__max_features=log2, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=gini, rf__max_depth=5, rf__max_features=log2, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=2, rf__max_features=sqrt, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=2, rf__max_features=sqrt, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=2, rf__max_features=sqrt, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=2, rf__max_features=sqrt, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=2, rf__max_features=sqrt, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=2, rf__max_features=sqrt, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=2, rf__max_features=sqrt, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=2, rf__max_features=sqrt, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=2, rf__max_features=sqrt, rf__n_estimators=150; total time=   0.1s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=2, rf__max_features=sqrt, rf__n_estimators=150; total time=   0.1s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=2, rf__max_features=log2, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=2, rf__max_features=log2, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=2, rf__max_features=log2, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=2, rf__max_features=log2, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=2, rf__max_features=log2, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=2, rf__max_features=log2, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=2, rf__max_features=log2, rf__n_estimators=150; total time=   0.1s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=2, rf__max_features=log2, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=2, rf__max_features=log2, rf__n_estimators=150; total time=   0.1s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=2, rf__max_features=log2, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=3, rf__max_features=sqrt, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=3, rf__max_features=sqrt, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=3, rf__max_features=sqrt, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=3, rf__max_features=sqrt, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=3, rf__max_features=sqrt, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=3, rf__max_features=sqrt, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=3, rf__max_features=sqrt, rf__n_estimators=150; total time=   0.1s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=3, rf__max_features=sqrt, rf__n_estimators=150; total time=   0.1s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=3, rf__max_features=sqrt, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=3, rf__max_features=sqrt, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=3, rf__max_features=log2, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=3, rf__max_features=log2, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=3, rf__max_features=log2, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=3, rf__max_features=log2, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=3, rf__max_features=log2, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=3, rf__max_features=log2, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=3, rf__max_features=log2, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=3, rf__max_features=log2, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=3, rf__max_features=log2, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=3, rf__max_features=log2, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=4, rf__max_features=sqrt, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=4, rf__max_features=sqrt, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=4, rf__max_features=sqrt, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=4, rf__max_features=sqrt, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=4, rf__max_features=sqrt, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=4, rf__max_features=sqrt, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=4, rf__max_features=sqrt, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=4, rf__max_features=sqrt, rf__n_estimators=150; total time=   0.3s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=4, rf__max_features=sqrt, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=4, rf__max_features=sqrt, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=4, rf__max_features=log2, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=4, rf__max_features=log2, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=4, rf__max_features=log2, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=4, rf__max_features=log2, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=4, rf__max_features=log2, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=4, rf__max_features=log2, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=4, rf__max_features=log2, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=4, rf__max_features=log2, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=4, rf__max_features=log2, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=4, rf__max_features=log2, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=5, rf__max_features=sqrt, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=5, rf__max_features=sqrt, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=5, rf__max_features=sqrt, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=5, rf__max_features=sqrt, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=5, rf__max_features=sqrt, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=5, rf__max_features=sqrt, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=5, rf__max_features=sqrt, rf__n_estimators=150; total time=   0.3s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=5, rf__max_features=sqrt, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=5, rf__max_features=sqrt, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=5, rf__max_features=sqrt, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=5, rf__max_features=log2, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=5, rf__max_features=log2, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=5, rf__max_features=log2, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=5, rf__max_features=log2, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=5, rf__max_features=log2, rf__n_estimators=100; total time=   0.1s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=5, rf__max_features=log2, rf__n_estimators=150; total time=   0.3s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=5, rf__max_features=log2, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=5, rf__max_features=log2, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=5, rf__max_features=log2, rf__n_estimators=150; total time=   0.2s\n",
      "[CV] END rf__criterion=entropy, rf__max_depth=5, rf__max_features=log2, rf__n_estimators=150; total time=   0.2s\n",
      "Matriz de confusão do modelo nos dados de teste:\n",
      "\n",
      "[[  1  59]\n",
      " [  0 140]]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Matriz de confusão do modelo nos dados de teste:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       1.00      0.02      0.03        60\n",
      "        good       0.70      1.00      0.83       140\n",
      "\n",
      "    accuracy                           0.70       200\n",
      "   macro avg       0.85      0.51      0.43       200\n",
      "weighted avg       0.79      0.70      0.59       200\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-17T22:03:45.241792Z",
     "start_time": "2021-09-17T22:02:59.999662Z"
    },
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "grid_rf.best_params_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'rf__criterion': 'gini',\n",
       " 'rf__max_depth': 2,\n",
       " 'rf__max_features': 'sqrt',\n",
       " 'rf__n_estimators': 100}"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-17T22:03:45.256768Z",
     "start_time": "2021-09-17T22:03:45.245776Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "_________\n",
    "_______\n",
    "_________"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3) Boosting & AdaBoost\n",
    "\n",
    "O AdaBoost significa **Adaptive Boosting**, e tem como procedimento geral **a criação sucessiva dos chamados weak learners**, que são modelos bem fracos de aprendizagem - geralmente, **árvores de um único nó (stumps)**.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1744/1*nJ5VrsiS1yaOR77d4h8gyw.png\" width=300>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "O AdaBoost utiliza os **erros da árvore anterior para melhorar a próxima árvore**. As predições finais são feitas com base **nos pesos de cada stump**, cuja determinação faz parte do algoritmo!\n",
    "\n",
    "<img src=\"https://static.packt-cdn.com/products/9781788295758/graphics/image_04_046-1.png\" width=700>\n",
    "\n",
    "Vamos entender um pouco melhor..."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aqui, o bootstrapping não é utilizado: o método começa treinando um classificador fraco **no dataset original**, e depois treina diversas cópias adicionais do classificador **no mesmo dataset**, mas dando **um peso maior às observações que foram classificadas erroneamente** (ou, no caso de regressões, a observações **com o maior erro**).\n",
    "\n",
    "Assim, após diversas iterações, classificadores/regressores vão sequencialmente \"focando nos casos mais difíceis\", e construindo um classificador encadeado que seja forte, apesar de utilizar diversos classificadores fracos em como elementos fundamentais.\n",
    "\n",
    "<img src=\"https://www.researchgate.net/profile/Zhuo_Wang8/publication/288699540/figure/fig9/AS:668373486686246@1536364065786/Illustration-of-AdaBoost-algorithm-for-creating-a-strong-classifier-based-on-multiple.png\" width=500>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "De forma resumida, as principais ideias por trás deste algoritmo são:\n",
    "\n",
    "- O algoritmo cria e combina um conjunto de **modelos fracos** (em geral, stumps);\n",
    "- Cada stump é criado **levando em consideração os erros do stump anterior**;\n",
    "- Alguns dos stumps têm **maior peso de decisão** do que outros na predição final;\n",
    "\n",
    "As classes no sklearn são:\n",
    "\n",
    "- [AdaBoostClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html)\n",
    "\n",
    "- [AdaBoostRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html#sklearn.ensemble.AdaBoostRegressor)\n",
    "\n",
    "Note que não há muitos hiperparâmetros. O mais importante, que deve ser tunado com o grid/random search, é:\n",
    "\n",
    "- `n_estimators` : o número de weak learners encadeados;\n",
    "\n",
    "Além disso, pode também ser interessante tunar os hiperparâmetros dos weak learners. Isso é possível de ser feito, como veremos a seguir!\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Primeiro, vamos começar com nosso baseline:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# adaboost baseline\r\n",
    "\r\n",
    "df = pd.read_csv('../datasets/german_credit_data.csv', index_col=0)\r\n",
    "\r\n",
    "# dropando NaNs e features categóricas\r\n",
    "df_aux = df.dropna().select_dtypes(include=np.number)\r\n",
    "df = pd.concat([df_aux, df.dropna()[\"Risk\"]], axis=1)          \r\n",
    "\r\n",
    "X = df.drop(columns=\"Risk\")\r\n",
    "y = df[\"Risk\"]\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \r\n",
    "                                                    y, \r\n",
    "                                                    test_size=0.2, \r\n",
    "                                                    random_state=42,\r\n",
    "                                                    stratify=y)\r\n",
    "\r\n",
    "from sklearn.ensemble import AdaBoostClassifier\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "\r\n",
    "estimador = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1, random_state=42), \r\n",
    "                               random_state=42)\r\n",
    "\r\n",
    "# to-do: implemente o cross_validate\r\n",
    "modelo = estimador.fit(X_train, y_train)\r\n",
    "\r\n",
    "y_pred = modelo.predict(X_test)\r\n",
    "\r\n",
    "from sklearn.metrics import confusion_matrix, classification_report, plot_confusion_matrix\r\n",
    "\r\n",
    "print(confusion_matrix(y_test, y_pred))\r\n",
    "\r\n",
    "plot_confusion_matrix(modelo, X_test, y_test)\r\n",
    "plt.show()\r\n",
    "\r\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[26 20]\n",
      " [14 45]]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.65      0.57      0.60        46\n",
      "        good       0.69      0.76      0.73        59\n",
      "\n",
      "    accuracy                           0.68       105\n",
      "   macro avg       0.67      0.66      0.67       105\n",
      "weighted avg       0.67      0.68      0.67       105\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-17T22:03:46.041835Z",
     "start_time": "2021-09-17T22:03:45.262765Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# adaboost baseline\n",
    "\n",
    "df = pd.read_csv('../datasets/german_credit_data.csv', index_col=0)\n",
    "\n",
    "# dropando NaNs e features categóricas\n",
    "df_aux = df.dropna().select_dtypes(include=np.number)\n",
    "df = pd.concat([df_aux, df.dropna()[\"Risk\"]], axis=1)          \n",
    "\n",
    "X = df.drop(columns=\"Risk\")\n",
    "y = df[\"Risk\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "estimador = AdaBoostClassifier(base_estimator=LogisticRegression(C=0.1, random_state=42), \n",
    "                               random_state=42)\n",
    "\n",
    "# to-do: implemente o cross_validate\n",
    "modelo = estimador.fit(X_train, y_train)\n",
    "\n",
    "y_pred = modelo.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, plot_confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "plot_confusion_matrix(modelo, X_test, y_test)\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[15 31]\n",
      " [13 46]]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.54      0.33      0.41        46\n",
      "        good       0.60      0.78      0.68        59\n",
      "\n",
      "    accuracy                           0.58       105\n",
      "   macro avg       0.57      0.55      0.54       105\n",
      "weighted avg       0.57      0.58      0.56       105\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-17T22:03:48.160650Z",
     "start_time": "2021-09-17T22:03:46.045819Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# construa um pipeline com o grid/randomsearch para achar o melhor random forest\r\n",
    "# (adapte da aula 8 a pipeline)\r\n",
    "\r\n",
    "# gridsearch com a PIPELINE MAIS GENERICA - processamento diferente em colunas diferentes!\r\n",
    "\r\n",
    "df = pd.read_csv('../datasets/german_credit_data.csv', index_col=0)          \r\n",
    "\r\n",
    "X = df.drop(columns=\"Risk\")\r\n",
    "y = df[\"Risk\"]\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \r\n",
    "                                                    y, \r\n",
    "                                                    test_size=0.2, \r\n",
    "                                                    random_state=42,\r\n",
    "                                                    stratify=y)\r\n",
    "\r\n",
    "\r\n",
    "######################## PIPELINE\r\n",
    "\r\n",
    "from sklearn.pipeline import Pipeline\r\n",
    "from sklearn.compose import ColumnTransformer\r\n",
    "\r\n",
    "# ==========================================\r\n",
    "# transformer das features numericas (pipeline de processamento)\r\n",
    "\r\n",
    "from sklearn.impute import SimpleImputer\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "\r\n",
    "transf_feat_nums = Pipeline([(\"simple_imput_num\", SimpleImputer(strategy=\"mean\")), \r\n",
    "                             (\"std_scaler\", StandardScaler())])\r\n",
    "\r\n",
    "features_nums = X.select_dtypes(include=np.number).columns.tolist()\r\n",
    "\r\n",
    "# ==========================================\r\n",
    "# transformer das features categoricas (pipeline de processamento)\r\n",
    "\r\n",
    "from sklearn.preprocessing import OneHotEncoder\r\n",
    "\r\n",
    "transf_feat_cats = Pipeline([(\"simple_imput_cat\", SimpleImputer(strategy=\"most_frequent\")),\r\n",
    "                             (\"onehot\", OneHotEncoder())])\r\n",
    "\r\n",
    "features_cats = X.select_dtypes(exclude=np.number).columns.tolist()\r\n",
    "\r\n",
    "# ==========================================\r\n",
    "\r\n",
    "pre_processador = ColumnTransformer([(\"transf_num\", transf_feat_nums, features_nums), \r\n",
    "                                     (\"transf_cat\", transf_feat_cats, features_cats)])\r\n",
    "\r\n",
    "\r\n",
    "from sklearn.ensemble import AdaBoostClassifier\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "\r\n",
    "# pipeline final, com pre-processamento, e depois a modelagem\r\n",
    "pipe = Pipeline([('pre_process', pre_processador),\r\n",
    "                 ('ab', AdaBoostClassifier(base_estimator=DecisionTreeClassifier(),\r\n",
    "                                           random_state=42))])\r\n",
    "\r\n",
    "######################## GRID SEARCH\r\n",
    "\r\n",
    "from sklearn.model_selection import GridSearchCV\r\n",
    "\r\n",
    "param_grid_ab = {\"ab__base_estimator__criterion\" : [\"gini\", \"entropy\"],\r\n",
    "                 \"ab__base_estimator__max_depth\" : [1, 2],\r\n",
    "                 \"ab__base_estimator__max_features\" : [\"sqrt\", \"log2\"],\r\n",
    "                 \"ab__n_estimators\" : [100, 150]}\r\n",
    "\r\n",
    "# PRA OTIMIZAR UMA METRICA QUE TEM DUAS OPÇOES\r\n",
    "from sklearn.metrics import recall_score, make_scorer\r\n",
    "\r\n",
    "metrica = make_scorer(recall_score, pos_label=\"good\")\r\n",
    "\r\n",
    "grid_ab = GridSearchCV(pipe, param_grid_ab, scoring=metrica, cv=5, verbose=1.5)\r\n",
    "\r\n",
    "grid_ab.fit(X_train, y_train)\r\n",
    "\r\n",
    "y_pred = grid_ab.predict(X_test)\r\n",
    "\r\n",
    "from sklearn.metrics import classification_report, confusion_matrix\r\n",
    "\r\n",
    "print(\"Matriz de confusão do modelo nos dados de teste:\\n\")\r\n",
    "print(confusion_matrix(y_test, y_pred))\r\n",
    "\r\n",
    "plot_confusion_matrix(grid_ab, X_test, y_test)\r\n",
    "plt.show()\r\n",
    "\r\n",
    "print(\"\\nMatriz de confusão do modelo nos dados de teste:\\n\")\r\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=sqrt, ab__n_estimators=100; total time=   0.3s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=sqrt, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=sqrt, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=sqrt, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=sqrt, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=sqrt, ab__n_estimators=150; total time=   0.3s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=sqrt, ab__n_estimators=150; total time=   0.5s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=sqrt, ab__n_estimators=150; total time=   0.5s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=sqrt, ab__n_estimators=150; total time=   0.3s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=sqrt, ab__n_estimators=150; total time=   0.2s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=log2, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=log2, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=log2, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=log2, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=log2, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=log2, ab__n_estimators=150; total time=   0.2s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=log2, ab__n_estimators=150; total time=   0.2s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=log2, ab__n_estimators=150; total time=   0.2s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=log2, ab__n_estimators=150; total time=   0.3s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=log2, ab__n_estimators=150; total time=   0.2s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=sqrt, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=sqrt, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=sqrt, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=sqrt, ab__n_estimators=100; total time=   0.2s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=sqrt, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=sqrt, ab__n_estimators=150; total time=   0.3s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=sqrt, ab__n_estimators=150; total time=   0.2s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=sqrt, ab__n_estimators=150; total time=   0.4s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=sqrt, ab__n_estimators=150; total time=   0.3s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=sqrt, ab__n_estimators=150; total time=   0.2s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=log2, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=log2, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=log2, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=log2, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=log2, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=log2, ab__n_estimators=150; total time=   0.2s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=log2, ab__n_estimators=150; total time=   0.2s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=log2, ab__n_estimators=150; total time=   0.3s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=log2, ab__n_estimators=150; total time=   0.2s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=log2, ab__n_estimators=150; total time=   0.3s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=sqrt, ab__n_estimators=100; total time=   0.2s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=sqrt, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=sqrt, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=sqrt, ab__n_estimators=100; total time=   0.2s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=sqrt, ab__n_estimators=100; total time=   0.2s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=sqrt, ab__n_estimators=150; total time=   0.2s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=sqrt, ab__n_estimators=150; total time=   0.2s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=sqrt, ab__n_estimators=150; total time=   0.3s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=sqrt, ab__n_estimators=150; total time=   0.2s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=sqrt, ab__n_estimators=150; total time=   0.3s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=log2, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=log2, ab__n_estimators=100; total time=   0.2s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=log2, ab__n_estimators=100; total time=   0.2s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=log2, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=log2, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=log2, ab__n_estimators=150; total time=   0.2s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=log2, ab__n_estimators=150; total time=   0.2s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=log2, ab__n_estimators=150; total time=   0.3s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=log2, ab__n_estimators=150; total time=   0.2s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=log2, ab__n_estimators=150; total time=   0.2s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=sqrt, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=sqrt, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=sqrt, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=sqrt, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=sqrt, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=sqrt, ab__n_estimators=150; total time=   0.2s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=sqrt, ab__n_estimators=150; total time=   0.2s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=sqrt, ab__n_estimators=150; total time=   0.2s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=sqrt, ab__n_estimators=150; total time=   0.2s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=sqrt, ab__n_estimators=150; total time=   0.2s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=log2, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=log2, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=log2, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=log2, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=log2, ab__n_estimators=100; total time=   0.2s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=log2, ab__n_estimators=150; total time=   0.3s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=log2, ab__n_estimators=150; total time=   0.2s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=log2, ab__n_estimators=150; total time=   0.2s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=log2, ab__n_estimators=150; total time=   0.2s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=log2, ab__n_estimators=150; total time=   0.2s\n",
      "Matriz de confusão do modelo nos dados de teste:\n",
      "\n",
      "[[ 15  45]\n",
      " [ 21 119]]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Matriz de confusão do modelo nos dados de teste:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.42      0.25      0.31        60\n",
      "        good       0.73      0.85      0.78       140\n",
      "\n",
      "    accuracy                           0.67       200\n",
      "   macro avg       0.57      0.55      0.55       200\n",
      "weighted avg       0.63      0.67      0.64       200\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-17T22:04:18.191517Z",
     "start_time": "2021-09-17T22:03:48.163636Z"
    },
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# construa um pipeline com o grid/randomsearch para achar o melhor random forest\r\n",
    "# (adapte da aula 8 a pipeline)\r\n",
    "\r\n",
    "# gridsearch com a PIPELINE MAIS GENERICA - processamento diferente em colunas diferentes!\r\n",
    "\r\n",
    "df = pd.read_csv('../datasets/german_credit_data.csv', index_col=0)          \r\n",
    "\r\n",
    "X = df.drop(columns=\"Risk\")\r\n",
    "y = df[\"Risk\"]\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \r\n",
    "                                                    y, \r\n",
    "                                                    test_size=0.2, \r\n",
    "                                                    random_state=42,\r\n",
    "                                                    stratify=y)\r\n",
    "\r\n",
    "\r\n",
    "######################## PIPELINE\r\n",
    "\r\n",
    "from sklearn.pipeline import Pipeline\r\n",
    "from sklearn.compose import ColumnTransformer\r\n",
    "\r\n",
    "# ==========================================\r\n",
    "# transformer das features numericas (pipeline de processamento)\r\n",
    "\r\n",
    "from sklearn.impute import SimpleImputer\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "\r\n",
    "transf_feat_nums = Pipeline([(\"simple_imput_num\", SimpleImputer(strategy=\"mean\")), \r\n",
    "                             (\"std_scaler\", StandardScaler())])\r\n",
    "\r\n",
    "features_nums = X.select_dtypes(include=np.number).columns.tolist()\r\n",
    "\r\n",
    "# ==========================================\r\n",
    "# transformer das features categoricas (pipeline de processamento)\r\n",
    "\r\n",
    "from sklearn.preprocessing import OneHotEncoder\r\n",
    "\r\n",
    "transf_feat_cats = Pipeline([(\"simple_imput_cat\", SimpleImputer(strategy=\"most_frequent\")),\r\n",
    "                             (\"onehot\", OneHotEncoder())])\r\n",
    "\r\n",
    "features_cats = X.select_dtypes(exclude=np.number).columns.tolist()\r\n",
    "\r\n",
    "# ==========================================\r\n",
    "\r\n",
    "pre_processador = ColumnTransformer([(\"transf_num\", transf_feat_nums, features_nums), \r\n",
    "                                     (\"transf_cat\", transf_feat_cats, features_cats)])\r\n",
    "\r\n",
    "\r\n",
    "from sklearn.ensemble import AdaBoostClassifier\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "\r\n",
    "# pipeline final, com pre-processamento, e depois a modelagem\r\n",
    "pipe = Pipeline([('pre_process', pre_processador),\r\n",
    "                 ('ab', AdaBoostClassifier(base_estimator=DecisionTreeClassifier(),\r\n",
    "                                           random_state=42))])\r\n",
    "\r\n",
    "######################## GRID SEARCH\r\n",
    "\r\n",
    "from sklearn.model_selection import GridSearchCV\r\n",
    "\r\n",
    "param_grid_ab = {\"ab__base_estimator__criterion\" : [\"gini\", \"entropy\"],\r\n",
    "                 \"ab__base_estimator__max_depth\" : [1, 2],\r\n",
    "                 \"ab__base_estimator__max_features\" : [\"sqrt\", \"log2\"],\r\n",
    "                 \"ab__n_estimators\" : [50, 100]}\r\n",
    "\r\n",
    "grid_ab = GridSearchCV(pipe, param_grid_ab, scoring=\"f1_weighted\", cv=5, verbose=1.5)\r\n",
    "\r\n",
    "grid_ab.fit(X_train, y_train)\r\n",
    "\r\n",
    "y_pred = grid_ab.predict(X_test)\r\n",
    "\r\n",
    "from sklearn.metrics import classification_report, confusion_matrix\r\n",
    "\r\n",
    "print(\"Matriz de confusão do modelo nos dados de teste:\\n\")\r\n",
    "print(confusion_matrix(y_test, y_pred))\r\n",
    "\r\n",
    "plot_confusion_matrix(grid_ab, X_test, y_test)\r\n",
    "plt.show()\r\n",
    "\r\n",
    "print(\"\\nMatriz de confusão do modelo nos dados de teste:\\n\")\r\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=sqrt, ab__n_estimators=50; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=sqrt, ab__n_estimators=50; total time=   0.0s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=sqrt, ab__n_estimators=50; total time=   0.0s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=sqrt, ab__n_estimators=50; total time=   0.0s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=sqrt, ab__n_estimators=50; total time=   0.0s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=sqrt, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=sqrt, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=sqrt, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=sqrt, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=sqrt, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=log2, ab__n_estimators=50; total time=   0.0s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=log2, ab__n_estimators=50; total time=   0.0s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=log2, ab__n_estimators=50; total time=   0.0s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=log2, ab__n_estimators=50; total time=   0.0s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=log2, ab__n_estimators=50; total time=   0.0s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=log2, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=log2, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=log2, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=log2, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=log2, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=sqrt, ab__n_estimators=50; total time=   0.0s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=sqrt, ab__n_estimators=50; total time=   0.0s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=sqrt, ab__n_estimators=50; total time=   0.0s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=sqrt, ab__n_estimators=50; total time=   0.0s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=sqrt, ab__n_estimators=50; total time=   0.0s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=sqrt, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=sqrt, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=sqrt, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=sqrt, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=sqrt, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=log2, ab__n_estimators=50; total time=   0.0s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=log2, ab__n_estimators=50; total time=   0.0s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=log2, ab__n_estimators=50; total time=   0.0s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=log2, ab__n_estimators=50; total time=   0.0s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=log2, ab__n_estimators=50; total time=   0.0s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=log2, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=log2, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=log2, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=log2, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=gini, ab__base_estimator__max_depth=2, ab__base_estimator__max_features=log2, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=sqrt, ab__n_estimators=50; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=sqrt, ab__n_estimators=50; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=sqrt, ab__n_estimators=50; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=sqrt, ab__n_estimators=50; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=sqrt, ab__n_estimators=50; total time=   0.0s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=sqrt, ab__n_estimators=100; total time=   0.2s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=sqrt, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=sqrt, ab__n_estimators=100; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=sqrt, ab__n_estimators=100; total time=   0.2s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=sqrt, ab__n_estimators=100; total time=   0.2s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=log2, ab__n_estimators=50; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=log2, ab__n_estimators=50; total time=   0.1s\n",
      "[CV] END ab__base_estimator__criterion=entropy, ab__base_estimator__max_depth=1, ab__base_estimator__max_features=log2, ab__n_estimators=50; total time=   0.1s\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-17T22:04:39.633213Z",
     "start_time": "2021-09-17T22:04:18.195520Z"
    },
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "grid_ab.best_params_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'ab__base_estimator__criterion': 'gini',\n",
       " 'ab__base_estimator__max_depth': 1,\n",
       " 'ab__base_estimator__max_features': 'sqrt',\n",
       " 'ab__n_estimators': 50}"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-17T22:04:39.649132Z",
     "start_time": "2021-09-17T22:04:39.636144Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pd.DataFrame(grid_ab.cv_results_).sort_values(\"rank_test_score\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_ab__base_estimator__criterion</th>\n",
       "      <th>param_ab__base_estimator__max_depth</th>\n",
       "      <th>param_ab__base_estimator__max_features</th>\n",
       "      <th>param_ab__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.136730</td>\n",
       "      <td>0.008200</td>\n",
       "      <td>0.019981</td>\n",
       "      <td>0.002091</td>\n",
       "      <td>gini</td>\n",
       "      <td>1</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>{'ab__base_estimator__criterion': 'gini', 'ab_...</td>\n",
       "      <td>0.740984</td>\n",
       "      <td>0.677714</td>\n",
       "      <td>0.698039</td>\n",
       "      <td>0.659764</td>\n",
       "      <td>0.631924</td>\n",
       "      <td>0.681685</td>\n",
       "      <td>0.036759</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.185021</td>\n",
       "      <td>0.073565</td>\n",
       "      <td>0.031625</td>\n",
       "      <td>0.014355</td>\n",
       "      <td>gini</td>\n",
       "      <td>1</td>\n",
       "      <td>log2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'ab__base_estimator__criterion': 'gini', 'ab_...</td>\n",
       "      <td>0.740984</td>\n",
       "      <td>0.677714</td>\n",
       "      <td>0.698039</td>\n",
       "      <td>0.659764</td>\n",
       "      <td>0.631924</td>\n",
       "      <td>0.681685</td>\n",
       "      <td>0.036759</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.258060</td>\n",
       "      <td>0.018677</td>\n",
       "      <td>0.028791</td>\n",
       "      <td>0.003701</td>\n",
       "      <td>gini</td>\n",
       "      <td>1</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'ab__base_estimator__criterion': 'gini', 'ab_...</td>\n",
       "      <td>0.737816</td>\n",
       "      <td>0.668820</td>\n",
       "      <td>0.654902</td>\n",
       "      <td>0.650286</td>\n",
       "      <td>0.617984</td>\n",
       "      <td>0.665962</td>\n",
       "      <td>0.039601</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.340344</td>\n",
       "      <td>0.037049</td>\n",
       "      <td>0.046775</td>\n",
       "      <td>0.017637</td>\n",
       "      <td>gini</td>\n",
       "      <td>1</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'ab__base_estimator__criterion': 'gini', 'ab_...</td>\n",
       "      <td>0.737816</td>\n",
       "      <td>0.668820</td>\n",
       "      <td>0.654902</td>\n",
       "      <td>0.650286</td>\n",
       "      <td>0.617984</td>\n",
       "      <td>0.665962</td>\n",
       "      <td>0.039601</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.144826</td>\n",
       "      <td>0.011067</td>\n",
       "      <td>0.021389</td>\n",
       "      <td>0.004363</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>{'ab__base_estimator__criterion': 'entropy', '...</td>\n",
       "      <td>0.699274</td>\n",
       "      <td>0.658014</td>\n",
       "      <td>0.648474</td>\n",
       "      <td>0.627278</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>0.665431</td>\n",
       "      <td>0.027446</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.169016</td>\n",
       "      <td>0.027032</td>\n",
       "      <td>0.035580</td>\n",
       "      <td>0.016225</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>log2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'ab__base_estimator__criterion': 'entropy', '...</td>\n",
       "      <td>0.699274</td>\n",
       "      <td>0.658014</td>\n",
       "      <td>0.648474</td>\n",
       "      <td>0.627278</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>0.665431</td>\n",
       "      <td>0.027446</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.182870</td>\n",
       "      <td>0.030604</td>\n",
       "      <td>0.037580</td>\n",
       "      <td>0.023398</td>\n",
       "      <td>entropy</td>\n",
       "      <td>1</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>{'ab__base_estimator__criterion': 'entropy', '...</td>\n",
       "      <td>0.703497</td>\n",
       "      <td>0.673651</td>\n",
       "      <td>0.678850</td>\n",
       "      <td>0.636559</td>\n",
       "      <td>0.631924</td>\n",
       "      <td>0.664896</td>\n",
       "      <td>0.027024</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.150714</td>\n",
       "      <td>0.022430</td>\n",
       "      <td>0.023185</td>\n",
       "      <td>0.004164</td>\n",
       "      <td>entropy</td>\n",
       "      <td>1</td>\n",
       "      <td>log2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'ab__base_estimator__criterion': 'entropy', '...</td>\n",
       "      <td>0.703497</td>\n",
       "      <td>0.673651</td>\n",
       "      <td>0.678850</td>\n",
       "      <td>0.636559</td>\n",
       "      <td>0.631924</td>\n",
       "      <td>0.664896</td>\n",
       "      <td>0.027024</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.269863</td>\n",
       "      <td>0.022831</td>\n",
       "      <td>0.030582</td>\n",
       "      <td>0.002732</td>\n",
       "      <td>entropy</td>\n",
       "      <td>1</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'ab__base_estimator__criterion': 'entropy', '...</td>\n",
       "      <td>0.716974</td>\n",
       "      <td>0.667939</td>\n",
       "      <td>0.664576</td>\n",
       "      <td>0.650286</td>\n",
       "      <td>0.622632</td>\n",
       "      <td>0.664481</td>\n",
       "      <td>0.030726</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.269767</td>\n",
       "      <td>0.028108</td>\n",
       "      <td>0.032977</td>\n",
       "      <td>0.006261</td>\n",
       "      <td>entropy</td>\n",
       "      <td>1</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'ab__base_estimator__criterion': 'entropy', '...</td>\n",
       "      <td>0.716974</td>\n",
       "      <td>0.667939</td>\n",
       "      <td>0.664576</td>\n",
       "      <td>0.650286</td>\n",
       "      <td>0.622632</td>\n",
       "      <td>0.664481</td>\n",
       "      <td>0.030726</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.144341</td>\n",
       "      <td>0.009963</td>\n",
       "      <td>0.021590</td>\n",
       "      <td>0.008203</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>{'ab__base_estimator__criterion': 'gini', 'ab_...</td>\n",
       "      <td>0.609534</td>\n",
       "      <td>0.656815</td>\n",
       "      <td>0.644792</td>\n",
       "      <td>0.651894</td>\n",
       "      <td>0.714888</td>\n",
       "      <td>0.655584</td>\n",
       "      <td>0.033968</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.158988</td>\n",
       "      <td>0.014220</td>\n",
       "      <td>0.025581</td>\n",
       "      <td>0.005278</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>log2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'ab__base_estimator__criterion': 'gini', 'ab_...</td>\n",
       "      <td>0.609534</td>\n",
       "      <td>0.656815</td>\n",
       "      <td>0.644792</td>\n",
       "      <td>0.651894</td>\n",
       "      <td>0.714888</td>\n",
       "      <td>0.655584</td>\n",
       "      <td>0.033968</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.307963</td>\n",
       "      <td>0.020080</td>\n",
       "      <td>0.035023</td>\n",
       "      <td>0.008851</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'ab__base_estimator__criterion': 'gini', 'ab_...</td>\n",
       "      <td>0.630129</td>\n",
       "      <td>0.614420</td>\n",
       "      <td>0.612485</td>\n",
       "      <td>0.630416</td>\n",
       "      <td>0.678215</td>\n",
       "      <td>0.633133</td>\n",
       "      <td>0.023771</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.362218</td>\n",
       "      <td>0.048629</td>\n",
       "      <td>0.043177</td>\n",
       "      <td>0.008370</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'ab__base_estimator__criterion': 'gini', 'ab_...</td>\n",
       "      <td>0.630129</td>\n",
       "      <td>0.614420</td>\n",
       "      <td>0.612485</td>\n",
       "      <td>0.630416</td>\n",
       "      <td>0.678215</td>\n",
       "      <td>0.633133</td>\n",
       "      <td>0.023771</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.283038</td>\n",
       "      <td>0.020966</td>\n",
       "      <td>0.030990</td>\n",
       "      <td>0.001670</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'ab__base_estimator__criterion': 'entropy', '...</td>\n",
       "      <td>0.650089</td>\n",
       "      <td>0.631388</td>\n",
       "      <td>0.608678</td>\n",
       "      <td>0.604017</td>\n",
       "      <td>0.635248</td>\n",
       "      <td>0.625884</td>\n",
       "      <td>0.017193</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.285334</td>\n",
       "      <td>0.031241</td>\n",
       "      <td>0.031781</td>\n",
       "      <td>0.004661</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'ab__base_estimator__criterion': 'entropy', '...</td>\n",
       "      <td>0.650089</td>\n",
       "      <td>0.631388</td>\n",
       "      <td>0.608678</td>\n",
       "      <td>0.604017</td>\n",
       "      <td>0.635248</td>\n",
       "      <td>0.625884</td>\n",
       "      <td>0.017193</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.136730      0.008200         0.019981        0.002091   \n",
       "2        0.185021      0.073565         0.031625        0.014355   \n",
       "1        0.258060      0.018677         0.028791        0.003701   \n",
       "3        0.340344      0.037049         0.046775        0.017637   \n",
       "12       0.144826      0.011067         0.021389        0.004363   \n",
       "14       0.169016      0.027032         0.035580        0.016225   \n",
       "8        0.182870      0.030604         0.037580        0.023398   \n",
       "10       0.150714      0.022430         0.023185        0.004164   \n",
       "9        0.269863      0.022831         0.030582        0.002732   \n",
       "11       0.269767      0.028108         0.032977        0.006261   \n",
       "4        0.144341      0.009963         0.021590        0.008203   \n",
       "6        0.158988      0.014220         0.025581        0.005278   \n",
       "5        0.307963      0.020080         0.035023        0.008851   \n",
       "7        0.362218      0.048629         0.043177        0.008370   \n",
       "13       0.283038      0.020966         0.030990        0.001670   \n",
       "15       0.285334      0.031241         0.031781        0.004661   \n",
       "\n",
       "   param_ab__base_estimator__criterion param_ab__base_estimator__max_depth  \\\n",
       "0                                 gini                                   1   \n",
       "2                                 gini                                   1   \n",
       "1                                 gini                                   1   \n",
       "3                                 gini                                   1   \n",
       "12                             entropy                                   2   \n",
       "14                             entropy                                   2   \n",
       "8                              entropy                                   1   \n",
       "10                             entropy                                   1   \n",
       "9                              entropy                                   1   \n",
       "11                             entropy                                   1   \n",
       "4                                 gini                                   2   \n",
       "6                                 gini                                   2   \n",
       "5                                 gini                                   2   \n",
       "7                                 gini                                   2   \n",
       "13                             entropy                                   2   \n",
       "15                             entropy                                   2   \n",
       "\n",
       "   param_ab__base_estimator__max_features param_ab__n_estimators  \\\n",
       "0                                    sqrt                     50   \n",
       "2                                    log2                     50   \n",
       "1                                    sqrt                    100   \n",
       "3                                    log2                    100   \n",
       "12                                   sqrt                     50   \n",
       "14                                   log2                     50   \n",
       "8                                    sqrt                     50   \n",
       "10                                   log2                     50   \n",
       "9                                    sqrt                    100   \n",
       "11                                   log2                    100   \n",
       "4                                    sqrt                     50   \n",
       "6                                    log2                     50   \n",
       "5                                    sqrt                    100   \n",
       "7                                    log2                    100   \n",
       "13                                   sqrt                    100   \n",
       "15                                   log2                    100   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'ab__base_estimator__criterion': 'gini', 'ab_...           0.740984   \n",
       "2   {'ab__base_estimator__criterion': 'gini', 'ab_...           0.740984   \n",
       "1   {'ab__base_estimator__criterion': 'gini', 'ab_...           0.737816   \n",
       "3   {'ab__base_estimator__criterion': 'gini', 'ab_...           0.737816   \n",
       "12  {'ab__base_estimator__criterion': 'entropy', '...           0.699274   \n",
       "14  {'ab__base_estimator__criterion': 'entropy', '...           0.699274   \n",
       "8   {'ab__base_estimator__criterion': 'entropy', '...           0.703497   \n",
       "10  {'ab__base_estimator__criterion': 'entropy', '...           0.703497   \n",
       "9   {'ab__base_estimator__criterion': 'entropy', '...           0.716974   \n",
       "11  {'ab__base_estimator__criterion': 'entropy', '...           0.716974   \n",
       "4   {'ab__base_estimator__criterion': 'gini', 'ab_...           0.609534   \n",
       "6   {'ab__base_estimator__criterion': 'gini', 'ab_...           0.609534   \n",
       "5   {'ab__base_estimator__criterion': 'gini', 'ab_...           0.630129   \n",
       "7   {'ab__base_estimator__criterion': 'gini', 'ab_...           0.630129   \n",
       "13  {'ab__base_estimator__criterion': 'entropy', '...           0.650089   \n",
       "15  {'ab__base_estimator__criterion': 'entropy', '...           0.650089   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.677714           0.698039           0.659764   \n",
       "2            0.677714           0.698039           0.659764   \n",
       "1            0.668820           0.654902           0.650286   \n",
       "3            0.668820           0.654902           0.650286   \n",
       "12           0.658014           0.648474           0.627278   \n",
       "14           0.658014           0.648474           0.627278   \n",
       "8            0.673651           0.678850           0.636559   \n",
       "10           0.673651           0.678850           0.636559   \n",
       "9            0.667939           0.664576           0.650286   \n",
       "11           0.667939           0.664576           0.650286   \n",
       "4            0.656815           0.644792           0.651894   \n",
       "6            0.656815           0.644792           0.651894   \n",
       "5            0.614420           0.612485           0.630416   \n",
       "7            0.614420           0.612485           0.630416   \n",
       "13           0.631388           0.608678           0.604017   \n",
       "15           0.631388           0.608678           0.604017   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.631924         0.681685        0.036759                1  \n",
       "2            0.631924         0.681685        0.036759                1  \n",
       "1            0.617984         0.665962        0.039601                3  \n",
       "3            0.617984         0.665962        0.039601                3  \n",
       "12           0.694118         0.665431        0.027446                5  \n",
       "14           0.694118         0.665431        0.027446                5  \n",
       "8            0.631924         0.664896        0.027024                7  \n",
       "10           0.631924         0.664896        0.027024                7  \n",
       "9            0.622632         0.664481        0.030726                9  \n",
       "11           0.622632         0.664481        0.030726                9  \n",
       "4            0.714888         0.655584        0.033968               11  \n",
       "6            0.714888         0.655584        0.033968               11  \n",
       "5            0.678215         0.633133        0.023771               13  \n",
       "7            0.678215         0.633133        0.023771               13  \n",
       "13           0.635248         0.625884        0.017193               15  \n",
       "15           0.635248         0.625884        0.017193               15  "
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-17T22:04:40.005648Z",
     "start_time": "2021-09-17T22:04:39.652132Z"
    },
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "______\n",
    "\n",
    "### Bagging vs Boosting\n",
    "\n",
    "Pra lembrar as principais diferenças entre os dois métodos de ensemble que estudamos:\n",
    "\n",
    "<img src=https://pluralsight2.imgix.net/guides/81232a78-2e99-4ccc-ba8e-8cd873625fdf_2.jpg width=600>\n",
    "\n",
    "<img src=https://dataaspirant.com/wp-content/uploads/2020/09/8-Difference-Between-Bagging-and-Boosting.png width=600>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "_________\n",
    "_______\n",
    "_________"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4) Gradient boosting\n",
    "\n",
    "Além dos métodos que estudamos, há ainda outras classes de métodos de ensemble!\n",
    "\n",
    "Em particular, a classe de modelos que se utilizam do procedimento de **gradient boosting**.\n",
    "\n",
    "O gradient boosting também é baseado no princípio de boosting (utilização de weak learners sequencialmente adicionados de modo a -**sequencialmente minimizar os erros cometidos**).\n",
    "\n",
    "<img src=https://miro.medium.com/max/788/1*pEu2LNmxf9ttXHIALPcEBw.png width=600>\n",
    "\n",
    "Mas este método implementa o boosting através de um **gradiente** explícito.\n",
    "\n",
    "A ideia é que caminhemos na direção do **erro mínimo** de maneira iterativa **passo a passo**.\n",
    "\n",
    "Este caminho se dá justamente pelo **gradiente** da **função de custo/perda**, que mede justamente os erros cometidos.\n",
    "\n",
    "<img src=https://upload.wikimedia.org/wikipedia/commons/a/a3/Gradient_descent.gif width=400>\n",
    "\n",
    "Este método é conhecido como:\n",
    "\n",
    "### Gradiente descendente\n",
    "\n",
    "Deixei em ênfase porque este será um método de **enorme importância** no estudo de redes neurais (e é, em geral, um método de otimização muito utilizado).\n",
    "\n",
    "O objetivo geral do método é bem simples: determionar quais são os **parâmetros** da hipótese que minimizam a função de custo/perda. Para isso, o método \"percorre\" a função de erro, indo em direção ao seu mínimo (e este \"caminho\" feito na função se dá justamente pela **determinação iterativa dos parâmetros**, isto é, **a cada passo, chegamos mais perto dos parâmetros finais da hipótese**, conforme eles são ajustados aos dados.\n",
    "\n",
    "> **Pequeno interlúdio matemático:** o gradiente descendente implementado pelo gradient boosting é, na verdade, um **gradiente descendente funcional**, isto é, desejamos encontrar não um conjunto de parâmetros que minimiza o erro, mas sim **introduzir sequencialmente weak learners (hipótese simples) que minimizam o erro**. Desta forma, o gradient boosting minimiza a função de custo ao ecolher iterativamente hipóteses simples que apontam na direção do mínimo, neste espaço funcional.\n",
    "\n",
    "Apesar do interlúdio acima, não precisamos nos preocupar muito com os detalhes matemáticos: o que importa é entender que no caso do gradient boosting, há alguns pontos importantes:\n",
    "\n",
    "- Uma **função de custo/perda (loss)** é explicitamente minimizada por um procedimento de gradiente;\n",
    "\n",
    "- O gradiente está relacionado com o procedimento de **encadeamento progressivo entre weak learners**, seguindo a ideia do boosting.\n",
    "\n",
    "Pra quem quiser saber um pouco mais de detalhes (e se aventurar na matemática), sugiro [este post](https://www.gormanalysis.com/blog/gradient-boosting-explained/) ou então [este site](https://explained.ai/gradient-boosting/), que contém vários materiais ótimos para entender o método com todos os detalhes matemáticos.\n",
    "\n",
    "Os [vídeos do StatQuest](https://www.youtube.com/playlist?list=PLblh5JKOoLUJjeXUvUE0maghNuY2_5fY6) também são uma boa referência!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As classes do sklearn são:\n",
    "\n",
    "- [GradientBoostingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)\n",
    "\n",
    "- [GradientBoostingRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn.ensemble.GradientBoostingRegressor)\n",
    "\n",
    "E os principais hiperparâmetros a serem ajustados são:\n",
    "\n",
    "- `n_estimators` : novamente, o número de weak learners encadeados.\n",
    "\n",
    "- `learning_rate` : a constante que multiplica o gradiente no gradiente descendente. Essencialmente, controla o \"tamanho do passo\" a ser dado em direção ao mínimo.\n",
    "\n",
    "Segundo o próprio [User Guide](https://scikit-learn.org/stable/modules/ensemble.html#gradient-boosting): \"*Empirical evidence suggests that small values of `learning_rate` favor better test error. The lireature recommends to set the learning rate to a small constant (e.g. `learning_rate <= 0.1`) and choose `n_estimators` by early stopping.*\"\n",
    "\n",
    "Ainda sobre a learning rate, as ilustrações a seguir ajudam a entender sua importância:\n",
    "\n",
    "<img src=https://www.jeremyjordan.me/content/images/2018/02/Screen-Shot-2018-02-24-at-11.47.09-AM.png width=700>\n",
    "\n",
    "<img src=https://cdn-images-1.medium.com/max/1440/0*A351v9EkS6Ps2zIg.gif width=500>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Vamos treinar nosso classificador baseline de gradient boosting:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# gboost baseline\n",
    "\n",
    "# adaboost baseline\n",
    "\n",
    "df = pd.read_csv('../datasets/german_credit_data.csv', index_col=0)\n",
    "\n",
    "# dropando NaNs e features categóricas\n",
    "df_aux = df.dropna().select_dtypes(include=np.number)\n",
    "df = pd.concat([df_aux, df.dropna()[\"Risk\"]], axis=1)          \n",
    "\n",
    "X = df.drop(columns=\"Risk\")\n",
    "y = df[\"Risk\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "estimador = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# to-do: implemente o cross_validate\n",
    "modelo = estimador.fit(X_train, y_train)\n",
    "\n",
    "y_pred = modelo.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, plot_confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "plot_confusion_matrix(modelo, X_test, y_test)\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[29 17]\n",
      " [14 45]]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.67      0.63      0.65        46\n",
      "        good       0.73      0.76      0.74        59\n",
      "\n",
      "    accuracy                           0.70       105\n",
      "   macro avg       0.70      0.70      0.70       105\n",
      "weighted avg       0.70      0.70      0.70       105\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-17T22:09:21.905274Z",
     "start_time": "2021-09-17T22:09:21.500507Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Agora é com você! Faça o grid/random search para otimizar os hiperparâmetros!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# otimizando hiperparametros do gboost\n",
    "\n",
    "# gridsearch com a PIPELINE MAIS GENERICA - processamento diferente em colunas diferentes!\n",
    "\n",
    "df = pd.read_csv('../datasets/german_credit_data.csv', index_col=0)          \n",
    "\n",
    "X = df.drop(columns=\"Risk\")\n",
    "y = df[\"Risk\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)\n",
    "\n",
    "\n",
    "######################## PIPELINE\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# ==========================================\n",
    "# transformer das features numericas (pipeline de processamento)\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "transf_feat_nums = Pipeline([(\"simple_imput_num\", SimpleImputer(strategy=\"mean\")), \n",
    "                             (\"std_scaler\", StandardScaler())])\n",
    "\n",
    "features_nums = X.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "# ==========================================\n",
    "# transformer das features categoricas (pipeline de processamento)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "transf_feat_cats = Pipeline([(\"simple_imput_cat\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                             (\"onehot\", OneHotEncoder())])\n",
    "\n",
    "features_cats = X.select_dtypes(exclude=np.number).columns.tolist()\n",
    "\n",
    "# ==========================================\n",
    "\n",
    "pre_processador = ColumnTransformer([(\"transf_num\", transf_feat_nums, features_nums), \n",
    "                                     (\"transf_cat\", transf_feat_cats, features_cats)])\n",
    "\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# pipeline final, com pre-processamento, e depois a modelagem\n",
    "pipe = Pipeline([('pre_process', pre_processador),\n",
    "                 ('gb', GradientBoostingClassifier(learning_rate=0.1,\n",
    "                                                   random_state=42))])\n",
    "\n",
    "######################## GRID SEARCH\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid_gb = {\"gb__loss\" : [\"deviance\", \"exponencial\"],\n",
    "                 \"gb__n_estimators\" : [100, 150, 200],\n",
    "                 \"gb__max_depth\" : [2, 3, 4]}\n",
    "\n",
    "grid_gb = GridSearchCV(pipe, param_grid_gb, scoring=\"f1_weighted\", cv=5, verbose=1.5)\n",
    "\n",
    "grid_gb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid_gb.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"Matriz de confusão do modelo nos dados de teste:\\n\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "plot_confusion_matrix(grid_gb, X_test, y_test)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nMatriz de confusão do modelo nos dados de teste:\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[CV] gb__loss=deviance, gb__max_depth=2, gb__n_estimators=100 ........\n",
      "[CV]  gb__loss=deviance, gb__max_depth=2, gb__n_estimators=100, total=   0.2s"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "[CV] gb__loss=deviance, gb__max_depth=2, gb__n_estimators=100 ........\n",
      "[CV]  gb__loss=deviance, gb__max_depth=2, gb__n_estimators=100, total=   0.2s\n",
      "[CV] gb__loss=deviance, gb__max_depth=2, gb__n_estimators=100 ........\n",
      "[CV]  gb__loss=deviance, gb__max_depth=2, gb__n_estimators=100, total=   0.2s\n",
      "[CV] gb__loss=deviance, gb__max_depth=2, gb__n_estimators=100 ........\n",
      "[CV]  gb__loss=deviance, gb__max_depth=2, gb__n_estimators=100, total=   0.2s\n",
      "[CV] gb__loss=deviance, gb__max_depth=2, gb__n_estimators=100 ........\n",
      "[CV]  gb__loss=deviance, gb__max_depth=2, gb__n_estimators=100, total=   0.2s\n",
      "[CV] gb__loss=deviance, gb__max_depth=2, gb__n_estimators=150 ........\n",
      "[CV]  gb__loss=deviance, gb__max_depth=2, gb__n_estimators=150, total=   0.2s\n",
      "[CV] gb__loss=deviance, gb__max_depth=2, gb__n_estimators=150 ........\n",
      "[CV]  gb__loss=deviance, gb__max_depth=2, gb__n_estimators=150, total=   0.3s\n",
      "[CV] gb__loss=deviance, gb__max_depth=2, gb__n_estimators=150 ........\n",
      "[CV]  gb__loss=deviance, gb__max_depth=2, gb__n_estimators=150, total=   0.4s\n",
      "[CV] gb__loss=deviance, gb__max_depth=2, gb__n_estimators=150 ........\n",
      "[CV]  gb__loss=deviance, gb__max_depth=2, gb__n_estimators=150, total=   0.3s\n",
      "[CV] gb__loss=deviance, gb__max_depth=2, gb__n_estimators=150 ........\n",
      "[CV]  gb__loss=deviance, gb__max_depth=2, gb__n_estimators=150, total=   0.3s\n",
      "[CV] gb__loss=deviance, gb__max_depth=2, gb__n_estimators=200 ........\n",
      "[CV]  gb__loss=deviance, gb__max_depth=2, gb__n_estimators=200, total=   0.4s\n",
      "[CV] gb__loss=deviance, gb__max_depth=2, gb__n_estimators=200 ........\n",
      "[CV]  gb__loss=deviance, gb__max_depth=2, gb__n_estimators=200, total=   0.4s\n",
      "[CV] gb__loss=deviance, gb__max_depth=2, gb__n_estimators=200 ........\n",
      "[CV]  gb__loss=deviance, gb__max_depth=2, gb__n_estimators=200, total=   0.4s\n",
      "[CV] gb__loss=deviance, gb__max_depth=2, gb__n_estimators=200 ........\n",
      "[CV]  gb__loss=deviance, gb__max_depth=2, gb__n_estimators=200, total=   0.4s\n",
      "[CV] gb__loss=deviance, gb__max_depth=2, gb__n_estimators=200 ........\n",
      "[CV]  gb__loss=deviance, gb__max_depth=2, gb__n_estimators=200, total=   0.4s\n",
      "[CV] gb__loss=deviance, gb__max_depth=3, gb__n_estimators=100 ........\n",
      "[CV]  gb__loss=deviance, gb__max_depth=3, gb__n_estimators=100, total=   0.3s\n",
      "[CV] gb__loss=deviance, gb__max_depth=3, gb__n_estimators=100 ........\n",
      "[CV]  gb__loss=deviance, gb__max_depth=3, gb__n_estimators=100, total=   0.2s\n",
      "[CV] gb__loss=deviance, gb__max_depth=3, gb__n_estimators=100 ........\n",
      "[CV]  gb__loss=deviance, gb__max_depth=3, gb__n_estimators=100, total=   0.3s\n",
      "[CV] gb__loss=deviance, gb__max_depth=3, gb__n_estimators=100 ........\n",
      "[CV]  gb__loss=deviance, gb__max_depth=3, gb__n_estimators=100, total=   0.3s\n",
      "[CV] gb__loss=deviance, gb__max_depth=3, gb__n_estimators=100 ........\n",
      "[CV]  gb__loss=deviance, gb__max_depth=3, gb__n_estimators=100, total=   0.3s\n",
      "[CV] gb__loss=deviance, gb__max_depth=3, gb__n_estimators=150 ........\n",
      "[CV]  gb__loss=deviance, gb__max_depth=3, gb__n_estimators=150, total=   0.4s\n",
      "[CV] gb__loss=deviance, gb__max_depth=3, gb__n_estimators=150 ........\n",
      "[CV]  gb__loss=deviance, gb__max_depth=3, gb__n_estimators=150, total=   0.4s\n",
      "[CV] gb__loss=deviance, gb__max_depth=3, gb__n_estimators=150 ........\n",
      "[CV]  gb__loss=deviance, gb__max_depth=3, gb__n_estimators=150, total=   0.3s\n",
      "[CV] gb__loss=deviance, gb__max_depth=3, gb__n_estimators=150 ........\n",
      "[CV]  gb__loss=deviance, gb__max_depth=3, gb__n_estimators=150, total=   0.3s\n",
      "[CV] gb__loss=deviance, gb__max_depth=3, gb__n_estimators=150 ........\n",
      "[CV]  gb__loss=deviance, gb__max_depth=3, gb__n_estimators=150, total=   0.3s\n",
      "[CV] gb__loss=deviance, gb__max_depth=3, gb__n_estimators=200 ........\n",
      "[CV]  gb__loss=deviance, gb__max_depth=3, gb__n_estimators=200, total=   0.4s\n",
      "[CV] gb__loss=deviance, gb__max_depth=3, gb__n_estimators=200 ........\n",
      "[CV]  gb__loss=deviance, gb__max_depth=3, gb__n_estimators=200, total=   0.4s\n",
      "[CV] gb__loss=deviance, gb__max_depth=3, gb__n_estimators=200 ........\n",
      "[CV]  gb__loss=deviance, gb__max_depth=3, gb__n_estimators=200, total=   0.5s\n",
      "[CV] gb__loss=deviance, gb__max_depth=3, gb__n_estimators=200 ........\n",
      "[CV]  gb__loss=deviance, gb__max_depth=3, gb__n_estimators=200, total=   0.5s\n",
      "[CV] gb__loss=deviance, gb__max_depth=3, gb__n_estimators=200 ........\n",
      "[CV]  gb__loss=deviance, gb__max_depth=3, gb__n_estimators=200, total=   0.6s\n",
      "[CV] gb__loss=deviance, gb__max_depth=4, gb__n_estimators=100 ........\n",
      "[CV]  gb__loss=deviance, gb__max_depth=4, gb__n_estimators=100, total=   0.4s\n",
      "[CV] gb__loss=deviance, gb__max_depth=4, gb__n_estimators=100 ........\n",
      "[CV]  gb__loss=deviance, gb__max_depth=4, gb__n_estimators=100, total=   0.4s\n",
      "[CV] gb__loss=deviance, gb__max_depth=4, gb__n_estimators=100 ........\n",
      "[CV]  gb__loss=deviance, gb__max_depth=4, gb__n_estimators=100, total=   0.4s\n",
      "[CV] gb__loss=deviance, gb__max_depth=4, gb__n_estimators=100 ........\n",
      "[CV]  gb__loss=deviance, gb__max_depth=4, gb__n_estimators=100, total=   0.4s\n",
      "[CV] gb__loss=deviance, gb__max_depth=4, gb__n_estimators=100 ........\n",
      "[CV]  gb__loss=deviance, gb__max_depth=4, gb__n_estimators=100, total=   0.4s\n",
      "[CV] gb__loss=deviance, gb__max_depth=4, gb__n_estimators=150 ........\n",
      "[CV]  gb__loss=deviance, gb__max_depth=4, gb__n_estimators=150, total=   0.4s\n",
      "[CV] gb__loss=deviance, gb__max_depth=4, gb__n_estimators=150 ........\n",
      "[CV]  gb__loss=deviance, gb__max_depth=4, gb__n_estimators=150, total=   0.8s\n",
      "[CV] gb__loss=deviance, gb__max_depth=4, gb__n_estimators=150 ........\n",
      "[CV]  gb__loss=deviance, gb__max_depth=4, gb__n_estimators=150, total=   0.7s\n",
      "[CV] gb__loss=deviance, gb__max_depth=4, gb__n_estimators=150 ........\n",
      "[CV]  gb__loss=deviance, gb__max_depth=4, gb__n_estimators=150, total=   0.5s\n",
      "[CV] gb__loss=deviance, gb__max_depth=4, gb__n_estimators=150 ........\n",
      "[CV]  gb__loss=deviance, gb__max_depth=4, gb__n_estimators=150, total=   0.5s\n",
      "[CV] gb__loss=deviance, gb__max_depth=4, gb__n_estimators=200 ........\n",
      "[CV]  gb__loss=deviance, gb__max_depth=4, gb__n_estimators=200, total=   0.7s\n",
      "[CV] gb__loss=deviance, gb__max_depth=4, gb__n_estimators=200 ........\n",
      "[CV]  gb__loss=deviance, gb__max_depth=4, gb__n_estimators=200, total=   0.5s\n",
      "[CV] gb__loss=deviance, gb__max_depth=4, gb__n_estimators=200 ........\n",
      "[CV]  gb__loss=deviance, gb__max_depth=4, gb__n_estimators=200, total=   0.8s\n",
      "[CV] gb__loss=deviance, gb__max_depth=4, gb__n_estimators=200 ........\n",
      "[CV]  gb__loss=deviance, gb__max_depth=4, gb__n_estimators=200, total=   0.7s\n",
      "[CV] gb__loss=deviance, gb__max_depth=4, gb__n_estimators=200 ........\n",
      "[CV]  gb__loss=deviance, gb__max_depth=4, gb__n_estimators=200, total=   0.7s\n",
      "[CV] gb__loss=exponencial, gb__max_depth=2, gb__n_estimators=100 .....\n",
      "[CV]  gb__loss=exponencial, gb__max_depth=2, gb__n_estimators=100, total=   0.0s\n",
      "[CV] gb__loss=exponencial, gb__max_depth=2, gb__n_estimators=100 .....\n",
      "[CV]  gb__loss=exponencial, gb__max_depth=2, gb__n_estimators=100, total=   0.0s\n",
      "[CV] gb__loss=exponencial, gb__max_depth=2, gb__n_estimators=100 .....\n",
      "[CV]  gb__loss=exponencial, gb__max_depth=2, gb__n_estimators=100, total=   0.0s\n",
      "[CV] gb__loss=exponencial, gb__max_depth=2, gb__n_estimators=100 .....\n",
      "[CV]  gb__loss=exponencial, gb__max_depth=2, gb__n_estimators=100, total=   0.0s\n",
      "[CV] gb__loss=exponencial, gb__max_depth=2, gb__n_estimators=100 .....\n",
      "[CV]  gb__loss=exponencial, gb__max_depth=2, gb__n_estimators=100, total=   0.0s\n",
      "[CV] gb__loss=exponencial, gb__max_depth=2, gb__n_estimators=150 .....\n",
      "[CV]  gb__loss=exponencial, gb__max_depth=2, gb__n_estimators=150, total=   0.0s\n",
      "[CV] gb__loss=exponencial, gb__max_depth=2, gb__n_estimators=150 .....\n",
      "[CV]  gb__loss=exponencial, gb__max_depth=2, gb__n_estimators=150, total=   0.0s\n",
      "[CV] gb__loss=exponencial, gb__max_depth=2, gb__n_estimators=150 .....\n",
      "[CV]  gb__loss=exponencial, gb__max_depth=2, gb__n_estimators=150, total=   0.0s\n",
      "[CV] gb__loss=exponencial, gb__max_depth=2, gb__n_estimators=150 .....\n",
      "[CV]  gb__loss=exponencial, gb__max_depth=2, gb__n_estimators=150, total=   0.0s\n",
      "[CV] gb__loss=exponencial, gb__max_depth=2, gb__n_estimators=150 .....\n",
      "[CV]  gb__loss=exponencial, gb__max_depth=2, gb__n_estimators=150, total=   0.0s\n",
      "[CV] gb__loss=exponencial, gb__max_depth=2, gb__n_estimators=200 .....\n",
      "[CV]  gb__loss=exponencial, gb__max_depth=2, gb__n_estimators=200, total=   0.0s\n",
      "[CV] gb__loss=exponencial, gb__max_depth=2, gb__n_estimators=200 .....\n",
      "[CV]  gb__loss=exponencial, gb__max_depth=2, gb__n_estimators=200, total=   0.0s\n",
      "[CV] gb__loss=exponencial, gb__max_depth=2, gb__n_estimators=200 .....\n",
      "[CV]  gb__loss=exponencial, gb__max_depth=2, gb__n_estimators=200, total=   0.0s\n",
      "[CV] gb__loss=exponencial, gb__max_depth=2, gb__n_estimators=200 .....\n",
      "[CV]  gb__loss=exponencial, gb__max_depth=2, gb__n_estimators=200, total=   0.0s\n",
      "[CV] gb__loss=exponencial, gb__max_depth=2, gb__n_estimators=200 .....\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV]  gb__loss=exponencial, gb__max_depth=2, gb__n_estimators=200, total=   0.0s\n",
      "[CV] gb__loss=exponencial, gb__max_depth=3, gb__n_estimators=100 .....\n",
      "[CV]  gb__loss=exponencial, gb__max_depth=3, gb__n_estimators=100, total=   0.0s\n",
      "[CV] gb__loss=exponencial, gb__max_depth=3, gb__n_estimators=100 .....\n",
      "[CV]  gb__loss=exponencial, gb__max_depth=3, gb__n_estimators=100, total=   0.0s\n",
      "[CV] gb__loss=exponencial, gb__max_depth=3, gb__n_estimators=100 .....\n",
      "[CV]  gb__loss=exponencial, gb__max_depth=3, gb__n_estimators=100, total=   0.0s\n",
      "[CV] gb__loss=exponencial, gb__max_depth=3, gb__n_estimators=100 .....\n",
      "[CV]  gb__loss=exponencial, gb__max_depth=3, gb__n_estimators=100, total=   0.0s\n",
      "[CV] gb__loss=exponencial, gb__max_depth=3, gb__n_estimators=100 .....\n",
      "[CV]  gb__loss=exponencial, gb__max_depth=3, gb__n_estimators=100, total=   0.0s\n",
      "[CV] gb__loss=exponencial, gb__max_depth=3, gb__n_estimators=150 .....\n",
      "[CV]  gb__loss=exponencial, gb__max_depth=3, gb__n_estimators=150, total=   0.0s\n",
      "[CV] gb__loss=exponencial, gb__max_depth=3, gb__n_estimators=150 .....\n",
      "[CV]  gb__loss=exponencial, gb__max_depth=3, gb__n_estimators=150, total=   0.0s\n",
      "[CV] gb__loss=exponencial, gb__max_depth=3, gb__n_estimators=150 .....\n",
      "[CV]  gb__loss=exponencial, gb__max_depth=3, gb__n_estimators=150, total=   0.0s\n",
      "[CV] gb__loss=exponencial, gb__max_depth=3, gb__n_estimators=150 .....\n",
      "[CV]  gb__loss=exponencial, gb__max_depth=3, gb__n_estimators=150, total=   0.1s\n",
      "[CV] gb__loss=exponencial, gb__max_depth=3, gb__n_estimators=150 .....\n",
      "[CV]  gb__loss=exponencial, gb__max_depth=3, gb__n_estimators=150, total=   0.0s\n",
      "[CV] gb__loss=exponencial, gb__max_depth=3, gb__n_estimators=200 .....\n",
      "[CV]  gb__loss=exponencial, gb__max_depth=3, gb__n_estimators=200, total=   0.0s\n",
      "[CV] gb__loss=exponencial, gb__max_depth=3, gb__n_estimators=200 .....\n",
      "[CV]  gb__loss=exponencial, gb__max_depth=3, gb__n_estimators=200, total=   0.0s\n",
      "[CV] gb__loss=exponencial, gb__max_depth=3, gb__n_estimators=200 .....\n",
      "[CV]  gb__loss=exponencial, gb__max_depth=3, gb__n_estimators=200, total=   0.0s\n",
      "[CV] gb__loss=exponencial, gb__max_depth=3, gb__n_estimators=200 .....\n",
      "[CV]  gb__loss=exponencial, gb__max_depth=3, gb__n_estimators=200, total=   0.0s\n",
      "[CV] gb__loss=exponencial, gb__max_depth=3, gb__n_estimators=200 .....\n",
      "[CV]  gb__loss=exponencial, gb__max_depth=3, gb__n_estimators=200, total=   0.0s\n",
      "[CV] gb__loss=exponencial, gb__max_depth=4, gb__n_estimators=100 .....\n",
      "[CV]  gb__loss=exponencial, gb__max_depth=4, gb__n_estimators=100, total=   0.0s\n",
      "[CV] gb__loss=exponencial, gb__max_depth=4, gb__n_estimators=100 .....\n",
      "[CV]  gb__loss=exponencial, gb__max_depth=4, gb__n_estimators=100, total=   0.0s\n",
      "[CV] gb__loss=exponencial, gb__max_depth=4, gb__n_estimators=100 .....\n",
      "[CV]  gb__loss=exponencial, gb__max_depth=4, gb__n_estimators=100, total=   0.0s\n",
      "[CV] gb__loss=exponencial, gb__max_depth=4, gb__n_estimators=100 .....\n",
      "[CV]  gb__loss=exponencial, gb__max_depth=4, gb__n_estimators=100, total=   0.1s\n",
      "[CV] gb__loss=exponencial, gb__max_depth=4, gb__n_estimators=100 .....\n",
      "[CV]  gb__loss=exponencial, gb__max_depth=4, gb__n_estimators=100, total=   0.1s\n",
      "[CV] gb__loss=exponencial, gb__max_depth=4, gb__n_estimators=150 .....\n",
      "[CV]  gb__loss=exponencial, gb__max_depth=4, gb__n_estimators=150, total=   0.1s\n",
      "[CV] gb__loss=exponencial, gb__max_depth=4, gb__n_estimators=150 .....\n",
      "[CV]  gb__loss=exponencial, gb__max_depth=4, gb__n_estimators=150, total=   0.0s\n",
      "[CV] gb__loss=exponencial, gb__max_depth=4, gb__n_estimators=150 .....\n",
      "[CV]  gb__loss=exponencial, gb__max_depth=4, gb__n_estimators=150, total=   0.0s\n",
      "[CV] gb__loss=exponencial, gb__max_depth=4, gb__n_estimators=150 .....\n",
      "[CV]  gb__loss=exponencial, gb__max_depth=4, gb__n_estimators=150, total=   0.0s\n",
      "[CV] gb__loss=exponencial, gb__max_depth=4, gb__n_estimators=150 .....\n",
      "[CV]  gb__loss=exponencial, gb__max_depth=4, gb__n_estimators=150, total=   0.0s\n",
      "[CV] gb__loss=exponencial, gb__max_depth=4, gb__n_estimators=200 .....\n",
      "[CV]  gb__loss=exponencial, gb__max_depth=4, gb__n_estimators=200, total=   0.0s\n",
      "[CV] gb__loss=exponencial, gb__max_depth=4, gb__n_estimators=200 .....\n",
      "[CV]  gb__loss=exponencial, gb__max_depth=4, gb__n_estimators=200, total=   0.0s\n",
      "[CV] gb__loss=exponencial, gb__max_depth=4, gb__n_estimators=200 .....\n",
      "[CV]  gb__loss=exponencial, gb__max_depth=4, gb__n_estimators=200, total=   0.1s\n",
      "[CV] gb__loss=exponencial, gb__max_depth=4, gb__n_estimators=200 .....\n",
      "[CV]  gb__loss=exponencial, gb__max_depth=4, gb__n_estimators=200, total=   0.0s\n",
      "[CV] gb__loss=exponencial, gb__max_depth=4, gb__n_estimators=200 .....\n",
      "[CV]  gb__loss=exponencial, gb__max_depth=4, gb__n_estimators=200, total=   0.1s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  90 out of  90 | elapsed:   20.5s finished\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Matriz de confusão do modelo nos dados de teste:\n",
      "\n",
      "[[ 15  45]\n",
      " [ 20 120]]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Matriz de confusão do modelo nos dados de teste:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.43      0.25      0.32        60\n",
      "        good       0.73      0.86      0.79       140\n",
      "\n",
      "    accuracy                           0.68       200\n",
      "   macro avg       0.58      0.55      0.55       200\n",
      "weighted avg       0.64      0.68      0.65       200\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-17T22:21:17.115639Z",
     "start_time": "2021-09-17T22:20:55.781568Z"
    },
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "grid_gb.best_params_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'gb__loss': 'deviance', 'gb__max_depth': 3, 'gb__n_estimators': 100}"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-17T22:21:17.131629Z",
     "start_time": "2021-09-17T22:21:17.121635Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pd.DataFrame(grid_gb.cv_results_).sort_values(\"rank_test_score\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_gb__loss</th>\n",
       "      <th>param_gb__max_depth</th>\n",
       "      <th>param_gb__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.276269</td>\n",
       "      <td>0.028813</td>\n",
       "      <td>0.019190</td>\n",
       "      <td>0.008227</td>\n",
       "      <td>deviance</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'gb__loss': 'deviance', 'gb__max_depth': 3, '...</td>\n",
       "      <td>0.686454</td>\n",
       "      <td>0.677714</td>\n",
       "      <td>0.724017</td>\n",
       "      <td>0.683214</td>\n",
       "      <td>0.695046</td>\n",
       "      <td>0.693289</td>\n",
       "      <td>0.016359</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.340167</td>\n",
       "      <td>0.047188</td>\n",
       "      <td>0.015789</td>\n",
       "      <td>0.002710</td>\n",
       "      <td>deviance</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>{'gb__loss': 'deviance', 'gb__max_depth': 3, '...</td>\n",
       "      <td>0.675004</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.700086</td>\n",
       "      <td>0.655069</td>\n",
       "      <td>0.714799</td>\n",
       "      <td>0.682325</td>\n",
       "      <td>0.021962</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.461474</td>\n",
       "      <td>0.053625</td>\n",
       "      <td>0.015192</td>\n",
       "      <td>0.008972</td>\n",
       "      <td>deviance</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>{'gb__loss': 'deviance', 'gb__max_depth': 3, '...</td>\n",
       "      <td>0.676009</td>\n",
       "      <td>0.675004</td>\n",
       "      <td>0.701534</td>\n",
       "      <td>0.637130</td>\n",
       "      <td>0.696413</td>\n",
       "      <td>0.677218</td>\n",
       "      <td>0.022686</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.262775</td>\n",
       "      <td>0.055869</td>\n",
       "      <td>0.018592</td>\n",
       "      <td>0.008705</td>\n",
       "      <td>deviance</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>{'gb__loss': 'deviance', 'gb__max_depth': 2, '...</td>\n",
       "      <td>0.706452</td>\n",
       "      <td>0.668820</td>\n",
       "      <td>0.678850</td>\n",
       "      <td>0.649587</td>\n",
       "      <td>0.663064</td>\n",
       "      <td>0.673354</td>\n",
       "      <td>0.019063</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.195889</td>\n",
       "      <td>0.014399</td>\n",
       "      <td>0.012993</td>\n",
       "      <td>0.002897</td>\n",
       "      <td>deviance</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'gb__loss': 'deviance', 'gb__max_depth': 2, '...</td>\n",
       "      <td>0.702979</td>\n",
       "      <td>0.659886</td>\n",
       "      <td>0.673438</td>\n",
       "      <td>0.655021</td>\n",
       "      <td>0.674057</td>\n",
       "      <td>0.673076</td>\n",
       "      <td>0.016705</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.362264</td>\n",
       "      <td>0.021987</td>\n",
       "      <td>0.018589</td>\n",
       "      <td>0.007860</td>\n",
       "      <td>deviance</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'gb__loss': 'deviance', 'gb__max_depth': 2, '...</td>\n",
       "      <td>0.696418</td>\n",
       "      <td>0.673651</td>\n",
       "      <td>0.674057</td>\n",
       "      <td>0.635208</td>\n",
       "      <td>0.685004</td>\n",
       "      <td>0.672868</td>\n",
       "      <td>0.020602</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.558935</td>\n",
       "      <td>0.149678</td>\n",
       "      <td>0.011994</td>\n",
       "      <td>0.000893</td>\n",
       "      <td>deviance</td>\n",
       "      <td>4</td>\n",
       "      <td>150</td>\n",
       "      <td>{'gb__loss': 'deviance', 'gb__max_depth': 4, '...</td>\n",
       "      <td>0.635138</td>\n",
       "      <td>0.675004</td>\n",
       "      <td>0.683214</td>\n",
       "      <td>0.660742</td>\n",
       "      <td>0.701534</td>\n",
       "      <td>0.671126</td>\n",
       "      <td>0.022310</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.384315</td>\n",
       "      <td>0.022473</td>\n",
       "      <td>0.014393</td>\n",
       "      <td>0.003006</td>\n",
       "      <td>deviance</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>{'gb__loss': 'deviance', 'gb__max_depth': 4, '...</td>\n",
       "      <td>0.632204</td>\n",
       "      <td>0.685004</td>\n",
       "      <td>0.709613</td>\n",
       "      <td>0.650089</td>\n",
       "      <td>0.671600</td>\n",
       "      <td>0.669702</td>\n",
       "      <td>0.026912</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.687778</td>\n",
       "      <td>0.092024</td>\n",
       "      <td>0.020589</td>\n",
       "      <td>0.003927</td>\n",
       "      <td>deviance</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>{'gb__loss': 'deviance', 'gb__max_depth': 4, '...</td>\n",
       "      <td>0.640358</td>\n",
       "      <td>0.665030</td>\n",
       "      <td>0.665030</td>\n",
       "      <td>0.652978</td>\n",
       "      <td>0.688269</td>\n",
       "      <td>0.662333</td>\n",
       "      <td>0.015860</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.035980</td>\n",
       "      <td>0.005827</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>exponencial</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'gb__loss': 'exponencial', 'gb__max_depth': 2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.005851</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>exponencial</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>{'gb__loss': 'exponencial', 'gb__max_depth': 2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.027186</td>\n",
       "      <td>0.006457</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>exponencial</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'gb__loss': 'exponencial', 'gb__max_depth': 2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.038746</td>\n",
       "      <td>0.006570</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>exponencial</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'gb__loss': 'exponencial', 'gb__max_depth': 3...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.034581</td>\n",
       "      <td>0.010244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>exponencial</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>{'gb__loss': 'exponencial', 'gb__max_depth': 3...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.031985</td>\n",
       "      <td>0.008873</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>exponencial</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>{'gb__loss': 'exponencial', 'gb__max_depth': 3...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.040978</td>\n",
       "      <td>0.015157</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>exponencial</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>{'gb__loss': 'exponencial', 'gb__max_depth': 4...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.035584</td>\n",
       "      <td>0.012807</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>exponencial</td>\n",
       "      <td>4</td>\n",
       "      <td>150</td>\n",
       "      <td>{'gb__loss': 'exponencial', 'gb__max_depth': 4...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.036979</td>\n",
       "      <td>0.013092</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>exponencial</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>{'gb__loss': 'exponencial', 'gb__max_depth': 4...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "3        0.276269      0.028813         0.019190        0.008227   \n",
       "4        0.340167      0.047188         0.015789        0.002710   \n",
       "5        0.461474      0.053625         0.015192        0.008972   \n",
       "1        0.262775      0.055869         0.018592        0.008705   \n",
       "0        0.195889      0.014399         0.012993        0.002897   \n",
       "2        0.362264      0.021987         0.018589        0.007860   \n",
       "7        0.558935      0.149678         0.011994        0.000893   \n",
       "6        0.384315      0.022473         0.014393        0.003006   \n",
       "8        0.687778      0.092024         0.020589        0.003927   \n",
       "9        0.035980      0.005827         0.000000        0.000000   \n",
       "10       0.038050      0.005851         0.000000        0.000000   \n",
       "11       0.027186      0.006457         0.000000        0.000000   \n",
       "12       0.038746      0.006570         0.000000        0.000000   \n",
       "13       0.034581      0.010244         0.000000        0.000000   \n",
       "14       0.031985      0.008873         0.000000        0.000000   \n",
       "15       0.040978      0.015157         0.000000        0.000000   \n",
       "16       0.035584      0.012807         0.000000        0.000000   \n",
       "17       0.036979      0.013092         0.000000        0.000000   \n",
       "\n",
       "   param_gb__loss param_gb__max_depth param_gb__n_estimators  \\\n",
       "3        deviance                   3                    100   \n",
       "4        deviance                   3                    150   \n",
       "5        deviance                   3                    200   \n",
       "1        deviance                   2                    150   \n",
       "0        deviance                   2                    100   \n",
       "2        deviance                   2                    200   \n",
       "7        deviance                   4                    150   \n",
       "6        deviance                   4                    100   \n",
       "8        deviance                   4                    200   \n",
       "9     exponencial                   2                    100   \n",
       "10    exponencial                   2                    150   \n",
       "11    exponencial                   2                    200   \n",
       "12    exponencial                   3                    100   \n",
       "13    exponencial                   3                    150   \n",
       "14    exponencial                   3                    200   \n",
       "15    exponencial                   4                    100   \n",
       "16    exponencial                   4                    150   \n",
       "17    exponencial                   4                    200   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "3   {'gb__loss': 'deviance', 'gb__max_depth': 3, '...           0.686454   \n",
       "4   {'gb__loss': 'deviance', 'gb__max_depth': 3, '...           0.675004   \n",
       "5   {'gb__loss': 'deviance', 'gb__max_depth': 3, '...           0.676009   \n",
       "1   {'gb__loss': 'deviance', 'gb__max_depth': 2, '...           0.706452   \n",
       "0   {'gb__loss': 'deviance', 'gb__max_depth': 2, '...           0.702979   \n",
       "2   {'gb__loss': 'deviance', 'gb__max_depth': 2, '...           0.696418   \n",
       "7   {'gb__loss': 'deviance', 'gb__max_depth': 4, '...           0.635138   \n",
       "6   {'gb__loss': 'deviance', 'gb__max_depth': 4, '...           0.632204   \n",
       "8   {'gb__loss': 'deviance', 'gb__max_depth': 4, '...           0.640358   \n",
       "9   {'gb__loss': 'exponencial', 'gb__max_depth': 2...                NaN   \n",
       "10  {'gb__loss': 'exponencial', 'gb__max_depth': 2...                NaN   \n",
       "11  {'gb__loss': 'exponencial', 'gb__max_depth': 2...                NaN   \n",
       "12  {'gb__loss': 'exponencial', 'gb__max_depth': 3...                NaN   \n",
       "13  {'gb__loss': 'exponencial', 'gb__max_depth': 3...                NaN   \n",
       "14  {'gb__loss': 'exponencial', 'gb__max_depth': 3...                NaN   \n",
       "15  {'gb__loss': 'exponencial', 'gb__max_depth': 4...                NaN   \n",
       "16  {'gb__loss': 'exponencial', 'gb__max_depth': 4...                NaN   \n",
       "17  {'gb__loss': 'exponencial', 'gb__max_depth': 4...                NaN   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "3            0.677714           0.724017           0.683214   \n",
       "4            0.666667           0.700086           0.655069   \n",
       "5            0.675004           0.701534           0.637130   \n",
       "1            0.668820           0.678850           0.649587   \n",
       "0            0.659886           0.673438           0.655021   \n",
       "2            0.673651           0.674057           0.635208   \n",
       "7            0.675004           0.683214           0.660742   \n",
       "6            0.685004           0.709613           0.650089   \n",
       "8            0.665030           0.665030           0.652978   \n",
       "9                 NaN                NaN                NaN   \n",
       "10                NaN                NaN                NaN   \n",
       "11                NaN                NaN                NaN   \n",
       "12                NaN                NaN                NaN   \n",
       "13                NaN                NaN                NaN   \n",
       "14                NaN                NaN                NaN   \n",
       "15                NaN                NaN                NaN   \n",
       "16                NaN                NaN                NaN   \n",
       "17                NaN                NaN                NaN   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "3            0.695046         0.693289        0.016359                1  \n",
       "4            0.714799         0.682325        0.021962                2  \n",
       "5            0.696413         0.677218        0.022686                3  \n",
       "1            0.663064         0.673354        0.019063                4  \n",
       "0            0.674057         0.673076        0.016705                5  \n",
       "2            0.685004         0.672868        0.020602                6  \n",
       "7            0.701534         0.671126        0.022310                7  \n",
       "6            0.671600         0.669702        0.026912                8  \n",
       "8            0.688269         0.662333        0.015860                9  \n",
       "9                 NaN              NaN             NaN               10  \n",
       "10                NaN              NaN             NaN               11  \n",
       "11                NaN              NaN             NaN               12  \n",
       "12                NaN              NaN             NaN               13  \n",
       "13                NaN              NaN             NaN               14  \n",
       "14                NaN              NaN             NaN               15  \n",
       "15                NaN              NaN             NaN               16  \n",
       "16                NaN              NaN             NaN               17  \n",
       "17                NaN              NaN             NaN               18  "
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-17T22:21:28.946206Z",
     "start_time": "2021-09-17T22:21:28.858257Z"
    },
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "_________\n",
    "_______\n",
    "_________"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5) XGBoost\n",
    "\n",
    "Chegamos ao nosso último método de ensemble, o XGBoost (e**X**treme **G**radient **Boost**ing).\n",
    "\n",
    "Este método nada mais é que um gradient boosting, mas com algumas importantes modificações que lhe conferem o título de \"extreme\"! Em particular, duas alterações merecem destaque:\n",
    "\n",
    "- A adição de procedimentos de regularização (L1 e L2!), o que melhora consideravelmente sua capacidade de generalização;\n",
    "\n",
    "- A utilização de derivadas de segunda ordem (Hessiano) para o procedimento de gradiente.\n",
    "\n",
    "Para quem quiser se aventurar mais, sugiro algumas boas leituras:\n",
    "\n",
    "- [Este](https://shirinsplayground.netlify.app/2018/11/ml_basics_gbm/), explica bem as particularidades do XGBoost, além de dar uma boa introdução ao gradient boosting (o código é em R, então pode ignorar essa parte hehe);\n",
    "\n",
    "- [Este](https://medium.com/analytics-vidhya/what-makes-xgboost-so-extreme-e1544a4433bb), introduz bem o método, enquanto enfativa suas particularidades, com alguns detalhes matemáticos;\n",
    "\n",
    "- [Este](https://xgboost.readthedocs.io/en/latest/tutorials/model.html), da própria documentação da biblioteca, traz uma explicação legal, e com alguns detalhes matemáticos;\n",
    "\n",
    "- [Este](https://towardsdatascience.com/https-medium-com-vishalmorde-xgboost-algorithm-long-she-may-rein-edd9f99be63d), com uma discussão mais alto-nível (sem tantos detalhes) sobre o XGBoost e os motivos de seu sucesso."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Infelizmente, o sklearn não tem o XGBoost implementado :(\n",
    "\n",
    "Mas, felizmente, existe uma biblioteca que o implementou, de maneira totalmente integrada ao sklearn!!\n",
    "\n",
    "A biblioteca é a [XGBoost](https://xgboost.readthedocs.io/en/latest/).\n",
    "\n",
    "Para instalar a biblioteca, o de sempre:\n",
    "\n",
    "`!pip install xgboost`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# xgboost baseline\n",
    "\n",
    "df = pd.read_csv('../datasets/german_credit_data.csv', index_col=0)\n",
    "\n",
    "# dropando NaNs e features categóricas\n",
    "df_aux = df.dropna().select_dtypes(include=np.number)\n",
    "df = pd.concat([df_aux, df.dropna()[\"Risk\"]], axis=1)          \n",
    "\n",
    "X = df.drop(columns=\"Risk\")\n",
    "y = df[\"Risk\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "estimador = XGBClassifier(random_state=42)\n",
    "\n",
    "# to-do: implemente o cross_validate\n",
    "modelo = estimador.fit(X_train, y_train)\n",
    "\n",
    "y_pred = modelo.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, plot_confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "plot_confusion_matrix(modelo, X_test, y_test)\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[19:43:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[[27 19]\n",
      " [12 47]]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.69      0.59      0.64        46\n",
      "        good       0.71      0.80      0.75        59\n",
      "\n",
      "    accuracy                           0.70       105\n",
      "   macro avg       0.70      0.69      0.69       105\n",
      "weighted avg       0.70      0.70      0.70       105\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-17T22:43:25.665170Z",
     "start_time": "2021-09-17T22:43:17.708203Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# gridsearch - PRA CASA\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "interpreter": {
   "hash": "e922dd073470bdcc017ae3abd31d6491d6ed7bf31c1d559806e5511bfea88b81"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}