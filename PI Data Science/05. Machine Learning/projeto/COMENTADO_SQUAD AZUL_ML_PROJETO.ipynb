{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue><b>\n",
    "Mandaram super bem, pessoal! Parabéns!!!\n",
    "    \n",
    "Vejam abaixo meus comentários :)\n",
    "    \n",
    "Nota: 9.8/10\n",
    "</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQUAD AZUL #\n",
    "\n",
    "<font size=4>Lets Code - Projeto da disciplina de Machine Learning\n",
    "\n",
    "<font size=4>Autores: Victor Cattani, Martin Lietz e Bruno Ary\n",
    "    \n",
    "08/10/21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder,MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from skopt import gp_minimize\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "path = os.getcwd()\n",
    "\n",
    "df_train = pd.read_csv(path+\"\\\\\"+\"credito-imoveis\"+\n",
    "                       \"\\\\\"+\"application_train.csv\", sep=\",\")\n",
    "\n",
    "df_teste = pd.read_csv(path+\"\\\\\"+\"credito-imoveis\"+\n",
    "                       \"\\\\\"+\"application_test_student.csv\", sep=\",\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamento da Base de Dados e Feature Engineering\n",
    "\n",
    "<font size=4>As próximas células apresentam processos associados ao tratamento da bases de dados e derivação de novos parâmetros. \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4> Em um primeiro momento, é feita a derivação de algumas variáveis, dentre elas:\n",
    "    \n",
    "    - Taxas relacionadas à receita de cada cliente.\n",
    "    - Tempo empregado\n",
    "    - Número de adultos e crianças na família\n",
    "    - Parâmetros estatísticos associados às pontuações externas de cada cliente.\n",
    "    - Número de documentos\n",
    "    - Diferenciação dos dias de aplicação entre dias de semana e final de semana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FEATURE ENGINEERINNG\n",
    "\n",
    "## taxas de receita --- Treinamento e Teste\n",
    "df_train[\"credito_receita\"] = df_train[\"AMT_CREDIT\"]/df_train[\"AMT_INCOME_TOTAL\"]\n",
    "df_train[\"anuidade_receita\"] = df_train[\"AMT_ANNUITY\"]/df_train[\"AMT_INCOME_TOTAL\"]\n",
    "df_train[\"bens_receita\"] = df_train[\"AMT_GOODS_PRICE\"] / df_train[\"AMT_INCOME_TOTAL\"]\n",
    "df_train[\"receita_pessoa\"] = df_train[\"AMT_INCOME_TOTAL\"] / df_train[\"CNT_FAM_MEMBERS\"]\n",
    "\n",
    "df_teste[\"credito_receita\"] = df_teste[\"AMT_CREDIT\"]/df_teste[\"AMT_INCOME_TOTAL\"]\n",
    "df_teste[\"anuidade_receita\"] = df_teste[\"AMT_ANNUITY\"]/df_teste[\"AMT_INCOME_TOTAL\"]\n",
    "df_teste[\"bens_receita\"] = df_teste[\"AMT_GOODS_PRICE\"] / df_teste[\"AMT_INCOME_TOTAL\"]\n",
    "df_teste[\"receita_pessoa\"] = df_teste[\"AMT_INCOME_TOTAL\"] / df_teste[\"CNT_FAM_MEMBERS\"]\n",
    "\n",
    "\n",
    "# tempo percetual empregado -- Treinamento e Teste\n",
    "df_train[\"tempo_empregado_percent\"] = df_train[\"DAYS_EMPLOYED\"] / df_train[\"DAYS_BIRTH\"]\n",
    "df_train[\"tempo_empregado_percent\"][df_train[\"tempo_empregado_percent\"] < 0] = None\n",
    "\n",
    "df_teste[\"tempo_empregado_percent\"] = df_teste[\"DAYS_EMPLOYED\"] / df_teste[\"DAYS_BIRTH\"]\n",
    "df_teste[\"tempo_empregado_percent\"][df_teste[\"tempo_empregado_percent\"] < 0] = None\n",
    "\n",
    "\n",
    "# número de adutlos --- Treinamento e Teste\n",
    "df_train[\"num_adultos\"] = df_train[\"CNT_FAM_MEMBERS\"] - df_train[\"CNT_CHILDREN\"]\n",
    "df_train['tax_kid'] = df_train['CNT_CHILDREN'] / df_train['CNT_FAM_MEMBERS']\n",
    "\n",
    "df_teste[\"num_adultos\"] = df_teste[\"CNT_FAM_MEMBERS\"] - df_teste[\"CNT_CHILDREN\"]\n",
    "df_teste['tax_kid'] = df_teste['CNT_CHILDREN'] / df_teste['CNT_FAM_MEMBERS']\n",
    "\n",
    "# number of overall payments -- Treinamento e Teste\n",
    "df_train['ANNUITY LENGTH'] = df_train['AMT_CREDIT'] / df_train['AMT_ANNUITY']\n",
    "\n",
    "df_teste['ANNUITY LENGTH'] = df_train['AMT_CREDIT'] / df_train['AMT_ANNUITY']\n",
    "\n",
    "# Recursos Externos -- Treinamento e Teste\n",
    "df_train[\"EXT_SOURCE_MIN\"]  = df_train[[\"EXT_SOURCE_1\", \"EXT_SOURCE_2\", \"EXT_SOURCE_3\"]].min(axis = 1)\n",
    "df_train[\"EXT_SOURCE_MAX\"]  = df_train[[\"EXT_SOURCE_1\", \"EXT_SOURCE_2\", \"EXT_SOURCE_3\"]].max(axis = 1)\n",
    "df_train[\"EXT_SOURCE_MEAN\"] = df_train[[\"EXT_SOURCE_1\", \"EXT_SOURCE_2\", \"EXT_SOURCE_3\"]].mean(axis = 1)\n",
    "df_train[\"EXT_SOURCE_SD\"]   = df_train[[\"EXT_SOURCE_1\", \"EXT_SOURCE_2\", \"EXT_SOURCE_3\"]].std(axis = 1)\n",
    "df_train[\"NUM_EXT_SOURCES\"] = 3 - (df_train[\"EXT_SOURCE_1\"].isnull().astype(int) +\n",
    "                               df_train[\"EXT_SOURCE_2\"].isnull().astype(int) +\n",
    "                               df_train[\"EXT_SOURCE_3\"].isnull().astype(int))\n",
    "\n",
    "df_teste[\"EXT_SOURCE_MIN\"]  = df_teste[[\"EXT_SOURCE_1\", \"EXT_SOURCE_2\", \"EXT_SOURCE_3\"]].min(axis = 1)\n",
    "df_teste[\"EXT_SOURCE_MAX\"]  = df_teste[[\"EXT_SOURCE_1\", \"EXT_SOURCE_2\", \"EXT_SOURCE_3\"]].max(axis = 1)\n",
    "df_teste[\"EXT_SOURCE_MEAN\"] = df_teste[[\"EXT_SOURCE_1\", \"EXT_SOURCE_2\", \"EXT_SOURCE_3\"]].mean(axis = 1)\n",
    "df_teste[\"EXT_SOURCE_SD\"]   = df_teste[[\"EXT_SOURCE_1\", \"EXT_SOURCE_2\", \"EXT_SOURCE_3\"]].std(axis = 1)\n",
    "df_teste[\"NUM_EXT_SOURCES\"] = 3 - (df_teste[\"EXT_SOURCE_1\"].isnull().astype(int) +\n",
    "                               df_teste[\"EXT_SOURCE_2\"].isnull().astype(int) +\n",
    "                               df_teste[\"EXT_SOURCE_3\"].isnull().astype(int))\n",
    "\n",
    "# Número de documentos -- Treinamento e Teste\n",
    "doc_vars = [\"FLAG_DOCUMENT_2\",  \"FLAG_DOCUMENT_3\",  \"FLAG_DOCUMENT_4\",  \"FLAG_DOCUMENT_5\",  \"FLAG_DOCUMENT_6\",\n",
    "            \"FLAG_DOCUMENT_7\",  \"FLAG_DOCUMENT_8\",  \"FLAG_DOCUMENT_9\",  \"FLAG_DOCUMENT_10\", \"FLAG_DOCUMENT_11\",\n",
    "            \"FLAG_DOCUMENT_12\", \"FLAG_DOCUMENT_13\", \"FLAG_DOCUMENT_14\", \"FLAG_DOCUMENT_15\", \"FLAG_DOCUMENT_16\",\n",
    "            \"FLAG_DOCUMENT_17\", \"FLAG_DOCUMENT_18\", \"FLAG_DOCUMENT_19\", \"FLAG_DOCUMENT_20\", \"FLAG_DOCUMENT_21\"]\n",
    "df_train[\"NUM_DOCUMENTS\"] = df_train[doc_vars].sum(axis = 1)\n",
    "\n",
    "df_teste[\"NUM_DOCUMENTS\"] = df_teste[doc_vars].sum(axis = 1)\n",
    "\n",
    "# Data De aplicação -- Treinamento e Teste\n",
    "df_train[\"DAY_APPR_PROCESS_START\"] = \"Working day\"\n",
    "df_train[\"DAY_APPR_PROCESS_START\"][(df_train[\"WEEKDAY_APPR_PROCESS_START\"] == \"SATURDAY\") |\n",
    "                               (df_train[\"WEEKDAY_APPR_PROCESS_START\"] == \"SUNDAY\")] = \"Weekend\"\n",
    "\n",
    "df_teste[\"DAY_APPR_PROCESS_START\"] = \"Working day\"\n",
    "df_teste[\"DAY_APPR_PROCESS_START\"][(df_teste[\"WEEKDAY_APPR_PROCESS_START\"] == \"SATURDAY\") |\n",
    "                               (df_teste[\"WEEKDAY_APPR_PROCESS_START\"] == \"SUNDAY\")] = \"Weekend\"\n",
    "\n",
    "df_train[\"DAY_APPR_PROCESS_START\"].astype('category')\n",
    "df_teste[\"DAY_APPR_PROCESS_START\"].astype('category')\n",
    "\n",
    "# age ratios\n",
    "df_train[\"OWN_CAR_AGE_RATIO\"] = df_train[\"OWN_CAR_AGE\"] / df_train[\"DAYS_BIRTH\"]\n",
    "df_train[\"DAYS_ID_PUBLISHED_RATIO\"] = df_train[\"DAYS_ID_PUBLISH\"] / df_train[\"DAYS_BIRTH\"]\n",
    "df_train[\"DAYS_REGISTRATION_RATIO\"] = df_train[\"DAYS_REGISTRATION\"] / df_train[\"DAYS_BIRTH\"]\n",
    "\n",
    "df_teste[\"OWN_CAR_AGE_RATIO\"] = df_teste[\"OWN_CAR_AGE\"] / df_teste[\"DAYS_BIRTH\"]\n",
    "df_teste[\"DAYS_ID_PUBLISHED_RATIO\"] = df_teste[\"DAYS_ID_PUBLISH\"] / df_teste[\"DAYS_BIRTH\"]\n",
    "df_teste[\"DAYS_REGISTRATION_RATIO\"] = df_teste[\"DAYS_REGISTRATION\"] / df_teste[\"DAYS_BIRTH\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue><b>\n",
    "Isso ae, galera! Curti bastaaante o trabalho de feature engineering que vcs fizeram!\n",
    "    \n",
    "E parabéns por já terem criado as features na base de teste também -- isso é fundamental! Sem isso, naturalmente o modelo não funcionaria na base de teste!\n",
    "\n",
    "<br>\n",
    "Como vcs fizeram está perfeito! Eu apenas sugeriria que vocês colocassem tudo em uma função genérica, que cria as novas features pra qualquer df, e aí vcs aplicam esta mesma função às bases de treino e teste separadamente. Assim, fica mais com cara de uma Pipeline ;)\n",
    "    \n",
    "E, falando em Pipeline, também é possível adicionar o processo de feature engineering à uma Pipeline propriamente dita, o que garante ainda maior robustez! Para isso, sugiro que vcs deem uma olhadinha no [FeatureUnion](https://scikit-learn.org/stable/modules/compose.html#feature-union)\n",
    "</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 246008 entries, 0 to 246007\n",
      "Data columns (total 140 columns):\n",
      " #    Column                        Dtype  \n",
      "---   ------                        -----  \n",
      " 0    SK_ID_CURR                    int64  \n",
      " 1    TARGET                        int64  \n",
      " 2    NAME_CONTRACT_TYPE            object \n",
      " 3    CODE_GENDER                   object \n",
      " 4    FLAG_OWN_CAR                  object \n",
      " 5    FLAG_OWN_REALTY               object \n",
      " 6    CNT_CHILDREN                  int64  \n",
      " 7    AMT_INCOME_TOTAL              float64\n",
      " 8    AMT_CREDIT                    float64\n",
      " 9    AMT_ANNUITY                   float64\n",
      " 10   AMT_GOODS_PRICE               float64\n",
      " 11   NAME_TYPE_SUITE               object \n",
      " 12   NAME_INCOME_TYPE              object \n",
      " 13   NAME_EDUCATION_TYPE           object \n",
      " 14   NAME_FAMILY_STATUS            object \n",
      " 15   NAME_HOUSING_TYPE             object \n",
      " 16   REGION_POPULATION_RELATIVE    float64\n",
      " 17   DAYS_BIRTH                    int64  \n",
      " 18   DAYS_EMPLOYED                 int64  \n",
      " 19   DAYS_REGISTRATION             float64\n",
      " 20   DAYS_ID_PUBLISH               int64  \n",
      " 21   OWN_CAR_AGE                   float64\n",
      " 22   FLAG_MOBIL                    int64  \n",
      " 23   FLAG_EMP_PHONE                int64  \n",
      " 24   FLAG_WORK_PHONE               int64  \n",
      " 25   FLAG_CONT_MOBILE              int64  \n",
      " 26   FLAG_PHONE                    int64  \n",
      " 27   FLAG_EMAIL                    int64  \n",
      " 28   OCCUPATION_TYPE               object \n",
      " 29   CNT_FAM_MEMBERS               float64\n",
      " 30   REGION_RATING_CLIENT          int64  \n",
      " 31   REGION_RATING_CLIENT_W_CITY   int64  \n",
      " 32   WEEKDAY_APPR_PROCESS_START    object \n",
      " 33   HOUR_APPR_PROCESS_START       int64  \n",
      " 34   REG_REGION_NOT_LIVE_REGION    int64  \n",
      " 35   REG_REGION_NOT_WORK_REGION    int64  \n",
      " 36   LIVE_REGION_NOT_WORK_REGION   int64  \n",
      " 37   REG_CITY_NOT_LIVE_CITY        int64  \n",
      " 38   REG_CITY_NOT_WORK_CITY        int64  \n",
      " 39   LIVE_CITY_NOT_WORK_CITY       int64  \n",
      " 40   ORGANIZATION_TYPE             object \n",
      " 41   EXT_SOURCE_1                  float64\n",
      " 42   EXT_SOURCE_2                  float64\n",
      " 43   EXT_SOURCE_3                  float64\n",
      " 44   APARTMENTS_AVG                float64\n",
      " 45   BASEMENTAREA_AVG              float64\n",
      " 46   YEARS_BEGINEXPLUATATION_AVG   float64\n",
      " 47   YEARS_BUILD_AVG               float64\n",
      " 48   COMMONAREA_AVG                float64\n",
      " 49   ELEVATORS_AVG                 float64\n",
      " 50   ENTRANCES_AVG                 float64\n",
      " 51   FLOORSMAX_AVG                 float64\n",
      " 52   FLOORSMIN_AVG                 float64\n",
      " 53   LANDAREA_AVG                  float64\n",
      " 54   LIVINGAPARTMENTS_AVG          float64\n",
      " 55   LIVINGAREA_AVG                float64\n",
      " 56   NONLIVINGAPARTMENTS_AVG       float64\n",
      " 57   NONLIVINGAREA_AVG             float64\n",
      " 58   APARTMENTS_MODE               float64\n",
      " 59   BASEMENTAREA_MODE             float64\n",
      " 60   YEARS_BEGINEXPLUATATION_MODE  float64\n",
      " 61   YEARS_BUILD_MODE              float64\n",
      " 62   COMMONAREA_MODE               float64\n",
      " 63   ELEVATORS_MODE                float64\n",
      " 64   ENTRANCES_MODE                float64\n",
      " 65   FLOORSMAX_MODE                float64\n",
      " 66   FLOORSMIN_MODE                float64\n",
      " 67   LANDAREA_MODE                 float64\n",
      " 68   LIVINGAPARTMENTS_MODE         float64\n",
      " 69   LIVINGAREA_MODE               float64\n",
      " 70   NONLIVINGAPARTMENTS_MODE      float64\n",
      " 71   NONLIVINGAREA_MODE            float64\n",
      " 72   APARTMENTS_MEDI               float64\n",
      " 73   BASEMENTAREA_MEDI             float64\n",
      " 74   YEARS_BEGINEXPLUATATION_MEDI  float64\n",
      " 75   YEARS_BUILD_MEDI              float64\n",
      " 76   COMMONAREA_MEDI               float64\n",
      " 77   ELEVATORS_MEDI                float64\n",
      " 78   ENTRANCES_MEDI                float64\n",
      " 79   FLOORSMAX_MEDI                float64\n",
      " 80   FLOORSMIN_MEDI                float64\n",
      " 81   LANDAREA_MEDI                 float64\n",
      " 82   LIVINGAPARTMENTS_MEDI         float64\n",
      " 83   LIVINGAREA_MEDI               float64\n",
      " 84   NONLIVINGAPARTMENTS_MEDI      float64\n",
      " 85   NONLIVINGAREA_MEDI            float64\n",
      " 86   FONDKAPREMONT_MODE            object \n",
      " 87   HOUSETYPE_MODE                object \n",
      " 88   TOTALAREA_MODE                float64\n",
      " 89   WALLSMATERIAL_MODE            object \n",
      " 90   EMERGENCYSTATE_MODE           object \n",
      " 91   OBS_30_CNT_SOCIAL_CIRCLE      float64\n",
      " 92   DEF_30_CNT_SOCIAL_CIRCLE      float64\n",
      " 93   OBS_60_CNT_SOCIAL_CIRCLE      float64\n",
      " 94   DEF_60_CNT_SOCIAL_CIRCLE      float64\n",
      " 95   DAYS_LAST_PHONE_CHANGE        float64\n",
      " 96   FLAG_DOCUMENT_2               int64  \n",
      " 97   FLAG_DOCUMENT_3               int64  \n",
      " 98   FLAG_DOCUMENT_4               int64  \n",
      " 99   FLAG_DOCUMENT_5               int64  \n",
      " 100  FLAG_DOCUMENT_6               int64  \n",
      " 101  FLAG_DOCUMENT_7               int64  \n",
      " 102  FLAG_DOCUMENT_8               int64  \n",
      " 103  FLAG_DOCUMENT_9               int64  \n",
      " 104  FLAG_DOCUMENT_10              int64  \n",
      " 105  FLAG_DOCUMENT_11              int64  \n",
      " 106  FLAG_DOCUMENT_12              int64  \n",
      " 107  FLAG_DOCUMENT_13              int64  \n",
      " 108  FLAG_DOCUMENT_14              int64  \n",
      " 109  FLAG_DOCUMENT_15              int64  \n",
      " 110  FLAG_DOCUMENT_16              int64  \n",
      " 111  FLAG_DOCUMENT_17              int64  \n",
      " 112  FLAG_DOCUMENT_18              int64  \n",
      " 113  FLAG_DOCUMENT_19              int64  \n",
      " 114  FLAG_DOCUMENT_20              int64  \n",
      " 115  FLAG_DOCUMENT_21              int64  \n",
      " 116  AMT_REQ_CREDIT_BUREAU_HOUR    float64\n",
      " 117  AMT_REQ_CREDIT_BUREAU_DAY     float64\n",
      " 118  AMT_REQ_CREDIT_BUREAU_WEEK    float64\n",
      " 119  AMT_REQ_CREDIT_BUREAU_MON     float64\n",
      " 120  AMT_REQ_CREDIT_BUREAU_QRT     float64\n",
      " 121  AMT_REQ_CREDIT_BUREAU_YEAR    float64\n",
      " 122  credito_receita               float64\n",
      " 123  anuidade_receita              float64\n",
      " 124  bens_receita                  float64\n",
      " 125  receita_pessoa                float64\n",
      " 126  tempo_empregado_percent       float64\n",
      " 127  num_adultos                   float64\n",
      " 128  tax_kid                       float64\n",
      " 129  ANNUITY LENGTH                float64\n",
      " 130  EXT_SOURCE_MIN                float64\n",
      " 131  EXT_SOURCE_MAX                float64\n",
      " 132  EXT_SOURCE_MEAN               float64\n",
      " 133  EXT_SOURCE_SD                 float64\n",
      " 134  NUM_EXT_SOURCES               int32  \n",
      " 135  NUM_DOCUMENTS                 int64  \n",
      " 136  DAY_APPR_PROCESS_START        object \n",
      " 137  OWN_CAR_AGE_RATIO             float64\n",
      " 138  DAYS_ID_PUBLISHED_RATIO       float64\n",
      " 139  DAYS_REGISTRATION_RATIO       float64\n",
      "dtypes: float64(80), int32(1), int64(42), object(17)\n",
      "memory usage: 261.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 61503 entries, 0 to 61502\n",
      "Data columns (total 139 columns):\n",
      " #    Column                        Dtype  \n",
      "---   ------                        -----  \n",
      " 0    SK_ID_CURR                    int64  \n",
      " 1    NAME_CONTRACT_TYPE            object \n",
      " 2    CODE_GENDER                   object \n",
      " 3    FLAG_OWN_CAR                  object \n",
      " 4    FLAG_OWN_REALTY               object \n",
      " 5    CNT_CHILDREN                  int64  \n",
      " 6    AMT_INCOME_TOTAL              float64\n",
      " 7    AMT_CREDIT                    float64\n",
      " 8    AMT_ANNUITY                   float64\n",
      " 9    AMT_GOODS_PRICE               float64\n",
      " 10   NAME_TYPE_SUITE               object \n",
      " 11   NAME_INCOME_TYPE              object \n",
      " 12   NAME_EDUCATION_TYPE           object \n",
      " 13   NAME_FAMILY_STATUS            object \n",
      " 14   NAME_HOUSING_TYPE             object \n",
      " 15   REGION_POPULATION_RELATIVE    float64\n",
      " 16   DAYS_BIRTH                    int64  \n",
      " 17   DAYS_EMPLOYED                 int64  \n",
      " 18   DAYS_REGISTRATION             float64\n",
      " 19   DAYS_ID_PUBLISH               int64  \n",
      " 20   OWN_CAR_AGE                   float64\n",
      " 21   FLAG_MOBIL                    int64  \n",
      " 22   FLAG_EMP_PHONE                int64  \n",
      " 23   FLAG_WORK_PHONE               int64  \n",
      " 24   FLAG_CONT_MOBILE              int64  \n",
      " 25   FLAG_PHONE                    int64  \n",
      " 26   FLAG_EMAIL                    int64  \n",
      " 27   OCCUPATION_TYPE               object \n",
      " 28   CNT_FAM_MEMBERS               float64\n",
      " 29   REGION_RATING_CLIENT          int64  \n",
      " 30   REGION_RATING_CLIENT_W_CITY   int64  \n",
      " 31   WEEKDAY_APPR_PROCESS_START    object \n",
      " 32   HOUR_APPR_PROCESS_START       int64  \n",
      " 33   REG_REGION_NOT_LIVE_REGION    int64  \n",
      " 34   REG_REGION_NOT_WORK_REGION    int64  \n",
      " 35   LIVE_REGION_NOT_WORK_REGION   int64  \n",
      " 36   REG_CITY_NOT_LIVE_CITY        int64  \n",
      " 37   REG_CITY_NOT_WORK_CITY        int64  \n",
      " 38   LIVE_CITY_NOT_WORK_CITY       int64  \n",
      " 39   ORGANIZATION_TYPE             object \n",
      " 40   EXT_SOURCE_1                  float64\n",
      " 41   EXT_SOURCE_2                  float64\n",
      " 42   EXT_SOURCE_3                  float64\n",
      " 43   APARTMENTS_AVG                float64\n",
      " 44   BASEMENTAREA_AVG              float64\n",
      " 45   YEARS_BEGINEXPLUATATION_AVG   float64\n",
      " 46   YEARS_BUILD_AVG               float64\n",
      " 47   COMMONAREA_AVG                float64\n",
      " 48   ELEVATORS_AVG                 float64\n",
      " 49   ENTRANCES_AVG                 float64\n",
      " 50   FLOORSMAX_AVG                 float64\n",
      " 51   FLOORSMIN_AVG                 float64\n",
      " 52   LANDAREA_AVG                  float64\n",
      " 53   LIVINGAPARTMENTS_AVG          float64\n",
      " 54   LIVINGAREA_AVG                float64\n",
      " 55   NONLIVINGAPARTMENTS_AVG       float64\n",
      " 56   NONLIVINGAREA_AVG             float64\n",
      " 57   APARTMENTS_MODE               float64\n",
      " 58   BASEMENTAREA_MODE             float64\n",
      " 59   YEARS_BEGINEXPLUATATION_MODE  float64\n",
      " 60   YEARS_BUILD_MODE              float64\n",
      " 61   COMMONAREA_MODE               float64\n",
      " 62   ELEVATORS_MODE                float64\n",
      " 63   ENTRANCES_MODE                float64\n",
      " 64   FLOORSMAX_MODE                float64\n",
      " 65   FLOORSMIN_MODE                float64\n",
      " 66   LANDAREA_MODE                 float64\n",
      " 67   LIVINGAPARTMENTS_MODE         float64\n",
      " 68   LIVINGAREA_MODE               float64\n",
      " 69   NONLIVINGAPARTMENTS_MODE      float64\n",
      " 70   NONLIVINGAREA_MODE            float64\n",
      " 71   APARTMENTS_MEDI               float64\n",
      " 72   BASEMENTAREA_MEDI             float64\n",
      " 73   YEARS_BEGINEXPLUATATION_MEDI  float64\n",
      " 74   YEARS_BUILD_MEDI              float64\n",
      " 75   COMMONAREA_MEDI               float64\n",
      " 76   ELEVATORS_MEDI                float64\n",
      " 77   ENTRANCES_MEDI                float64\n",
      " 78   FLOORSMAX_MEDI                float64\n",
      " 79   FLOORSMIN_MEDI                float64\n",
      " 80   LANDAREA_MEDI                 float64\n",
      " 81   LIVINGAPARTMENTS_MEDI         float64\n",
      " 82   LIVINGAREA_MEDI               float64\n",
      " 83   NONLIVINGAPARTMENTS_MEDI      float64\n",
      " 84   NONLIVINGAREA_MEDI            float64\n",
      " 85   FONDKAPREMONT_MODE            object \n",
      " 86   HOUSETYPE_MODE                object \n",
      " 87   TOTALAREA_MODE                float64\n",
      " 88   WALLSMATERIAL_MODE            object \n",
      " 89   EMERGENCYSTATE_MODE           object \n",
      " 90   OBS_30_CNT_SOCIAL_CIRCLE      float64\n",
      " 91   DEF_30_CNT_SOCIAL_CIRCLE      float64\n",
      " 92   OBS_60_CNT_SOCIAL_CIRCLE      float64\n",
      " 93   DEF_60_CNT_SOCIAL_CIRCLE      float64\n",
      " 94   DAYS_LAST_PHONE_CHANGE        float64\n",
      " 95   FLAG_DOCUMENT_2               int64  \n",
      " 96   FLAG_DOCUMENT_3               int64  \n",
      " 97   FLAG_DOCUMENT_4               int64  \n",
      " 98   FLAG_DOCUMENT_5               int64  \n",
      " 99   FLAG_DOCUMENT_6               int64  \n",
      " 100  FLAG_DOCUMENT_7               int64  \n",
      " 101  FLAG_DOCUMENT_8               int64  \n",
      " 102  FLAG_DOCUMENT_9               int64  \n",
      " 103  FLAG_DOCUMENT_10              int64  \n",
      " 104  FLAG_DOCUMENT_11              int64  \n",
      " 105  FLAG_DOCUMENT_12              int64  \n",
      " 106  FLAG_DOCUMENT_13              int64  \n",
      " 107  FLAG_DOCUMENT_14              int64  \n",
      " 108  FLAG_DOCUMENT_15              int64  \n",
      " 109  FLAG_DOCUMENT_16              int64  \n",
      " 110  FLAG_DOCUMENT_17              int64  \n",
      " 111  FLAG_DOCUMENT_18              int64  \n",
      " 112  FLAG_DOCUMENT_19              int64  \n",
      " 113  FLAG_DOCUMENT_20              int64  \n",
      " 114  FLAG_DOCUMENT_21              int64  \n",
      " 115  AMT_REQ_CREDIT_BUREAU_HOUR    float64\n",
      " 116  AMT_REQ_CREDIT_BUREAU_DAY     float64\n",
      " 117  AMT_REQ_CREDIT_BUREAU_WEEK    float64\n",
      " 118  AMT_REQ_CREDIT_BUREAU_MON     float64\n",
      " 119  AMT_REQ_CREDIT_BUREAU_QRT     float64\n",
      " 120  AMT_REQ_CREDIT_BUREAU_YEAR    float64\n",
      " 121  credito_receita               float64\n",
      " 122  anuidade_receita              float64\n",
      " 123  bens_receita                  float64\n",
      " 124  receita_pessoa                float64\n",
      " 125  tempo_empregado_percent       float64\n",
      " 126  num_adultos                   float64\n",
      " 127  tax_kid                       float64\n",
      " 128  ANNUITY LENGTH                float64\n",
      " 129  EXT_SOURCE_MIN                float64\n",
      " 130  EXT_SOURCE_MAX                float64\n",
      " 131  EXT_SOURCE_MEAN               float64\n",
      " 132  EXT_SOURCE_SD                 float64\n",
      " 133  NUM_EXT_SOURCES               int32  \n",
      " 134  NUM_DOCUMENTS                 int64  \n",
      " 135  DAY_APPR_PROCESS_START        object \n",
      " 136  OWN_CAR_AGE_RATIO             float64\n",
      " 137  DAYS_ID_PUBLISHED_RATIO       float64\n",
      " 138  DAYS_REGISTRATION_RATIO       float64\n",
      "dtypes: float64(80), int32(1), int64(41), object(17)\n",
      "memory usage: 65.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_teste.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4> Após a derivação de algumas variáveis, verificou-se a porcentagem entre de dados faltantes. Da tabela abaixo,nota-se que há um hiato significativo entre os valores pecentuais de 50 e 30. Portanto, decidiu-se que se excluíram somentes os parâmetros que teriam valores percentuais acima de 35%,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>COMMONAREA_MODE</th>\n",
       "      <td>171978</td>\n",
       "      <td>69.907483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COMMONAREA_AVG</th>\n",
       "      <td>171978</td>\n",
       "      <td>69.907483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COMMONAREA_MEDI</th>\n",
       "      <td>171978</td>\n",
       "      <td>69.907483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NONLIVINGAPARTMENTS_MODE</th>\n",
       "      <td>170914</td>\n",
       "      <td>69.474976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NONLIVINGAPARTMENTS_MEDI</th>\n",
       "      <td>170914</td>\n",
       "      <td>69.474976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NONLIVINGAPARTMENTS_AVG</th>\n",
       "      <td>170914</td>\n",
       "      <td>69.474976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FONDKAPREMONT_MODE</th>\n",
       "      <td>168392</td>\n",
       "      <td>68.449807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LIVINGAPARTMENTS_AVG</th>\n",
       "      <td>168278</td>\n",
       "      <td>68.403467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LIVINGAPARTMENTS_MODE</th>\n",
       "      <td>168278</td>\n",
       "      <td>68.403467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LIVINGAPARTMENTS_MEDI</th>\n",
       "      <td>168278</td>\n",
       "      <td>68.403467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLOORSMIN_MEDI</th>\n",
       "      <td>166999</td>\n",
       "      <td>67.883565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLOORSMIN_MODE</th>\n",
       "      <td>166999</td>\n",
       "      <td>67.883565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLOORSMIN_AVG</th>\n",
       "      <td>166999</td>\n",
       "      <td>67.883565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEARS_BUILD_MEDI</th>\n",
       "      <td>163680</td>\n",
       "      <td>66.534422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEARS_BUILD_MODE</th>\n",
       "      <td>163680</td>\n",
       "      <td>66.534422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEARS_BUILD_AVG</th>\n",
       "      <td>163680</td>\n",
       "      <td>66.534422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OWN_CAR_AGE_RATIO</th>\n",
       "      <td>162359</td>\n",
       "      <td>65.997447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OWN_CAR_AGE</th>\n",
       "      <td>162359</td>\n",
       "      <td>65.997447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LANDAREA_AVG</th>\n",
       "      <td>146087</td>\n",
       "      <td>59.383028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LANDAREA_MODE</th>\n",
       "      <td>146087</td>\n",
       "      <td>59.383028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LANDAREA_MEDI</th>\n",
       "      <td>146087</td>\n",
       "      <td>59.383028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BASEMENTAREA_MEDI</th>\n",
       "      <td>144090</td>\n",
       "      <td>58.571266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BASEMENTAREA_AVG</th>\n",
       "      <td>144090</td>\n",
       "      <td>58.571266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BASEMENTAREA_MODE</th>\n",
       "      <td>144090</td>\n",
       "      <td>58.571266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXT_SOURCE_1</th>\n",
       "      <td>138803</td>\n",
       "      <td>56.422149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NONLIVINGAREA_MODE</th>\n",
       "      <td>135860</td>\n",
       "      <td>55.225846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NONLIVINGAREA_AVG</th>\n",
       "      <td>135860</td>\n",
       "      <td>55.225846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NONLIVINGAREA_MEDI</th>\n",
       "      <td>135860</td>\n",
       "      <td>55.225846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELEVATORS_AVG</th>\n",
       "      <td>131208</td>\n",
       "      <td>53.334851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELEVATORS_MODE</th>\n",
       "      <td>131208</td>\n",
       "      <td>53.334851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELEVATORS_MEDI</th>\n",
       "      <td>131208</td>\n",
       "      <td>53.334851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALLSMATERIAL_MODE</th>\n",
       "      <td>125164</td>\n",
       "      <td>50.878020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>APARTMENTS_AVG</th>\n",
       "      <td>124955</td>\n",
       "      <td>50.793064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>APARTMENTS_MODE</th>\n",
       "      <td>124955</td>\n",
       "      <td>50.793064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>APARTMENTS_MEDI</th>\n",
       "      <td>124955</td>\n",
       "      <td>50.793064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENTRANCES_MEDI</th>\n",
       "      <td>123944</td>\n",
       "      <td>50.382101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENTRANCES_MODE</th>\n",
       "      <td>123944</td>\n",
       "      <td>50.382101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENTRANCES_AVG</th>\n",
       "      <td>123944</td>\n",
       "      <td>50.382101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LIVINGAREA_MODE</th>\n",
       "      <td>123617</td>\n",
       "      <td>50.249179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LIVINGAREA_MEDI</th>\n",
       "      <td>123617</td>\n",
       "      <td>50.249179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LIVINGAREA_AVG</th>\n",
       "      <td>123617</td>\n",
       "      <td>50.249179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOUSETYPE_MODE</th>\n",
       "      <td>123540</td>\n",
       "      <td>50.217879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLOORSMAX_MEDI</th>\n",
       "      <td>122483</td>\n",
       "      <td>49.788218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLOORSMAX_MODE</th>\n",
       "      <td>122483</td>\n",
       "      <td>49.788218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLOORSMAX_AVG</th>\n",
       "      <td>122483</td>\n",
       "      <td>49.788218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEARS_BEGINEXPLUATATION_MODE</th>\n",
       "      <td>120096</td>\n",
       "      <td>48.817925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEARS_BEGINEXPLUATATION_MEDI</th>\n",
       "      <td>120096</td>\n",
       "      <td>48.817925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEARS_BEGINEXPLUATATION_AVG</th>\n",
       "      <td>120096</td>\n",
       "      <td>48.817925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOTALAREA_MODE</th>\n",
       "      <td>118837</td>\n",
       "      <td>48.306153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EMERGENCYSTATE_MODE</th>\n",
       "      <td>116761</td>\n",
       "      <td>47.462278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OCCUPATION_TYPE</th>\n",
       "      <td>77237</td>\n",
       "      <td>31.396133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXT_SOURCE_3</th>\n",
       "      <td>48728</td>\n",
       "      <td>19.807486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tempo_empregado_percent</th>\n",
       "      <td>44399</td>\n",
       "      <td>18.047787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "      <td>33172</td>\n",
       "      <td>13.484114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <td>33172</td>\n",
       "      <td>13.484114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <td>33172</td>\n",
       "      <td>13.484114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <td>33172</td>\n",
       "      <td>13.484114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <td>33172</td>\n",
       "      <td>13.484114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <td>33172</td>\n",
       "      <td>13.484114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXT_SOURCE_SD</th>\n",
       "      <td>29554</td>\n",
       "      <td>12.013430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Total    Percent\n",
       "COMMONAREA_MODE               171978  69.907483\n",
       "COMMONAREA_AVG                171978  69.907483\n",
       "COMMONAREA_MEDI               171978  69.907483\n",
       "NONLIVINGAPARTMENTS_MODE      170914  69.474976\n",
       "NONLIVINGAPARTMENTS_MEDI      170914  69.474976\n",
       "NONLIVINGAPARTMENTS_AVG       170914  69.474976\n",
       "FONDKAPREMONT_MODE            168392  68.449807\n",
       "LIVINGAPARTMENTS_AVG          168278  68.403467\n",
       "LIVINGAPARTMENTS_MODE         168278  68.403467\n",
       "LIVINGAPARTMENTS_MEDI         168278  68.403467\n",
       "FLOORSMIN_MEDI                166999  67.883565\n",
       "FLOORSMIN_MODE                166999  67.883565\n",
       "FLOORSMIN_AVG                 166999  67.883565\n",
       "YEARS_BUILD_MEDI              163680  66.534422\n",
       "YEARS_BUILD_MODE              163680  66.534422\n",
       "YEARS_BUILD_AVG               163680  66.534422\n",
       "OWN_CAR_AGE_RATIO             162359  65.997447\n",
       "OWN_CAR_AGE                   162359  65.997447\n",
       "LANDAREA_AVG                  146087  59.383028\n",
       "LANDAREA_MODE                 146087  59.383028\n",
       "LANDAREA_MEDI                 146087  59.383028\n",
       "BASEMENTAREA_MEDI             144090  58.571266\n",
       "BASEMENTAREA_AVG              144090  58.571266\n",
       "BASEMENTAREA_MODE             144090  58.571266\n",
       "EXT_SOURCE_1                  138803  56.422149\n",
       "NONLIVINGAREA_MODE            135860  55.225846\n",
       "NONLIVINGAREA_AVG             135860  55.225846\n",
       "NONLIVINGAREA_MEDI            135860  55.225846\n",
       "ELEVATORS_AVG                 131208  53.334851\n",
       "ELEVATORS_MODE                131208  53.334851\n",
       "ELEVATORS_MEDI                131208  53.334851\n",
       "WALLSMATERIAL_MODE            125164  50.878020\n",
       "APARTMENTS_AVG                124955  50.793064\n",
       "APARTMENTS_MODE               124955  50.793064\n",
       "APARTMENTS_MEDI               124955  50.793064\n",
       "ENTRANCES_MEDI                123944  50.382101\n",
       "ENTRANCES_MODE                123944  50.382101\n",
       "ENTRANCES_AVG                 123944  50.382101\n",
       "LIVINGAREA_MODE               123617  50.249179\n",
       "LIVINGAREA_MEDI               123617  50.249179\n",
       "LIVINGAREA_AVG                123617  50.249179\n",
       "HOUSETYPE_MODE                123540  50.217879\n",
       "FLOORSMAX_MEDI                122483  49.788218\n",
       "FLOORSMAX_MODE                122483  49.788218\n",
       "FLOORSMAX_AVG                 122483  49.788218\n",
       "YEARS_BEGINEXPLUATATION_MODE  120096  48.817925\n",
       "YEARS_BEGINEXPLUATATION_MEDI  120096  48.817925\n",
       "YEARS_BEGINEXPLUATATION_AVG   120096  48.817925\n",
       "TOTALAREA_MODE                118837  48.306153\n",
       "EMERGENCYSTATE_MODE           116761  47.462278\n",
       "OCCUPATION_TYPE                77237  31.396133\n",
       "EXT_SOURCE_3                   48728  19.807486\n",
       "tempo_empregado_percent        44399  18.047787\n",
       "AMT_REQ_CREDIT_BUREAU_YEAR     33172  13.484114\n",
       "AMT_REQ_CREDIT_BUREAU_DAY      33172  13.484114\n",
       "AMT_REQ_CREDIT_BUREAU_MON      33172  13.484114\n",
       "AMT_REQ_CREDIT_BUREAU_WEEK     33172  13.484114\n",
       "AMT_REQ_CREDIT_BUREAU_QRT      33172  13.484114\n",
       "AMT_REQ_CREDIT_BUREAU_HOUR     33172  13.484114\n",
       "EXT_SOURCE_SD                  29554  12.013430"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Tratamento dos dados missing\n",
    "\n",
    "total = df_train.isnull().sum().sort_values(ascending = False)\n",
    "\n",
    "percent = (df_train.isnull().sum()/df_train.isnull().count()*100).sort_values(ascending=False)\n",
    "\n",
    "missing_application_train_data  = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_application_train_data=missing_application_train_data[missing_application_train_data['Percent']>0]\n",
    "\n",
    "missing_application_train_data[missing_application_train_data[\"Percent\"]>=10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "drops=list(missing_application_train_data[missing_application_train_data[\"Percent\"]>=35].index)\n",
    "\n",
    "df_train = df_train.drop(columns = drops)\n",
    "\n",
    "df_teste = df_teste.drop(columns = drops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue><b>\n",
    "Gostei bastante da forma como vcs estruturam a aferição de dados nulos, bem legal!!\n",
    "    \n",
    "E achei justo o critério de vocês pra dropar as colunas com mais do que certa porcentagem de dados nulos! De maneira geral, é um procedimento justo.\n",
    "    \n",
    "<br>\n",
    "Dito isso, queria apenas fazer um comentário: lembrem-se que em alguns casos, a falta de informação também é informação! Por exemplo, a coluna \"OWN_CAR_AGE\". Naturalmente, as pessoas que não têm carro, terão NaN nesta coluna, certo? Pro outro lado, esta pode ser uma informação valiosa para as pessoas QUE TÊM carro. Por este motivo, pode não ser uma boa ideia jogar fora esta coluna. Poderíamos, ao invés, preencher os dados que estão faltando com -1, por exemplo (isso faz sentido, pois preenchendo com um valor negativo uma coluna que só deveria ter valores positivos, faz com que todos os NaNs sejam tratados da mesma maneira, e diferente de qualquer outro valor na base!).\n",
    "\n",
    "Enfim, a mensagem que quero passar é: antes de simplesmente jogarmos fora uma coluna, vale a pena refletir um pouco antes pra saber se é justo que joguemos tudo fora ou não, legal?? Por isso, é fundamental uma EDA bem feita para que conheçamos 100% a base e suas colunas, assim podemos saber com segurança o que jogar fora e o que não! (E, infelizmente, senti falta disso no trabalho de vcs)\n",
    "    \n",
    "Isso, claro, pensando em fazer modelos muuuito performáticos, e tentando garantir que fizemos o melhor que pode ser feito, nos aproveitando de toda a info disponpivel. Ou seja, seria apenas um algo a mais a se tentar, caso vocês no final não estivessem satisfeitos ainda com a performance do modelo! ;)\n",
    "</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size =4> As variáveis categóricas, como de prache, foram transformadas em numéricas através de uma lógica semelhante do OneHoteEnconding. As variáveis que possuem somente dois únicos foi feito um Label Enconder. As demais variáveis passaram por um processo que será exposto posteriormente,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAME_CONTRACT_TYPE             2\n",
       "FLAG_OWN_CAR                   2\n",
       "FLAG_OWN_REALTY                2\n",
       "DAY_APPR_PROCESS_START         2\n",
       "CODE_GENDER                    3\n",
       "NAME_EDUCATION_TYPE            5\n",
       "NAME_FAMILY_STATUS             6\n",
       "NAME_HOUSING_TYPE              6\n",
       "NAME_TYPE_SUITE                7\n",
       "WEEKDAY_APPR_PROCESS_START     7\n",
       "NAME_INCOME_TYPE               8\n",
       "OCCUPATION_TYPE               18\n",
       "ORGANIZATION_TYPE             58\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical = [col for col in df_train.columns if df_train[col].dtypes == 'object']\n",
    "ct = df_train[categorical].nunique().sort_values()\n",
    "\n",
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME_CONTRACT_TYPE\n",
      "FLAG_OWN_CAR\n",
      "FLAG_OWN_REALTY\n",
      "DAY_APPR_PROCESS_START\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>...</th>\n",
       "      <th>EXT_SOURCE_SD</th>\n",
       "      <th>NUM_EXT_SOURCES</th>\n",
       "      <th>NUM_DOCUMENTS</th>\n",
       "      <th>DAY_APPR_PROCESS_START</th>\n",
       "      <th>DAYS_ID_PUBLISHED_RATIO</th>\n",
       "      <th>DAYS_REGISTRATION_RATIO</th>\n",
       "      <th>oNAME_CONTRACT_TYPE</th>\n",
       "      <th>oFLAG_OWN_CAR</th>\n",
       "      <th>oFLAG_OWN_REALTY</th>\n",
       "      <th>oDAY_APPR_PROCESS_START</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>456162</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>700830.0</td>\n",
       "      <td>22738.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.373285</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Working day</td>\n",
       "      <td>0.157100</td>\n",
       "      <td>0.479829</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>134978</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>375322.5</td>\n",
       "      <td>14422.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.286485</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Working day</td>\n",
       "      <td>0.241994</td>\n",
       "      <td>0.261651</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>318952</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>544491.0</td>\n",
       "      <td>16047.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055561</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Working day</td>\n",
       "      <td>0.298363</td>\n",
       "      <td>0.569642</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>361264</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>814041.0</td>\n",
       "      <td>28971.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060841</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Working day</td>\n",
       "      <td>0.077235</td>\n",
       "      <td>0.526421</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>260639</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>144000.0</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>21906.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.192295</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Working day</td>\n",
       "      <td>0.126387</td>\n",
       "      <td>0.269069</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246003</th>\n",
       "      <td>242114</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1172470.5</td>\n",
       "      <td>34411.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008268</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Working day</td>\n",
       "      <td>0.255690</td>\n",
       "      <td>0.626813</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246004</th>\n",
       "      <td>452374</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>654498.0</td>\n",
       "      <td>27859.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248636</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>0.194848</td>\n",
       "      <td>0.156904</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246005</th>\n",
       "      <td>276545</td>\n",
       "      <td>1</td>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054030</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>0.301021</td>\n",
       "      <td>0.515717</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246006</th>\n",
       "      <td>236776</td>\n",
       "      <td>1</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>3</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>204858.0</td>\n",
       "      <td>17653.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.299722</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>0.308156</td>\n",
       "      <td>0.131780</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246007</th>\n",
       "      <td>454197</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>2</td>\n",
       "      <td>81000.0</td>\n",
       "      <td>547344.0</td>\n",
       "      <td>23139.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Working day</td>\n",
       "      <td>0.218021</td>\n",
       "      <td>0.116831</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246008 rows × 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
       "0           456162       0         Cash loans           F            N   \n",
       "1           134978       0         Cash loans           F            N   \n",
       "2           318952       0         Cash loans           M            Y   \n",
       "3           361264       0         Cash loans           F            N   \n",
       "4           260639       0         Cash loans           F            N   \n",
       "...            ...     ...                ...         ...          ...   \n",
       "246003      242114       0         Cash loans           F            N   \n",
       "246004      452374       0         Cash loans           F            N   \n",
       "246005      276545       1    Revolving loans           M            N   \n",
       "246006      236776       1         Cash loans           M            Y   \n",
       "246007      454197       0         Cash loans           F            N   \n",
       "\n",
       "       FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  \\\n",
       "0                    N             0          112500.0    700830.0   \n",
       "1                    N             0           90000.0    375322.5   \n",
       "2                    N             0          180000.0    544491.0   \n",
       "3                    Y             0          270000.0    814041.0   \n",
       "4                    Y             0          144000.0    675000.0   \n",
       "...                ...           ...               ...         ...   \n",
       "246003               Y             1          270000.0   1172470.5   \n",
       "246004               Y             0          180000.0    654498.0   \n",
       "246005               N             1          112500.0    270000.0   \n",
       "246006               N             3          202500.0    204858.0   \n",
       "246007               Y             2           81000.0    547344.0   \n",
       "\n",
       "        AMT_ANNUITY  ...  EXT_SOURCE_SD NUM_EXT_SOURCES NUM_DOCUMENTS  \\\n",
       "0           22738.5  ...       0.373285               2             1   \n",
       "1           14422.5  ...       0.286485               3             1   \n",
       "2           16047.0  ...       0.055561               2             1   \n",
       "3           28971.0  ...       0.060841               2             1   \n",
       "4           21906.0  ...       0.192295               3             1   \n",
       "...             ...  ...            ...             ...           ...   \n",
       "246003      34411.5  ...       0.008268               2             1   \n",
       "246004      27859.5  ...       0.248636               2             1   \n",
       "246005      13500.0  ...       0.054030               2             0   \n",
       "246006      17653.5  ...       0.299722               2             1   \n",
       "246007      23139.0  ...            NaN               1             1   \n",
       "\n",
       "       DAY_APPR_PROCESS_START DAYS_ID_PUBLISHED_RATIO DAYS_REGISTRATION_RATIO  \\\n",
       "0                 Working day                0.157100                0.479829   \n",
       "1                 Working day                0.241994                0.261651   \n",
       "2                 Working day                0.298363                0.569642   \n",
       "3                 Working day                0.077235                0.526421   \n",
       "4                 Working day                0.126387                0.269069   \n",
       "...                       ...                     ...                     ...   \n",
       "246003            Working day                0.255690                0.626813   \n",
       "246004                Weekend                0.194848                0.156904   \n",
       "246005                Weekend                0.301021                0.515717   \n",
       "246006                Weekend                0.308156                0.131780   \n",
       "246007            Working day                0.218021                0.116831   \n",
       "\n",
       "        oNAME_CONTRACT_TYPE  oFLAG_OWN_CAR  oFLAG_OWN_REALTY  \\\n",
       "0                         0              0                 0   \n",
       "1                         0              0                 0   \n",
       "2                         0              1                 0   \n",
       "3                         0              0                 1   \n",
       "4                         0              0                 1   \n",
       "...                     ...            ...               ...   \n",
       "246003                    0              0                 1   \n",
       "246004                    0              0                 1   \n",
       "246005                    1              0                 0   \n",
       "246006                    0              1                 0   \n",
       "246007                    0              0                 1   \n",
       "\n",
       "        oDAY_APPR_PROCESS_START  \n",
       "0                             1  \n",
       "1                             1  \n",
       "2                             1  \n",
       "3                             1  \n",
       "4                             1  \n",
       "...                         ...  \n",
       "246003                        1  \n",
       "246004                        0  \n",
       "246005                        0  \n",
       "246006                        0  \n",
       "246007                        1  \n",
       "\n",
       "[246008 rows x 94 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb = LabelEncoder()\n",
    "\n",
    "for col in categorical:\n",
    "    if len(df_train[col].unique()) ==2:\n",
    "        lb.fit(df_train[col])\n",
    "        \n",
    "        print(col)\n",
    "        \n",
    "        df_train[\"o\"+col] = lb.transform(df_train[col])\n",
    "        \n",
    "        df_teste[\"o\"+col] = lb.transform(df_teste[col])\n",
    "           \n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue><b>\n",
    "Legal! Aqui, novamente, vocês fizeram o mesmo tratamento pra base de treino e de teste, então está certinho.\n",
    "    \n",
    "Mas lembrem-se do Pipeline! É mais prático, rápido e seguro colocar essa e as demais etapas de pré-processamento dentro do Pipeline, pois assim garantimos que não vai ter problema algum de data leakage.\n",
    "    \n",
    "Mas, de fato, isso só vai se tornar algo notavelmente importante em modelos produtivos (no último módulo do curso vcs vão entender pq). Enquanto não estamos pensando em modelos produtivos, o que vocês fizeram tá certinho!\n",
    "</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4> Das variáveis categóricas que possuem o maior número de valores únicos (OCCUPATION_TYPE E ORGANIZATION_TYPE), decidimos tratá-las de maneira especial. A partir do valor médio dos target fizemos um clusterização de modo que os valores únicos para as variáveis categóricas fossem reduzidos e, desta forma, não onerasse (pelo número excessivo de features) os modelos durante o treinamento e predição. Para determinar o número ideal de cluster utilizamos o método da silhueta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "organ_sort = df_train.groupby(['ORGANIZATION_TYPE'])['TARGET'].agg(['mean'])\n",
    "\n",
    "occupation_sort = df_train.groupby([\"OCCUPATION_TYPE\"])['TARGET'].agg(['mean'])\n",
    "\n",
    "categorical_df_lista=[organ_sort, occupation_sort]\n",
    "\n",
    "lista_k = list(range(2,10))\n",
    "\n",
    "for df in categorical_df_lista:\n",
    "    \n",
    "    silhouete_scores =[]\n",
    "    \n",
    "    for k in lista_k:\n",
    "    \n",
    "        estimador = KMeans (n_clusters=k, max_iter=1000)\n",
    "\n",
    "        modelo = estimador.fit(df) \n",
    "\n",
    "        silhouete_scores.append(silhouette_score(df, modelo.labels_))\n",
    "\n",
    "    k=lista_k[np.argmax(silhouete_scores)]\n",
    "\n",
    "    estimador = KMeans(n_clusters=k, max_iter=1000,random_state=2)\n",
    "\n",
    "    modelo = estimador.fit(df)\n",
    "\n",
    "    labels = modelo.predict(df)\n",
    "    \n",
    "    df=df.reset_index()\n",
    "\n",
    "    dados_cluster = pd.concat([df, \n",
    "                                 pd.Series(labels, name=\"cluster_\"+df.columns[0])], axis=1)\n",
    "    \n",
    "    df_train=df_train.merge(dados_cluster[[dados_cluster.columns[0],\"cluster_\"+df.columns[0]]],on=dados_cluster.columns[0], how='left')\n",
    "    \n",
    "    df_teste=df_teste.merge(dados_cluster[[dados_cluster.columns[0],\"cluster_\"+df.columns[0]]],on=dados_cluster.columns[0], how='left')\n",
    "\n",
    "    df_train[\"cluster_\"+df.columns[0]] = df_train[\"cluster_\"+df.columns[0]].astype('category')\n",
    "    \n",
    "    df_teste[\"cluster_\"+df.columns[0]] = df_teste[\"cluster_\"+df.columns[0]].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue><b>\n",
    "Uaaau, aí sim hein!! Achei <i>FANCY</i> hahahaha\n",
    "    \n",
    "Mas, sério, parabéns por terem usado uma técnica de clusterização como pré-processamento! Isso demonstra uma compreensão muuuito boa de tudo o que aprendemos no curso, e utilização das técnicas em contextos bem específicos, o que evidencia que vcs absorveram super bem a essência do que aprendemos!. Gostei muuuito, parabéns mesmo!!\n",
    "</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4> Nesta etapa as variáveis categóricas que já sofreram o processo Encoding e as clusterizadas são dropadas da base, e as demais variáveis categóricas são transformadas em dummies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "discard_features = ['ORGANIZATION_TYPE', 'OCCUPATION_TYPE','FLAG_OWN_CAR','FLAG_OWN_REALTY','NAME_CONTRACT_TYPE', 'DAY_APPR_PROCESS_START']\n",
    "\n",
    "df_train.drop(discard_features,axis = 1, inplace = True)\n",
    "\n",
    "df_teste.drop(discard_features,axis = 1, inplace = True)\n",
    "\n",
    "df_train = pd.get_dummies(df_train)\n",
    "\n",
    "df_teste = pd.get_dummies(df_teste)\n",
    "\n",
    "train_labels = df_train['TARGET']\n",
    "df_train, df_teste = df_train.align(df_teste, join = 'inner', axis = 1)\n",
    "df_train['TARGET'] = train_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4> Por fim, é feito o processo de normalização e preenchimento dos valores faltantes. No primeiro caso os dados foram normalizados entre 0 e 1, e os dados faltantes foram preenchidas pela mediana dos parâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill in missing values\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer= SimpleImputer(strategy='median')\n",
    "scaler = MinMaxScaler(feature_range = [0,1])\n",
    "train = df_train.drop(columns = ['TARGET'])\n",
    "\n",
    "imputer.fit(train)\n",
    "train = imputer.transform(train)\n",
    "test = imputer.transform(df_teste)\n",
    "scaler.fit(train)\n",
    "train = scaler.transform(train)\n",
    "test = scaler.transform(test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue><b>\n",
    "Mais uma vez, muito bem! Mandaram bem demais!!\n",
    "    \n",
    "Aqui, faço novamente o comentário sobre a utilização do Pipeline (ressaltando, novamente, que apesar do comentário, tá certinho como vcs fizeram!)\n",
    "</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicação das técnicas de aprendizado de máquina\n",
    "\n",
    "<font size=4> Após o processo de feature engineering, forama aplicados algumas técnicas de aprendizado de máquina. Em se tratando de um problema de classificação e o grau de complexidade do modelo, foram utilizados os seguintes modelos:\n",
    "    \n",
    "    -Regressão Logística\n",
    "    -Random Forest\n",
    "    -LightGBM\n",
    "    \n",
    "O LightGBM é uma primo próximo ao XGBoost, portanto, funciona como sendo um ensemble de árvores. Contudo, o seu processo de aprendizado é mais rápido para alguns casos. Uma explicação mais detalhada do modelo está [nesse link.](https://datarisk.io/gradient-boostings-parte-3-xgboost-vs-lightgbm-vs-catboost/?cn-reloaded=1).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue><b>\n",
    "Perfeito!! Não chegamos a falar em detalhes sobre o LightGBM, então fico muuito feliz de vcs terem ido atrás dele por conta própria! Isso mostra que vocês estão agindo mto bem de maneira autodidata e independente (e exercitando mto bem a importante habilidade de pesquisa hehe), então, parabéns demais!!\n",
    "</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ----------------------------------------------Regressão Logística ------------------------------------------- ###\n",
    "\n",
    "\n",
    "<font size=4>Para o algoritmo de regressão logística, o processamento de determinação dos hiperparâmetros do modelo deu-se através do GridSearchCV. Desta forma, todas as combinações possíveis para os valores dos hiperparâmetros são testados. Neste caso, as regularizações lasso e ridge ridge regression foram utilizadas bem como diferentes valores de trade-off. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] END .................................C=0.01, penalty=l1; total time=   4.5s\n",
      "[CV] END .................................C=0.01, penalty=l1; total time=   0.1s\n",
      "[CV] END .................................C=0.01, penalty=l1; total time=   0.1s\n",
      "[CV] END .................................C=0.01, penalty=l1; total time=   0.1s\n",
      "[CV] END .................................C=0.01, penalty=l1; total time=   0.1s\n",
      "[CV] END .................................C=0.01, penalty=l2; total time=   8.5s\n",
      "[CV] END .................................C=0.01, penalty=l2; total time=   8.4s\n",
      "[CV] END .................................C=0.01, penalty=l2; total time=   8.4s\n",
      "[CV] END .................................C=0.01, penalty=l2; total time=   8.3s\n",
      "[CV] END .................................C=0.01, penalty=l2; total time=   8.7s\n",
      "[CV] END ..................................C=0.1, penalty=l1; total time=   0.1s\n",
      "[CV] END ..................................C=0.1, penalty=l1; total time=   0.0s\n",
      "[CV] END ..................................C=0.1, penalty=l1; total time=   0.1s\n",
      "[CV] END ..................................C=0.1, penalty=l1; total time=   0.2s\n",
      "[CV] END ..................................C=0.1, penalty=l1; total time=   0.1s\n",
      "[CV] END ..................................C=0.1, penalty=l2; total time=   8.1s\n",
      "[CV] END ..................................C=0.1, penalty=l2; total time=   8.4s\n",
      "[CV] END ..................................C=0.1, penalty=l2; total time=  10.6s\n",
      "[CV] END ..................................C=0.1, penalty=l2; total time=  12.1s\n",
      "[CV] END ..................................C=0.1, penalty=l2; total time=  12.2s\n",
      "[CV] END ....................................C=1, penalty=l1; total time=   2.0s\n",
      "[CV] END ....................................C=1, penalty=l1; total time=   1.7s\n",
      "[CV] END ....................................C=1, penalty=l1; total time=   0.1s\n",
      "[CV] END ....................................C=1, penalty=l1; total time=   0.1s\n",
      "[CV] END ....................................C=1, penalty=l1; total time=   0.1s\n",
      "[CV] END ....................................C=1, penalty=l2; total time=  10.0s\n",
      "[CV] END ....................................C=1, penalty=l2; total time=  12.7s\n",
      "[CV] END ....................................C=1, penalty=l2; total time=  12.0s\n",
      "[CV] END ....................................C=1, penalty=l2; total time=  10.5s\n",
      "[CV] END ....................................C=1, penalty=l2; total time=  11.1s\n",
      "[CV] END ...................................C=10, penalty=l1; total time=   0.2s\n",
      "[CV] END ...................................C=10, penalty=l1; total time=   0.1s\n",
      "[CV] END ...................................C=10, penalty=l1; total time=   0.1s\n",
      "[CV] END ...................................C=10, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=10, penalty=l1; total time=   0.1s\n",
      "[CV] END ...................................C=10, penalty=l2; total time=   8.1s\n",
      "[CV] END ...................................C=10, penalty=l2; total time=   9.9s\n",
      "[CV] END ...................................C=10, penalty=l2; total time=  11.0s\n",
      "[CV] END ...................................C=10, penalty=l2; total time=   9.7s\n",
      "[CV] END ...................................C=10, penalty=l2; total time=   9.6s\n",
      "[CV] END ..................................C=100, penalty=l1; total time=   2.8s\n",
      "[CV] END ..................................C=100, penalty=l1; total time=   2.2s\n",
      "[CV] END ..................................C=100, penalty=l1; total time=   0.2s\n",
      "[CV] END ..................................C=100, penalty=l1; total time=   0.2s\n",
      "[CV] END ..................................C=100, penalty=l1; total time=   0.1s\n",
      "[CV] END ..................................C=100, penalty=l2; total time=   9.4s\n",
      "[CV] END ..................................C=100, penalty=l2; total time=   9.3s\n",
      "[CV] END ..................................C=100, penalty=l2; total time=  10.1s\n",
      "[CV] END ..................................C=100, penalty=l2; total time=  10.8s\n",
      "[CV] END ..................................C=100, penalty=l2; total time=   8.2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7466520076364109"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Regressão Logística ### \n",
    "param_grid_reg_log = {'C' : [0.01,0.1,1,10,100],\n",
    "              'penalty' : ['l1','l2']}\n",
    "log_reg = LogisticRegression()\n",
    "grid_search_reg_log = GridSearchCV(log_reg, param_grid_reg_log, scoring = 'roc_auc', cv = 5, verbose=1.5)\n",
    "grid_search_reg_log.fit(train, train_labels)\n",
    "\n",
    "# Train on the training data\n",
    "log_reg_best = grid_search_reg_log.best_estimator_\n",
    "log_reg_pred = log_reg_best.predict_proba(test)[:, 1]\n",
    "submit = df_teste[['SK_ID_CURR']]\n",
    "submit['REGRESSÃO_LOGISTICA'] = log_reg_pred\n",
    "\n",
    "grid_search_reg_log.best_score_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue><b>\n",
    "Ótimo!!\n",
    "</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------------------------------- Random Forest ------------------------------------------- ###\n",
    "\n",
    "<font size=4> No que diz respeito à tecnica de random forest, a definição dos hiperparâmetros deu-se também através do GridSearch. Neste caso, foram utilizados os seguintes parâmetros:\n",
    "    \n",
    "**Critério**: Determina qual é o melhor critério que determina o melhor ganho de informação no momento da separação (entropia ou gini).\n",
    " \n",
    "**Máxima profundidade**: Como o próprio nome sugere, determina a máxima profundidade de das árvores que compõem o ennemble. Utiizou-se um intervalo entre 2 e 5.\n",
    "    \n",
    "**Máximo número de  features**: Determina qual operação aritmética será utilizada para selecionar o número máximo de parâmetros no momento da separação da árvore. \n",
    "    \n",
    "**Número Estimadores**: Determina o número de árvores utilizado pelo ensemble. Neste caso, utilizou-se 50,100,150,200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=50; total time=  12.6s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=50; total time=  11.8s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=50; total time=  10.9s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=50; total time=   9.8s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=50; total time=   8.5s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=100; total time=  15.1s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=100; total time=  15.2s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=100; total time=  15.9s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=100; total time=  15.3s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=100; total time=  14.8s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=150; total time=  21.7s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=150; total time=  22.5s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=150; total time=  25.6s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=150; total time=  24.5s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=150; total time=  26.3s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=200; total time=  34.1s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=200; total time=  29.6s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=200; total time=  30.2s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=200; total time=  37.2s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=200; total time=  46.3s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=50; total time=  10.1s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=50; total time=   7.0s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=50; total time=   6.1s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=50; total time=   8.3s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=50; total time=   6.0s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=100; total time=  12.6s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=100; total time=  12.8s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=100; total time=  12.7s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=100; total time=  11.5s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=100; total time=  11.3s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=150; total time=  17.4s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=150; total time=  15.9s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=150; total time=  16.5s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=150; total time=  16.8s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=150; total time=  16.9s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=200; total time=  21.7s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=200; total time=  21.7s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=200; total time=  21.6s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=200; total time=  21.6s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=200; total time=  21.7s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=50; total time=  10.5s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=50; total time=  10.1s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=50; total time=  10.6s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=50; total time=   9.9s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=50; total time=  12.8s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=100; total time=  22.7s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=100; total time=  23.2s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=100; total time=  22.9s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=100; total time=  23.3s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=100; total time=  21.8s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=150; total time=  30.4s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=150; total time=  29.9s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=150; total time=  31.9s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=150; total time=  32.3s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=150; total time=  31.1s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=200; total time=  41.3s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=200; total time=  52.7s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=200; total time=  52.4s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=200; total time=  55.9s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=200; total time=  55.8s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=50; total time=  10.6s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=50; total time=   8.7s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=50; total time=  11.2s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=50; total time=  13.6s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=50; total time=   9.6s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=100; total time=  18.1s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=100; total time=  19.5s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=100; total time=  18.8s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=100; total time=  23.5s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=100; total time=  17.4s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=150; total time=  26.5s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=150; total time=  30.2s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=150; total time=  30.1s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=150; total time=  33.9s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=150; total time=  28.1s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=200; total time=  37.5s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=200; total time=  35.1s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=200; total time=  31.6s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=200; total time=  33.4s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=200; total time=  32.9s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=50; total time=  14.3s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=50; total time=  14.1s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=50; total time=  14.2s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=50; total time=  13.6s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=50; total time=  14.0s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=100; total time=  27.6s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=100; total time=  28.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=100; total time=  26.9s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=100; total time=  28.3s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=100; total time=  28.8s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=150; total time=  41.4s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=150; total time=  41.7s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=150; total time=  41.2s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=150; total time=  41.1s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=150; total time=  47.2s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=200; total time= 1.0min\n",
      "[CV] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=200; total time=  55.4s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=200; total time=  55.9s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=200; total time= 1.1min\n",
      "[CV] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=200; total time= 1.3min\n",
      "[CV] END criterion=gini, max_depth=4, max_features=log2, n_estimators=50; total time=  12.9s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=log2, n_estimators=50; total time=  11.3s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=log2, n_estimators=50; total time=  12.5s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=log2, n_estimators=50; total time=  11.8s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=log2, n_estimators=50; total time=  12.6s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=log2, n_estimators=100; total time=  23.2s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=log2, n_estimators=100; total time=  23.1s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=log2, n_estimators=100; total time=  23.2s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=log2, n_estimators=100; total time=  22.8s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=log2, n_estimators=100; total time=  24.8s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=log2, n_estimators=150; total time=  34.3s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=log2, n_estimators=150; total time=  35.8s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=log2, n_estimators=150; total time=  33.7s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=log2, n_estimators=150; total time=  36.5s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=log2, n_estimators=150; total time=  35.2s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=log2, n_estimators=200; total time=  45.4s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=log2, n_estimators=200; total time=  48.5s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=log2, n_estimators=200; total time=  45.9s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=log2, n_estimators=200; total time=  39.2s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=log2, n_estimators=200; total time=  41.9s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=50; total time=   8.7s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=50; total time=   8.7s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=50; total time=   9.6s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=50; total time=   8.6s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=50; total time=   8.5s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=100; total time=  17.2s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=100; total time=  17.5s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=100; total time=  17.4s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=100; total time=  17.5s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=100; total time=  16.8s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=150; total time=  26.4s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=150; total time=  25.3s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=150; total time=  25.6s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=150; total time=  25.8s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=150; total time=  25.9s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=200; total time=  35.9s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=200; total time=  36.0s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=200; total time=  35.5s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=200; total time=  40.0s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=200; total time=  34.9s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=50; total time=   7.0s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=50; total time=   6.3s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=50; total time=   6.5s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=50; total time=   6.5s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=50; total time=   6.5s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=100; total time=  13.0s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=100; total time=  12.2s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=100; total time=  13.2s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=100; total time=  12.3s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=100; total time=  17.0s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=150; total time=  20.6s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=150; total time=  22.7s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=150; total time=  21.1s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=150; total time=  20.2s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=150; total time=  25.4s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=200; total time=  30.3s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=200; total time=  29.2s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=200; total time=  27.8s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=200; total time=  28.7s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=200; total time=  26.9s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=50; total time=  13.4s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=50; total time=  13.0s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=50; total time=  14.1s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=50; total time=  13.2s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=50; total time=  13.0s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=100; total time=  27.0s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=100; total time=  40.1s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=100; total time=  30.2s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=100; total time=  26.1s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=100; total time=  25.2s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=150; total time=  39.6s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=150; total time=  40.7s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=150; total time=  39.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=150; total time=  37.6s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=150; total time=  35.8s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=200; total time=  48.1s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=200; total time=  52.8s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=200; total time=  53.8s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=200; total time=  48.0s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=200; total time=  48.9s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=50; total time=  15.9s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=50; total time=  14.9s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=50; total time=  11.0s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=50; total time=  10.3s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=50; total time=   9.3s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=100; total time=  23.2s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=100; total time=  20.6s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=100; total time=  19.0s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=100; total time=  19.2s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=100; total time=  23.2s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=150; total time=  25.3s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=150; total time=  25.9s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=150; total time=  25.1s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=150; total time=  25.4s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=150; total time=  27.1s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=200; total time=  36.2s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=200; total time= 1.1min\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=200; total time= 1.0min\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=200; total time=  58.3s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=200; total time=  53.9s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=50; total time=  23.9s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=50; total time=  25.5s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=50; total time=  28.7s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=50; total time=  26.3s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=50; total time=  26.6s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=100; total time=  50.0s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=100; total time=  43.0s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=100; total time=  43.4s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=100; total time=  40.8s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=100; total time=  48.9s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=150; total time= 1.4min\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=150; total time= 1.3min\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=150; total time= 1.2min\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=150; total time= 1.2min\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=150; total time= 1.3min\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=200; total time= 1.7min\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=200; total time= 1.4min\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=200; total time= 1.6min\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=200; total time= 1.5min\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=200; total time= 1.3min\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=50; total time=  12.1s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=50; total time=  12.4s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=50; total time=  12.3s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=50; total time=  14.9s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=50; total time=  15.7s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=100; total time=  35.2s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=100; total time=  34.6s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=100; total time=  30.2s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=100; total time=  32.5s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=100; total time=  34.8s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=150; total time=  47.5s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=150; total time=  49.1s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=150; total time=  47.0s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=150; total time=  44.8s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=150; total time=  52.1s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=200; total time= 1.2min\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=200; total time= 1.1min\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=200; total time= 1.3min\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=200; total time= 1.2min\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=200; total time= 1.3min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7340532292336415"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Random Forest ###\n",
    "\n",
    "param_grid_reg_rf = {'criterion' : [\"gini\",\"entropy\"], \n",
    "                     \"max_depth\":[i for i in range(2,5)], \n",
    "                     \"max_features\":[\"sqrt\", \"log2\"], \n",
    "                     \"n_estimators\" : [50,100,150,200]}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "grid_search_rf = GridSearchCV(rf, param_grid_reg_rf, scoring = 'roc_auc', cv = 5, verbose=1.5)\n",
    "grid_search_rf.fit(train, train_labels)\n",
    "\n",
    "# Train on the training data\n",
    "rf_best = grid_search_rf.best_estimator_\n",
    "rf_pred = rf_best.predict_proba(test)[:, 1]\n",
    "submit = df_teste[['SK_ID_CURR']]\n",
    "\n",
    "\n",
    "grid_search_rf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue><b>\n",
    "Apenas um pequeno comentário: modelos random forest tendem a funcionar melhor com um grande número de estimadores (da ordem de 1000), o que faz sentido, dado o procedimento de bagging que é utilizado, né?\n",
    "    \n",
    "Fica como sugestão para próximos projetos: apesar de demorar beeeem mais pra treinar, pode valer a pena testar um número maior de estimadores também! (E aliás, foi provavelmente por este motivo que o random forest não teve uma performance tão legal aqui!)\n",
    "</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['RANDOM_FOREST'] = rf_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------------------------------- Light GBM------------------------------------------- ###\n",
    "\n",
    "<font size=4> Por fim, a determinação dos hiperparâmetros para a técnica Light GBM deu-se através de um processo de otimização. Este baseia-se em um processo de otimização Bayesiana usando processos Gaussianos [mais informações aqui]((https://datarisk.io/gradient-boostings-parte-3-xgboost-vs-lightgbm-vs-catboost/?cn-reloaded=1)). Assim sendo, o processo de otimização tem como variáveis de decisão os intervalos de valores estabelecidos para os hiperparâmetros do modelo e como função obejtivo a equação analítica (1 - ROC_SCORE). Utilizou-se esta uma vez que o processo de otimização tem como pressuposto atingir o mínimo valor possível  para a  função objetivo. Neste caso, assim como exposto para as demais técnicas previamente expostas, estamos tentando achar o valor máximo para a métrica ROC, assim, a minimização da equação analítica indica a maximização da métrica ROC. Dentre os hiperparâmetros, foram utilizados a taxa aprendizado, termo de regularização para o L1 e L2, número de estimadores, máxima profunidade das árvores, entre outros. Salienta-se que o valor utilizado de ROC junto à função objetivo é dado como a média entre os valores obtidos de roc, que é obtido a partir de um processo de validação cruzada. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time= 1.8min\n",
      "[CV] END .................................................... total time= 1.6min\n",
      "[CV] END .................................................... total time= 1.6min\n",
      "[CV] END .................................................... total time= 1.7min\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 497.8520\n",
      "Function value obtained: 0.2350\n",
      "Current minimum: 0.2350\n",
      "Iteration No: 2 started. Evaluating function at random point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  8.3min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time= 1.6min\n",
      "[CV] END .................................................... total time= 1.6min\n",
      "[CV] END .................................................... total time= 1.5min\n",
      "[CV] END .................................................... total time= 1.6min\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 489.4581\n",
      "Function value obtained: 0.2348\n",
      "Current minimum: 0.2348\n",
      "Iteration No: 3 started. Evaluating function at random point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  8.2min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=  48.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   48.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=  43.0s\n",
      "[CV] END .................................................... total time=  48.7s\n",
      "[CV] END .................................................... total time= 1.0min\n",
      "[CV] END .................................................... total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  4.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 265.1301\n",
      "Function value obtained: 0.2382\n",
      "Current minimum: 0.2348\n",
      "Iteration No: 4 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=  42.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   42.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=  44.2s\n",
      "[CV] END .................................................... total time=  45.1s\n",
      "[CV] END .................................................... total time=  43.7s\n",
      "[CV] END .................................................... total time=  42.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  3.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 4 ended. Search finished for the next optimal point.\n",
      "Time taken: 219.0353\n",
      "Function value obtained: 0.2363\n",
      "Current minimum: 0.2348\n",
      "Iteration No: 5 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time= 2.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time= 3.3min\n",
      "[CV] END .................................................... total time= 3.2min\n",
      "[CV] END .................................................... total time= 2.8min\n",
      "[CV] END .................................................... total time= 2.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 13.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 5 ended. Search finished for the next optimal point.\n",
      "Time taken: 826.4109\n",
      "Function value obtained: 0.2456\n",
      "Current minimum: 0.2348\n",
      "Iteration No: 6 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=10.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 10.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time= 8.9min\n",
      "[CV] END .................................................... total time= 7.1min\n",
      "[CV] END .................................................... total time= 7.0min\n",
      "[CV] END .................................................... total time= 6.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 40.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 6 ended. Search finished for the next optimal point.\n",
      "Time taken: 2445.4054\n",
      "Function value obtained: 0.2565\n",
      "Current minimum: 0.2348\n",
      "Iteration No: 7 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   5.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   4.6s\n",
      "[CV] END .................................................... total time=   4.2s\n",
      "[CV] END .................................................... total time=   5.1s\n",
      "[CV] END .................................................... total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   23.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 7 ended. Search finished for the next optimal point.\n",
      "Time taken: 24.3802\n",
      "Function value obtained: 0.2553\n",
      "Current minimum: 0.2348\n",
      "Iteration No: 8 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time= 1.8min\n",
      "[CV] END .................................................... total time= 1.8min\n",
      "[CV] END .................................................... total time= 1.7min\n",
      "[CV] END .................................................... total time= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  8.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 8 ended. Search finished for the next optimal point.\n",
      "Time taken: 514.1813\n",
      "Function value obtained: 0.2714\n",
      "Current minimum: 0.2348\n",
      "Iteration No: 9 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time= 3.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time= 4.3min\n",
      "[CV] END .................................................... total time= 4.8min\n",
      "[CV] END .................................................... total time= 4.7min\n",
      "[CV] END .................................................... total time= 4.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 21.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 9 ended. Search finished for the next optimal point.\n",
      "Time taken: 1308.6005\n",
      "Function value obtained: 0.2343\n",
      "Current minimum: 0.2343\n",
      "Iteration No: 10 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time= 2.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time= 2.1min\n",
      "[CV] END .................................................... total time= 1.9min\n",
      "[CV] END .................................................... total time= 2.1min\n",
      "[CV] END .................................................... total time= 2.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 10.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 10 ended. Search finished for the next optimal point.\n",
      "Time taken: 648.8571\n",
      "Function value obtained: 0.2387\n",
      "Current minimum: 0.2343\n",
      "Best parameters:\n",
      "            - 0) learning_rate=0.001784\n",
      "            - 1) num_leaves=339\n",
      "            - 2) min_child_samples=61\n",
      "            - 3) n_estimators=9636.000000\n",
      "            - 4) max_depth=5.000000\n",
      "            - 5) reg_alpha = 5\n",
      "            - 6) sub_sample = 0\n",
      "            - 7) colsample_bytree = 0\n",
      "            - 8) reg_lambda = 7 \n",
      "            - 9) min_child_weight =6\n",
      "            - 10) min_split_gain =0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from skopt.space import Integer\n",
    "from skopt.space import Real\n",
    "\n",
    "def param_search (params_range):\n",
    "    \n",
    "    learning_rate =params_range[0],\n",
    "    num_leaves = params_range[1],\n",
    "    min_child_samples = params_range[2]\n",
    "    n_estimators=params_range[3]\n",
    "    max_depth = params_range[4]\n",
    "    reg_alpha=params_range[5]\n",
    "    subsample=params_range[6]\n",
    "    colsample_bytree=params_range[7]\n",
    "    reg_lambda = params_range[8]\n",
    "    min_child_weight = params_range[9]\n",
    "    min_split_gain = params_range[10]\n",
    "   \n",
    "    \n",
    "    mdl = lgb.LGBMClassifier(learning_rate =learning_rate,\n",
    "                             num_leaves = num_leaves,\n",
    "                             min_child_samples = min_child_samples,\n",
    "                             n_estimators=n_estimators,\n",
    "                             max_depth = max_depth,\n",
    "                             reg_alpha = reg_alpha,\n",
    "                             random_state=42,\n",
    "                             subsample=subsample,\n",
    "                             colsample_bytree=colsample_bytree,\n",
    "                             reg_lambda = reg_lambda,\n",
    "                             min_child_weight = min_child_weight,\n",
    "                             min_split_gain = min_split_gain)\n",
    "    \n",
    "    #mdl.fit(X_train,Y_train, eval_set=(X_val, Y_val), \n",
    "            #eval_metric= 'auc',early_stopping_rounds= 200, verbose=1.5) \n",
    "        \n",
    "    result = cross_val_score (mdl, train, train_labels, scoring = 'roc_auc', cv=5, verbose=1.5)\n",
    "    \n",
    "    estimate = np.mean(result)\n",
    "    \n",
    "    print(estimate)\n",
    "                            \n",
    "    return 1-estimate\n",
    "\n",
    "params_range =[\n",
    "    (0.0001, 0.3,'log-uniform'), ## 0-learning_rate,\n",
    "    (2,1000), ## 1-num_leaves\n",
    "    (1,100), ## 2-min_child_samples\n",
    "    (50,10000), ##3-n_estimators\n",
    "    (-1,20), ## 4-max_depth\n",
    "    Real(0.01,10), ## 5-reg_alpha\n",
    "    Real(0.01,1), ##6-sub_sample\n",
    "    Real (0.01,1), ##7-colsample_bytree,\n",
    "    Real(0.01,10), ## 8 - reg_lambda\n",
    "    (0.01,50), ## 9 - min_child_weight,\n",
    "    (0.01,50)] ## 10 - min_split_gain \n",
    "  \n",
    "result_gp=gp_minimize (param_search, params_range, random_state = 42, verbose=True, n_calls=5,  \n",
    "                             n_random_starts=3)\n",
    "    \n",
    "\n",
    "print(\"\"\"Best parameters:\n",
    "            - 0) learning_rate=%f\n",
    "            - 1) num_leaves=%f\n",
    "            - 2) min_child_samples=%f\n",
    "            - 3) n_estimators=%f\n",
    "            - 4) max_depth=%f\n",
    "            - 5) reg_alpha = %f\n",
    "            - 6) sub_sample = %f\n",
    "            - 7) colsample_bytree = %f\n",
    "            - 8) reg_lambda = %f \n",
    "            - 9) min_child_weight =%f\n",
    "            - 10) min_split_gain =%f\"\"\" %(result_gp.x[0],\n",
    "                                   result_gp.x[1],\n",
    "                                   result_gp.x[2],\n",
    "                                   result_gp.x[3],\n",
    "                                   result_gp.x[4],\n",
    "                                   result_gp.x[5],\n",
    "                                   result_gp.x[6],\n",
    "                                   result_gp.x[7]),\n",
    "                                   result_gp.x[8]),\n",
    "                                   result_gp.x[9],\n",
    "                                   result_gp.x[10]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue><b>\n",
    "Mais uma vez, UAAAAU!!\n",
    "    \n",
    "Embora eu tenha mencionado sobre otimização baeysiana em algumas aulas bem en passant, nós não abordamos estes métodos em detalhes pq eles são tecnicamente bem complicados de se entender (imagino que vocês tenham sentido isso quando procurarm pelo método, não é mesmo? rs). Por isso, esse acaba sendo um método de otimização de hiperparâmetros raramente abordado em um primeiro curso, por ser uma técnica bem avançada. Então, fiquei muuuuuito feliz em ter visto que vocês foram atrás e aplicaram esse método, muuuuito bem, de verdade!! Está mais do que claro que vcs não somente absorveram mto bem tudo o que aprendemos no curso, como também desenvolveram super bem a importante habilidade de pesquisa! Parabéns mesmo pessoal, continuem assim!\n",
    "</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4> Com os hiperparâmetros obtidos, estes são adicionados ao modelo para o treinamento do modelo (O atributo .x retorna uma lista com os valores dos hiperparâmetros que resultaram no menor valor da função objetivo)  . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    }
   ],
   "source": [
    "### Treinamento do modelo com os hiperparâmetros obtidos na otimização. \n",
    "\n",
    "mdl = lgb.LGBMClassifier(learning_rate =result_gp.x[0],\n",
    "                             num_leaves = result_gp.x[1],\n",
    "                             min_child_samples = result_gp.x[2],\n",
    "                             n_estimators=result_gp.x[3],\n",
    "                             max_depth = result_gp.x[4],\n",
    "                             random_state=42,\n",
    "                             reg_alpha = result_gp.x[5],\n",
    "                             subsample=result_gp.x[6],\n",
    "                             colsample_bytree=result_gp.x[7],\n",
    "                             reg_lambda = result_gp.x[8],\n",
    "                             min_child_weight = result_gp.x[9],\n",
    "                             min_split_gain = result_gp.x[10])\n",
    "\n",
    "mdl.fit(train,train_labels, eval_set=(train, train_labels),\n",
    "            eval_metric= 'auc',early_stopping_rounds= 200, verbose=1.5) \n",
    "    \n",
    "mdl.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size =4> Aplicação da modelagem junto aos dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_pred=mdl.predict_proba(test)[:,1]\n",
    "\n",
    "submit[\"LGBM_PRED\"] = lgbm_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>PROB_ABORDAGEM_2_RANDOM_FOREST</th>\n",
       "      <th>LGBM_PRED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>149741</td>\n",
       "      <td>0.225538</td>\n",
       "      <td>0.185502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>363290</td>\n",
       "      <td>0.033843</td>\n",
       "      <td>0.042619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>436006</td>\n",
       "      <td>0.094906</td>\n",
       "      <td>0.093070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>377703</td>\n",
       "      <td>0.051528</td>\n",
       "      <td>0.046153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>188624</td>\n",
       "      <td>0.321391</td>\n",
       "      <td>0.229862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61498</th>\n",
       "      <td>102817</td>\n",
       "      <td>0.164420</td>\n",
       "      <td>0.099415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61499</th>\n",
       "      <td>343961</td>\n",
       "      <td>0.110765</td>\n",
       "      <td>0.082015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61500</th>\n",
       "      <td>427828</td>\n",
       "      <td>0.023412</td>\n",
       "      <td>0.033431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61501</th>\n",
       "      <td>405956</td>\n",
       "      <td>0.083919</td>\n",
       "      <td>0.032192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61502</th>\n",
       "      <td>425814</td>\n",
       "      <td>0.071501</td>\n",
       "      <td>0.042937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61503 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SK_ID_CURR  PROB_ABORDAGEM_2_RANDOM_FOREST  LGBM_PRED\n",
       "0          149741                        0.225538   0.185502\n",
       "1          363290                        0.033843   0.042619\n",
       "2          436006                        0.094906   0.093070\n",
       "3          377703                        0.051528   0.046153\n",
       "4          188624                        0.321391   0.229862\n",
       "...           ...                             ...        ...\n",
       "61498      102817                        0.164420   0.099415\n",
       "61499      343961                        0.110765   0.082015\n",
       "61500      427828                        0.023412   0.033431\n",
       "61501      405956                        0.083919   0.032192\n",
       "61502      425814                        0.071501   0.042937\n",
       "\n",
       "[61503 rows x 3 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv(\"submit_squad_azul_2.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusões ##\n",
    "\n",
    "- A técnica de regressão logística por se tratar de um problema de classificação linear apresentou resultados surpreendemente bons. \n",
    "\n",
    "- O mau desempenho do Random Forest em relação aos demais possivelmente está atrelado às definições do hiperparâmetros, necessitando de uma análise mais detalhada nesse sentido.\n",
    "\n",
    "- A técnica de LightGBm por se mais poderosa em relação às demais apresentou um valor de roc visivlemente superior.\n",
    "\n",
    "- O processo de feature engineering foi fundamental no bom desempenho das técnicas de ML utilizadas. O bom desempenho neste caso se baseia nos resultados obtidos por outros programadores para o problema. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue><b>\n",
    "Ótimas conclusões, pessoal! Todas corretas, muito bem observado! (Lembrando que o lightgbm tbm usou otimização bayesiana, então tem isso tbm hehehe).\n",
    " \n",
    "Pelos meus comentários no meio do código, dá pra ver que fique bastante feliz coma solução de vcs, né? Vcs mandaram muito bem mesmo, parabéns!\n",
    "   \n",
    "<br>\n",
    "Além dos comentários pontuais supracitados, a única coisa que eu senti falta foi de uma análise exploratória. Vocês já começaram o notebook com o processo de feature engineering (talvez inspirados em algumas outras soluções que vcs viram, como vcs disseram (e tá tudo certo!!)), mas notem que na vida real dificilmente será possível fazer feature engineering sem que vcs antes conheçam muuuuuito bem o problema e a base de vcs, o que só é possível com extensa EDA. E, bom, eu imagino que vocês tenham sim feito alguma EDA, apenas não colocaram aqui no notebook final, hehe. De qualquer maneira, fica essa dica e o lembrete de que este tempo que passamos explorando a base é de enooooorme importância e necessidade, como fizemos extensivamente no módulo 3 hehe.\n",
    "    \n",
    "Enfim, de maneira geral, curti bastante o trabalho de vcs! Vcs certamente mostraram ter absorvido muuuito bem a essência de tudo o que estudamos nestes meses, então fico bastante feliz! :)\n",
    "</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue><b>\n",
    "___________\n",
    "    \n",
    "Eu enviei pra vocês o arquivo `test_targets.csv`, que contém o target real da base de teste. Vou usá-lo abaixo pra produzir a roc_auc de teste de vcs:\n",
    "</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T20:37:14.686010Z",
     "start_time": "2021-10-20T20:37:14.093378Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T20:37:15.719126Z",
     "start_time": "2021-10-20T20:37:15.653114Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>149741</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>363290</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>436006</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>377703</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>188624</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  TARGET\n",
       "0      149741       1\n",
       "1      363290       0\n",
       "2      436006       0\n",
       "3      377703       0\n",
       "4      188624       0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"test_targets.csv\")\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T20:38:22.876981Z",
     "start_time": "2021-10-20T20:38:22.675742Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>REGRESSÃO_LOGISTICA</th>\n",
       "      <th>RANDOM_FOREST</th>\n",
       "      <th>LGBM_PRED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>149741</td>\n",
       "      <td>0.225538</td>\n",
       "      <td>0.147858</td>\n",
       "      <td>0.185502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>363290</td>\n",
       "      <td>0.033843</td>\n",
       "      <td>0.052104</td>\n",
       "      <td>0.042619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>436006</td>\n",
       "      <td>0.094906</td>\n",
       "      <td>0.116577</td>\n",
       "      <td>0.093070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>377703</td>\n",
       "      <td>0.051528</td>\n",
       "      <td>0.062726</td>\n",
       "      <td>0.046153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>188624</td>\n",
       "      <td>0.321391</td>\n",
       "      <td>0.159345</td>\n",
       "      <td>0.229862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  REGRESSÃO_LOGISTICA  RANDOM_FOREST  LGBM_PRED\n",
       "0      149741             0.225538       0.147858   0.185502\n",
       "1      363290             0.033843       0.052104   0.042619\n",
       "2      436006             0.094906       0.116577   0.093070\n",
       "3      377703             0.051528       0.062726   0.046153\n",
       "4      188624             0.321391       0.159345   0.229862"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred = pd.read_csv(\"submit_squad_azul.csv\", sep=\";\")\n",
    "\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T20:38:34.163074Z",
     "start_time": "2021-10-20T20:38:34.116099Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>REGRESSÃO_LOGISTICA</th>\n",
       "      <th>RANDOM_FOREST</th>\n",
       "      <th>LGBM_PRED</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>149741</td>\n",
       "      <td>0.225538</td>\n",
       "      <td>0.147858</td>\n",
       "      <td>0.185502</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>363290</td>\n",
       "      <td>0.033843</td>\n",
       "      <td>0.052104</td>\n",
       "      <td>0.042619</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>436006</td>\n",
       "      <td>0.094906</td>\n",
       "      <td>0.116577</td>\n",
       "      <td>0.093070</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>377703</td>\n",
       "      <td>0.051528</td>\n",
       "      <td>0.062726</td>\n",
       "      <td>0.046153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>188624</td>\n",
       "      <td>0.321391</td>\n",
       "      <td>0.159345</td>\n",
       "      <td>0.229862</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  REGRESSÃO_LOGISTICA  RANDOM_FOREST  LGBM_PRED  TARGET\n",
       "0      149741             0.225538       0.147858   0.185502       1\n",
       "1      363290             0.033843       0.052104   0.042619       0\n",
       "2      436006             0.094906       0.116577   0.093070       0\n",
       "3      377703             0.051528       0.062726   0.046153       0\n",
       "4      188624             0.321391       0.159345   0.229862       0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge = df_pred.merge(df_test, on=\"SK_ID_CURR\", how=\"inner\")\n",
    "\n",
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T20:49:37.786090Z",
     "start_time": "2021-10-20T20:49:37.680232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC de teste para o modelo REGRESSÃO_LOGISTICA: 0.7448\n",
      "\n",
      "ROC-AUC de teste para o modelo RANDOM_FOREST: 0.7315\n",
      "\n",
      "ROC-AUC de teste para o modelo LGBM_PRED: 0.7468\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "y_true = df_merge[\"TARGET\"]\n",
    "\n",
    "for col in ['REGRESSÃO_LOGISTICA', 'RANDOM_FOREST', 'LGBM_PRED']:\n",
    "    \n",
    "    y_score = df_merge[col]\n",
    "\n",
    "    print(f\"ROC-AUC de teste para o modelo {col}: {roc_auc_score(y_true, y_score):.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue><b>\n",
    "Boaaa, esses são resultados beeeem legais, parabéns!! De fato, o trabalho de feature engineering que vcs fizeram certamente contribuiu bastante pra esse resultado legal -- o que corrobora mais uma vez como o processo de EDA/data wrangling é FUNDAMENTAL para um bom resultado em projetos de data science!!\n",
    "    \n",
    "De fato, é muito legal ver que o logit ficou bem próximo do lgbm, né?? Modelos lineares, quando bem usados, são extremamente poderosos!!\n",
    "    \n",
    "E notem que os scores na base teste tão bem próximos dos scores de CV, bem legal! ;)\n",
    "</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue><b>\n",
    "Parabéns, pessoal! Espero que vocês tenha curtido a experiência do projeto e de todo esse tempo que passamos juntos!\n",
    "    \n",
    "Mais uma vez, desejo muuuito sucesso na vida e carreira de vocês! \n",
    "    \n",
    "Valeu, galera -- e nos vemos no happy hour! ;)\n",
    "</b></font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
