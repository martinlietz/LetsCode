{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 3 - Regressão Logística\n",
    "\n",
    "Na aula de hoje, vamos explorar os seguintes tópicos em Python:\n",
    "\n",
    "- 1) Introdução\n",
    "- 2) Regressão logística\n",
    "- 4) Métricas de performance para problemas de classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "____\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Introdução\n",
    "\n",
    "**Problemas de Classificação** são aqueles em que queremos determinar a que **CATEGORIA** dentro de um **CONJUNTO DE CATEGORIAS** uma dada observação pertence, com base em suas features.\n",
    "\n",
    "Para isso, construímos um **CLASSIFICADOR**: modelo que tem como input as features (contínuas ou discretas) e como output uma entre as classes (discretas)\n",
    "\n",
    "\n",
    "Principal diferença entre problemas de regressão e classificação:\n",
    "- Regressão: valores contínuos;\n",
    "- Classificação: valores (classes) discretas (binárias ou não).\n",
    "\n",
    "<img src=\"https://i0.wp.com/vinodsblog.com/wp-content/uploads/2018/11/Classification-vs-Regression.png?fit=2048%2C1158&ssl=1\" width=700>\n",
    "\n",
    "\n",
    "<img src=\"https://i.pinimg.com/originals/71/8e/6a/718e6a40e1782bead960e58d3c52663b.png\" width=300>\n",
    "\n",
    "Exemplos de problemas de classificação:\n",
    "- Detecção de e-mails SPAM: um e-mail é SPAM ou não?;\n",
    "    - Features: palavras contidas no corpo do e-mail; remetente; assunto;\n",
    "- Detecção de doenças: que codição médica a pessoa tem?\n",
    "    - Features: sintomas fisiológicos; resultados de exames (medidas de variáveis biológicas);\n",
    "- Detecção do tipo de documento: secreto, confidencial ou não-sensível?\n",
    "    - Features: palavras no corpo do texto; título;\n",
    "- Detecção de fraudes de cartão de crédito: uma operação é fraudulenta ou não?;\n",
    "    - Features: histórico de transações; hora, local e frequência das transações; tipo de compra;\n",
    "- Modelo de risco de crédito: qual é a chance de determinada pessoa não pagar seu empréstimo?\n",
    "    - Features: histórico de pagamento; score de crédito;\n",
    "    \n",
    "    \n",
    "<img src=\"https://developers.google.com/machine-learning/guides/text-classification/images/TextClassificationExample.png\" width=500>\n",
    "\n",
    "\n",
    "\n",
    "Veremos hoje um dos mais simples e poderosos classificadores: a **Regressão Logística!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Regressão Logística\n",
    "\n",
    "A [Regressão Logística](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) (também chamado de **logit**), apesar do nome, é um método utilizado para classificação!\n",
    "\n",
    "- Classificação binária: duas classes (0 e 1);\n",
    "- Classificação multiclasse: n classes (0, 1, ..., n-1), com $n \\in \\mathbb{N}$\n",
    "\n",
    "O objetivo da regressão logística é: **modelar a PROBABILIDADE $P(x)$ de dada observação (com features $x$) pertencer à classe 1**, ou seja, queremos encontrar um modelo que nos dê:\n",
    "\n",
    "$$ P( x \\in 1 | x) $$\n",
    "\n",
    "Naturalmente, $0 \\le P(x) \\le 1$. Assim, por exemplo, se:\n",
    "- $P(x) \\ge 0,5$: x pertence à classe 1\n",
    "- $P(x) < 0.5$: x pertence à classe 0\n",
    "\n",
    "Obs.: este valor de 0.5 (50%) é chamado de \"cutoff\", e pode ser ajustado, embora seja comum fixá-lo em 50%!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poderíamos pensar em utilizar a regressão linear em nossos problemas de classificação, mas isso não é uma boa ideia: acabamos encontrando probabilidades negativas e fit ruim!\n",
    "\n",
    "No exemplo a seguir, temos a probabilidade de não-pagamento (default) de um empréstimo com base em uma feature (balanço). Note probabilidades negativas!\n",
    "\n",
    "<figure>\n",
    "    <img src=\"https://s3-sa-east-1.amazonaws.com/lcpi/70189f79-2886-4e59-893b-1dac9dd64078.png\" height=\"400\" width=\"400\">\n",
    "    <figcaption>\n",
    "        Regressão Linear para classificação. Fonte: \n",
    "        <a href=\"http://faculty.marshall.usc.edu/gareth-james/ISL/\">ISLR</a>\n",
    "    </figcaption>\n",
    "</figure> \n",
    "\n",
    "Para resolver este problema, podemos adaptar a função de regressão linear para uma função que tem imagem entre 0 e 1. Seria legal se tivéssemos algo como:\n",
    "\n",
    "<figure>\n",
    "    <img src=\"https://s3-sa-east-1.amazonaws.com/lcpi/6d54529a-d295-47a3-8a11-1f426fde7229.png\" height=\"400\" width=\"400\">\n",
    "    <figcaption>\n",
    "        Classificador. Fonte: \n",
    "        <a href=\"http://faculty.marshall.usc.edu/gareth-james/ISL/\">ISLR</a>\n",
    "    </figcaption>\n",
    "</figure> \n",
    "\n",
    "Um exemplo de tal função é a FUNÇÃO LOGÍSTICA ou FUNÇÃO SIGMOIDAL:\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/970/1*Xu7B5y9gp0iL5ooBj7LtWw.png\" width=400>\n",
    "\n",
    "Note que:\n",
    "- $z \\in \\mathbb{R}$\n",
    "- $0 \\le \\phi(z) \\le 1$\n",
    "\n",
    "Para incorporar a ideia da regressão linear na regressão logística, tomamos:\n",
    "\n",
    "- $z = \\beta_0 + \\beta_1x$, que é o modelo de regressão linear (uma variável);\n",
    "\n",
    "E substituímos na função logística:\n",
    "\n",
    "- $\\phi(x) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 x)}}$\n",
    "\n",
    "Com isso, tomamos qualquer output real do modelo linear e transformamos em um valor entre 0 e 1, como queríamos!\n",
    "\n",
    "<img src=\"http://juangabrielgomila.com/wp-content/uploads/2015/04/LogReg_1.png\" width=\"500\">\n",
    "\n",
    "No nosso caso, como queremos modelar probabilidades, tomamos, no caso de uma feature:\n",
    "\n",
    "$P(x) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 x)}}$\n",
    "\n",
    "Ou, para a regressão logística múltipla com $p$ features:\n",
    "\n",
    "$P(x_1, \\cdots, x_p) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 x_1 + \\cdots + \\beta_p x_p)}}$\n",
    "\n",
    "Com um pouco de álgebra, é possível mostrar que: \n",
    "\n",
    "$ \\beta_0 + \\beta_1 x_1 + \\cdots + \\beta_p x_p = \\log \\left ( \\frac{P}{1-P} \\right ) $\n",
    "\n",
    "A quantidade $\\frac{P}{1-P}$ é conhecida como **odds/chance**; e $\\log \\left ( \\frac{P}{1-P} \\right )$ é o [log-odds ou logit](https://en.wikipedia.org/wiki/Logit).\n",
    "\n",
    "Note, portanto, que podemos entender a regressão logística como um modelo em que **o logit é linear com as features**. Portanto, de fato, a regressão logística é **um modelo linear**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "### Função de perda e algoritmo de aprendizagem\n",
    "\n",
    "A função de perda para a regressão logística é a famosa [binary cross-entropy](https://towardsdatascience.com/understanding-binary-cross-entropy-log-loss-a-visual-explanation-a3ac6025181a), também conhecida como [log loss](https://developers.google.com/machine-learning/crash-course/logistic-regression/model-training)\n",
    "\n",
    "Esta função será de enorme importância no estudo de **redes neurais**.\n",
    "\n",
    "As principais implementações do algoritmo de aprendizagem da regressão logística se baseia no [método de máxima verossimilhança](https://pt.wikipedia.org/wiki/M%C3%A1xima_verossimilhan%C3%A7a). \n",
    "\n",
    "Para maiores detalhes sobre o algoritmo de aprendizagem, veja [este vídeo](https://youtu.be/yIYKR4sgzI8) e [esta série de vídeos](https://youtu.be/vN5cNN2-HWE), do ótimo canal StatQuest!\n",
    "\n",
    "\n",
    "_________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________________\n",
    "\n",
    "Para introduzirmos as ideias, utilizaremos um dataset de marketing (propagandas/advertising), que está disponível no <a href=\"https://www.kaggle.com/fayomi/advertising\">Kaggle</a>. Este é um dataset artificial e didático, com os dados bem separáveis, o que é ótimo para ilustração!<br>\n",
    "\n",
    "Visite o Kaggle e procure por \"advertising\" para datasets relacionados reais e ainda mais interessantes\n",
    "\n",
    "A base que utilizaremos contém as seguintes colunas:\n",
    "\n",
    "* 'Daily Time Spent on Site': tempo que o cliente ficou no site (em minutos);\n",
    "* 'Age': idade do cliente (em anos);\n",
    "* 'Area Income': média salarial (por ano) da região geográfica do cliente;\n",
    "* 'Daily Internet Usage': tempo médio (em minutos) que o cliente fica na internet;\n",
    "* 'Ad Topic Line': título do anúncio;\n",
    "* 'City': cidade do cliente;\n",
    "* 'Male': dummy indicando se o cliente é do sexo masculino (1) ou não (0);\n",
    "* 'Country': país do cliente;\n",
    "* 'Timestamp': marcação de tempo em que o cliente clickou no anúncio OU fechou a página\n",
    "* 'Clicked on Ad': dummy indicando se o cliente clickou no anúncio (1) ou não (0).\n",
    "\n",
    "Nosso objetivo é criar um modelo que possa prever se um determinado usuário clickará em um anúncio online ou não, com base em suas características pessoais/comportamentais, bem como informações relativas ao anúncio.\n",
    "\n",
    "Tomamos como variáveis independentes (preditores/features) as primeiras 9 colunas, enquanto nossa variável dependente (target) é a última coluna (\"Clicked on Ad\").\n",
    "\n",
    "Ou seja, nosso modelo deve ser capaz de dizer se um usuário com um conjunto particular das 9 features clickará no anúncio ou não. \n",
    "\n",
    "__IMPORTANTE!__\n",
    "\n",
    "Pense no problema de negócio que estamos querendo resolver com nosso modelo -- direcionamento de marketing! Temos os dados dos nossos clientes (customer-centric), nós os conhecemos! Não podemos utilizar essa informação a nosso favor?\n",
    "\n",
    "Talvez não faça sentido exibir o anúncio para um usuário que tem baixa probabilidade de clickar no ad, não é mesmo? \n",
    "\n",
    "Por outro lado, é muito mais eficiente direcionar nosso marketing aos clientes com alta chance de clickar no nosso anúncio!\n",
    "\n",
    "Assim, economizamos dinheiro (todo anúncio é pago!), e ganhamos em eficiência e alcance!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T01:37:58.380936Z",
     "start_time": "2020-02-14T01:37:54.673709Z"
    }
   },
   "outputs": [],
   "source": [
    "# importe as principais bibliotecas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código abaixo é apenas para formatar os números em até 3 casas decimais. \n",
    "\n",
    "Fica aqui pra conhecimento e também pq vai nos auxiliar a ver melhor as probabilidades no final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "np.set_printoptions(suppress=True, precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T01:37:58.542928Z",
     "start_time": "2020-02-14T01:37:58.384972Z"
    }
   },
   "outputs": [],
   "source": [
    "# leia os dados em '../datasets/advertising.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T01:37:58.576564Z",
     "start_time": "2020-02-14T01:37:58.549180Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# de uma olhada nas 5 primeiras linhas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dê uma olhada no info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T01:37:58.709069Z",
     "start_time": "2020-02-14T01:37:58.580977Z"
    }
   },
   "outputs": [],
   "source": [
    "# olhe as estatísticas básicas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T01:37:58.731197Z",
     "start_time": "2020-02-14T01:37:58.711810Z"
    }
   },
   "source": [
    "Alguma observação notável?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dê uma olhada na distribuição do target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos um dataset balanceado no target, o que __bem raro na vida real!__\n",
    "\n",
    "Um dataset desbalanceado pode causar sérios problemas de performance ao modelo! Há várias técnicas para lidar com tal problema, mas, neste primeiro exemplo, não nos preocuparemos com isso..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T01:38:00.441491Z",
     "start_time": "2020-02-14T01:37:58.735817Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# dê uma olhada na distribuição das variáveis numéricas\n",
    "# lembre do df.select_dtypes(include=[np.number])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T01:40:34.906627Z",
     "start_time": "2020-02-14T01:40:27.142434Z"
    }
   },
   "outputs": [],
   "source": [
    "# faça um pairplot usando o hue como target -- isso é sempre uma boa prática em problemas de classificação!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como tínhamos comentado no início, nossos dados são muito bem separáveis!\n",
    "\n",
    "Isto favorece bastante a performance do nosso modelo. Mas, lembre-se, é bem raro encontrar casos assim na vida real! (É aí que devemos partir para métodos mais avançados, como SVM, árvores, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos começar a construir o modelo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T01:38:45.783214Z",
     "start_time": "2020-02-14T01:38:43.497774Z"
    }
   },
   "outputs": [],
   "source": [
    "# crie as variáveis X e y, com as features e o target\n",
    "# utilize todas as features numéricas - dica: df.select_dtypes(include=[np.number])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Importe a classe do estimador que se deseja treinar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Instancie a classe do estimador, escolhendo os hiperparâmetros desejados (não há muitos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Separe os dados em dados de treino e dados de teste\n",
    "# dica: procure pelo \"train_test_split\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Treine o modelo, usando os dados de treino. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Modelo treinado!__\n",
    "\n",
    "Vamos ver os coeficientes do modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T01:38:46.192778Z",
     "start_time": "2020-02-14T01:38:46.187346Z"
    }
   },
   "outputs": [],
   "source": [
    "# capture e exiba o intercept e os demais coeficientes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lembre-se que, diferentemente da regressão linear, devido ao fato da função logística ser uma exponencial, a variação de $P(x)$ depende de x, e não apenas dos coeficientes! Então, a interpretação dos coeficientes não é tão imediata. \n",
    "\n",
    "Mas, os sinais carregam significado. Para um coeficiente:\n",
    "- positivo ($\\beta_i > 0$), temos que um aumento em x levará a um aumento de $P(x)$;\n",
    "- negativo ($\\beta_i < 0$), temos que um aumento em x levará a uma diminuição de $P(x)$\n",
    "\n",
    "Mas, a variacão de $P(x)$ em si, depende do valor de x!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Agora que o modelo está treinado, vamos avaliá-lo!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______\n",
    "_____\n",
    "_____\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Métricas de performance para problemas de classificação\n",
    "\n",
    "Após treinar o modelo, como podemos avaliar sua performance?\n",
    "\n",
    "No caso de problemas de classificação, existem **métricas específicas**, e também um importante conceito chamado de **Matriz de Confusão**.\n",
    "\n",
    "A **matriz de confusão** leva em consideração as **classes preditas** e as **classes verdadeiras** da base de **teste**, e contabiliza a performance do modelo:\n",
    "\n",
    "<img src=https://diegonogare.net/wp-content/uploads/2020/04/matrizConfusao-600x381.png height=\"400\" width=\"400\">\n",
    "\n",
    "No Sklearn, a notação muda um pouco:\n",
    "\n",
    "<img src=\"https://static.packt-cdn.com/products/9781838555078/graphics/C13314_06_05.jpg\" width=400>\n",
    "\n",
    "Note que a diagonal principal são as observações que o modelo acertou! Temos:\n",
    "\n",
    "- Verdadeiros Positivos (VP): classificação correta da classe positivo;\n",
    "- Verdadeiros Negativos (VN): classificação correta da classe negativo;\n",
    "- Falsos Positivos (FP, erro tipo I): correto: negativo. Previsto: positivo.\n",
    "- Falsos Negativos (FN, erro tipo II): correto: positivo. Previsto: negativo.\n",
    "\n",
    "Um jeito fácil de lembrar os tipos de erros:\n",
    "\n",
    "\n",
    "<img src=\"https://i.pinimg.com/originals/f6/9b/11/f69b111014ef466fe541a393346d2c3a.jpg\" height=\"400\" width=\"400\">\n",
    "\n",
    "\n",
    "Além disso, temos as seguintes métricas numéricas de avaliação:\n",
    "\n",
    "- Acurácia (Accuracy): porcentagem de classificações CORRETAS do modelo;\n",
    "\n",
    "- Precisão (Precision): das respostas retornadas, quantas são relevantes? -- é a razão entre verdadeiros positivos e o  número de **preditos positivos**, isto é, positivos quanto à **label predita pelo modelo**.\n",
    "\n",
    "- Revocação/Sensibilidade (Recall/Sensitivity): das respostas relevantes, quantas são retornadas? -- é a razão entre verdadeiros positivos e o  número de **verdadeiramente positivos**, isto é, positivos quanto à **label real**.\n",
    "\n",
    "- F1-Score: média harmônica de precision e recall.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/1200px-Precisionrecall.svg.png\" width=450>\n",
    "\n",
    "Devido ao <a href=\"https://medium.com/opex-analytics/why-you-need-to-understand-the-trade-off-between-precision-and-recall-525a33919942\">tradeoff entre precision e recall</a>, a métrica a ser otimizada é o F1! \n",
    "\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1080/1*t1vf-ofJrJqtmam0KSn3EQ.png\" height=\"400\" width=\"400\">\n",
    "\n",
    "Adiante, veremos como calcular a matriz de confusão e as métricas acima para problemas de classificação!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T01:38:46.295698Z",
     "start_time": "2020-02-14T01:38:46.194931Z"
    }
   },
   "outputs": [],
   "source": [
    "# 5) Use o modelo treinado para fazer previsões usando os dados de teste \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vimos no passo 2, em problemas de classificação é muito comum utilizarmos a **matriz de confusão** e as **métricas de classificação** para avaliar nossos modelos.\n",
    "\n",
    "Dado isso, o sklearn já disponibilica estas funcionalidades:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T01:38:46.362889Z",
     "start_time": "2020-02-14T01:38:46.297731Z"
    }
   },
   "outputs": [],
   "source": [
    "# 6) Avalie a performance do modelo com base nas previsões acima\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conforme esperado, nosso modelo está muito bom! Um f1-score tão alto na vida real é algo notável!\n",
    "\n",
    "Isso se deve à grande separabilidade dos nossos dados!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Além dos coeficientes do modelo, algo muito interessante que a classe do sklearn tem é o método `predict_proba()`\n",
    "\n",
    "Esse método retorna exatamente qual é a probabilidade modelada pelo logit.\n",
    "\n",
    "Isso pode ser muito útil, pois assim conseguimos **mudar qual é o threshold de esclha de classe** para ser algo diferente de 0.5!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use o atributo classes_ para captar as classes do modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calcule as probabilidades com o método predict_proba()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine a classe através da seguinte lógica:\n",
    "# se a p(x=1) > threshold, é classe 1, se não, classe 0\n",
    "# dica: use o np.where()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos avaliar diferentes cutoffs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# leia a base\n",
    "df = pd.read_csv(\"../datasets/advertising.csv\")\n",
    "\n",
    "# apenas as features numericas\n",
    "df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "# separe as features e o target\n",
    "X = df.drop(columns = 'Clicked on Ad')\n",
    "y = df['Clicked on Ad']\n",
    "\n",
    "# 1) importe a classe do classificador\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 2) instancie a classe\n",
    "estimador = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# 3) faça o train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "# 4) treine o modelo\n",
    "modelo = estimador.fit(X_train, y_train)\n",
    "\n",
    "# dê uma olhada nos coeficientes\n",
    "print(\"Coeficientes:\\n\", modelo.coef_)\n",
    "print(\"\\nIntercept:\", modelo.intercept_)\n",
    "\n",
    "# dê uma olhada nas classes do modelo\n",
    "classes =  modelo.classes_\n",
    "print(\"\\nClasses:\", classes)\n",
    "\n",
    "# 5) probabilidades das previsões\n",
    "probs = modelo.predict_proba(X_test)\n",
    "\n",
    "# probabilidade de pertencimento à classe 0\n",
    "probs_0 = probs[:, 0]\n",
    "\n",
    "# avaliação  do modelo\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "threshold_list = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "\n",
    "print(\"\\n###################################################\\n\")\n",
    "print(\"Avaliação de modelos com diferentes valores de cutoff\")\n",
    "print(\"\\n###################################################\\n\")\n",
    "\n",
    "for threshold in threshold_list:\n",
    "    \n",
    "    print(\"\\n Cutoff:\", threshold)\n",
    "    \n",
    "    # previsões\n",
    "    y_pred = np.where(probs_0 > threshold, 0, 1)\n",
    "\n",
    "    print(\"\\nMatriz de confusão do modelo nos dados de teste:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    print(\"\\nClassification report do modelo nos dados de teste:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print(\"\\n##########################################################\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E se tivermos uma classificação multiclasse?\n",
    "\n",
    "Há problemas em que temos um problema de **classificação multiclasse**, pois há mais do que duas classes a serem preditas.\n",
    "\n",
    "<img src=\"https://utkuufuk.com/2018/06/03/one-vs-all-classification/one-vs-all.png\">\n",
    "\n",
    "Boa noitícia: o operacional de construção e avaliação do modelo com o sklearn muda em absolutamente **nada**.\n",
    "\n",
    "No entanto, conceitualmente, há algumas mudanças: a rigor, o modelo passa a se chamar **regresão logística MULTINOMIAL**, cujo processo de classificação é dado pela função **softmax**:\n",
    "\n",
    "<img src=\"https://i.stack.imgur.com/YLeRi.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para quem quiser saber mais sobre o \"logit score\", [clique aqui](https://stats.stackexchange.com/questions/329857/what-is-the-difference-between-decision-function-predict-proba-and-predict-fun).\n",
    "\n",
    "Essencialmente, esse é o valor do termo linear usado como argumento da sigmoide, isto é, $z(x) = \\beta_0 + \\beta_1 x_1 + \\cdots + \\beta_p x_p$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "249.667px",
    "width": "359.667px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
