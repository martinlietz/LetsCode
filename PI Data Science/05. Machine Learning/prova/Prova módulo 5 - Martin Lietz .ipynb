{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Prova módulo 5\n",
    "\n",
    "_____\n",
    "_____\n",
    "_____"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**1) Julgue a afirmativa a seguir como verdadeira ou falsa, justificando sua resposta se a afirmativa for falsa**\r\n",
    "\r\n",
    "> Há situações em que a resolução de um problema de negócio demanda o desenvolvimento de um modelo preditivo. Nestes casos, é comum seguirmos uma abordagem data-driven, comumente apoiada por técnicas de aprendizagem de máquina. Neste contexto, podemos dizer que um modelo de machine learning nada mais é do que uma representação matemática do problema sob análise, construído teoricamente a partir dos princíios fundamentais que regem o problema sob análise.\r\n",
    "\r\n",
    "( ) Verdadeiro\r\n",
    "\r\n",
    "(x ) Falso\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color=red>\r\n",
    "Justificativa:</font> \r\n",
    "*Falso* o processo teórico F é modelado pela função hipótese f, que é parametrizada. A determinação dos parâmetros é feita pelo algoritmo de aprendizagem com os dados na base de treino e não ```teoricamente```\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "__________\n",
    "__________"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**2) Julgue a afirmativa a seguir como verdadeira ou falsa, justificando sua resposta se a afirmativa for falsa**\r\n",
    "\r\n",
    "> Utilizamos uma abordagem data-driven, baseada em aprendizagem de máquina, em problemas tais que:\r\n",
    "- Existe um parão a ser descoberto (processo teórico $\\mathcal{F}$ que rege o problema);\r\n",
    "- Uma descrição teóricas não é praticável;\r\n",
    "- Existam dados coletados sobre o problema, isto é, amostras geradas pelo proceso teórico $\\mathcal{F}$.\r\n",
    "\r\n",
    "(x ) Verdadeiro\r\n",
    "\r\n",
    "( ) Falso\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color=red>Justificativa</font>    \r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "__________\n",
    "__________"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**3) Julgue a afirmativa a seguir como verdadeira ou falsa, justificando sua resposta se a afirmativa for falsa**\r\n",
    "\r\n",
    "> Para aferir a capacidade de generalização de um modelo supervisionado, é muito importante que o volume de dados original seja separado nas amostras de treino e de teste. \r\n",
    "<br>\r\n",
    "O modelo é treinado utilizando os dados de treino; e os dados de teste são utilizados ao fim do processo, para avaliar sua performance em dados não vistos em treinamento, aferindo, assim, sua capacidade de generalização.\r\n",
    "\r\n",
    "(x ) Verdadeiro\r\n",
    "\r\n",
    "( ) Falso\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color=red>\n",
    "Justificativa aqui\n",
    "</font>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "__________\n",
    "__________"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**4) Considere a figura a seguir, sobre o famoso tradeoff *viés/variância* (*bias/variance*):**\r\n",
    "\r\n",
    "<img src=https://www.learnopencv.com/wp-content/uploads/2017/02/Bias-Variance-Tradeoff-In-Machine-Learning-1.png width=400>\r\n",
    "\r\n",
    "Sobre este tradeoff, avalie as afirmativas a seguir como verdadeiras ou falsas:\r\n",
    "\r\n",
    "- 1 - Dizemos que um modelo tem **alto viés** (bias), se ele sofre de **underfitting**, isto é, se a diferença entre os erros de treino e teste/validação é pequena, e ambos são grandes;\r\n",
    "\r\n",
    "- 2 - Dizemos que um modelo tem **alta variância** (variance), se ele sofre de **overfitting**, isto é, se a diferença entre os erros de treino e teste/validação é muito grande, sendo os erros de teste/validação muito maiores que os erros de treino; \r\n",
    "\r\n",
    "Julgando as afirmativas 1 e 2, temos, respectivamente:\r\n",
    "\r\n",
    "( x) Verdadeiro / Verdadeiro\r\n",
    "\r\n",
    "( ) Falso / Verdadeiro\r\n",
    "\r\n",
    "( ) Verdadeiro / Falso\r\n",
    "\r\n",
    "( ) Falso / Falso\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color=red>\n",
    "Justificativa aqui\n",
    "</font>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "__________\n",
    "__________"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**5) Considere a figura a seguir, sobre métricas de avaliação de problemas de classificação:**\r\n",
    "\r\n",
    "<img src=https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/1200px-Precisionrecall.svg.png width=200>\r\n",
    "\r\n",
    "Neste contexto, julgue a afirmativa a seguir como verdadeira ou falsa, justificando sua resposta se a afirmativa for falsa:\r\n",
    "\r\n",
    "> Em um sistema/teste de detecção de doenças extremamente contagiosas, é muito importante que o modelo consiga capturar corretamente todas as pessoas que estão de fato doentes, mesmo que isso implique em indicar erroneamente que algumas pessoas saudáveis estão doentes. Ou seja, em um sistema desses, é importante que os **falsos negativos** sejam minimizados; portanto, o objetivo é **maximizar** a métrica **precision**.\r\n",
    "\r\n",
    "( ) Verdadeiro\r\n",
    "\r\n",
    "( x) Falso\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color=red>\r\n",
    "Justificativa</font>\r\n",
    "\r\n",
    " Falso, porque queremos diminuir os falsos positivos, o correto é usar Recall  = $\\frac{TP}{TP+FN}$ Quanto menor os FN's melhor o resultado.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "__________\n",
    "__________"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**6) Julgue a afirmativa a seguir como verdadeira ou falsa, justificando sua resposta se a afirmativa for falsa**\r\n",
    "\r\n",
    "> O método de regressão linear é capaz de gerar, unicamente, hipóteses lineares, pelo fato de ser linear nas features. Por este motivo, é impossível, por exemplo, que um modelo construído com o método de regressão linear descreva bem um conjunto de dados que são quadrátivos, independente do tipo de pré-processamento que for aplicado às features.\r\n",
    "\r\n",
    "( ) Verdadeiro\r\n",
    "\r\n",
    "( x) Falso\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color=red>\r\n",
    "Justificativa</font> Podemos usa e.g. Z=x**2 como um fator e assim não so definir hipoteses lineares.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "__________\n",
    "__________"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**7) Julgue a afirmativa a seguir como verdadeira ou falsa, justificando sua resposta se a afirmativa for falsa**\r\n",
    "\r\n",
    "> No método de regressão logística aplicado à classificação binária, modelamos explicitamente a probabilidade de uma dada observação pertencer a uma das classes (comumente a classe 1), isto é, $P(y=1 \\mid \\vec{x})$. No entanto, a decisão final de classificação é tomada ao escolhermos um threshold, que corta a probabilidade modelada em duas regiões, cada uma referente a uma das classes. Ex.: threshold de 0.5, é tal que se $P(y=1 \\mid \\vec{x}) > 0.5$, atribuímos $\\hat{y} = 1$ para a observação $\\vec{x}$; caso contrário, $\\hat{y}=0$.\r\n",
    "\r\n",
    "(x ) Verdadeiro\r\n",
    "\r\n",
    "( ) Falso\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color=red>\n",
    "Justificativa aqui\n",
    "</font>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "__________\n",
    "__________"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**8) Julgue as afirmativas a seguir como verdadeiras ou falsas, justificando sua resposta para as afirmativas falsas, se houver alguma**\r\n",
    "\r\n",
    "> - 1 - Com a aplicação de técnicas de regularização, overfitting é evitado a partir da redução do espaço de hipóteses acessível;\r\n",
    "\r\n",
    "> - 2 - A regularização L1 (lasso), pode implementar feature selection, ao efetivamente zerar os parâmetros referentes a determinadas features;\r\n",
    "\r\n",
    "> - 3 - A regularização L2 (ridge), pode implementar feature selection, ao efetivamente zerar os parâmetros referentes a determinadas features;\r\n",
    "\r\n",
    "\r\n",
    "Julgando as afirmativas 1, 2 e 3, temos, respectivamente:\r\n",
    "\r\n",
    "( x) Verdadeiro / Verdadeiro / Falso\r\n",
    "\r\n",
    "( ) Verdadeiro / Verdadeiro / Verdadeiro\r\n",
    "\r\n",
    "( ) Verdadeiro / Falso / Verdadeiro\r\n",
    "\r\n",
    "( ) Falso / Falso /    Falso\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color=red>Justificativa</font>\r\n",
    "Só a L1 consegue ```zerar``` features. Na L2 podemos quase chegar a 0 mas nunca chega a zerar.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "__________\n",
    "__________"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**9) Julgue a afirmativa a seguir como verdadeira ou falsa, justificando sua resposta se a afirmativa for falsa**\r\n",
    "\r\n",
    "> A validação cruzada é uma técnica muito importante para que tenhamos estatísticas para as métricas de avaliação, sendo também muito utilizada para a determinação de valores adequados para hiperparâmetros de modelos, contribuindo para evitar overfitting.\r\n",
    "\r\n",
    "(x ) Verdadeiro\r\n",
    "\r\n",
    "( ) Falso\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color=red>\n",
    "Justificativa aqui\n",
    "</font>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "__________\n",
    "__________"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**10) Julgue as afirmativas a seguir como verdadeiras ou falsas, justificando sua resposta para as afirmativas falsas, se houver alguma**\r\n",
    "\r\n",
    "> - 1 - O método KNN pode ser usado tanto para classificação quanto para regressão, e consiste em atribuir o target a uma observação de teste como sendo a média dos targets das $k$ observações de treino mais próximas à observação de teste (no caso de classificação, esta \"média\" pode ser entendida como um voto de maioria);\r\n",
    "\r\n",
    "> - 2 - Pensando nos extremos dos valores de $k$: quando $k=1$, o modelo tem alto viés; e quando $k=n$ ($n$ é o número de observações na base de treino), o modelo tem alta variância.\r\n",
    "\r\n",
    "\r\n",
    "Julgando as afirmativas 1 e 2, temos, respectivamente:\r\n",
    "\r\n",
    "( ) Verdadeiro / Verdadeiro\r\n",
    "\r\n",
    "( ) Falso / Verdadeiro\r\n",
    "\r\n",
    "(x) Verdadeiro / Falso\r\n",
    "\r\n",
    "( ) Falso / Falso"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color=red>Justificativa</font>\r\n",
    "\r\n",
    "k=1 quase sempre gera alta variancia(overfitting) e k=n alto viés, a ideia de KNN é de reduzir ruído, outliers etc. com um $k \\ne (1,n)$ o sistema pode ser mais robusto. Mais usado +- um k=10\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "__________\n",
    "__________"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**11) Julgue a afirmativa a seguir como verdadeira ou falsa, justificando sua resposta se a afirmativa for falsa**\r\n",
    "\r\n",
    "> Árvores de decisão são modelos simples e interpretáveis. A árvore determina, com base nos dados de treino, quais features devem ser utilizadas como critério de quebra em cada nó, utilizando-se comumente dos critérios de entropia ou gini para reliar esta determinação. No caso de classificação, os critérios têm como objetivo aumentar a separabilidade das classes do target a cada quebra; enquanto no caso de regressão, os critérios têm como objetivo diminuir o erro (quadrático, por exemplo) entre o target predito e real a cada quebra.\r\n",
    "\r\n",
    "(x ) Verdadeiro\r\n",
    "\r\n",
    "( ) Falso\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color=red>\n",
    "Justificativa aqui\n",
    "</font>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "__________\n",
    "__________"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**12) Julgue a afirmativa a seguir como verdadeira ou falsa, justificando sua resposta se a afirmativa for falsa**\r\n",
    "\r\n",
    "> O random forest é um método de ensemble que se utiliza da metodologia de bagging para gerar modelos que são sequencialmente melhorados levando em consideração os erros cometidos pelos modelos anteriores; Já o adaboost se utiliza do procedimento de boosting para gerar árvores independentes entre si, cujo compartamento coletivo é levado em consideração para a predição final.\r\n",
    "\r\n",
    "( ) Verdadeiro\r\n",
    "\r\n",
    "(x ) Falso\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color=red>Justificativa</font>\r\n",
    "\r\n",
    "Falso, porque esta invertido o Boosting melhora considerando os erros anteriores. Bagging( Bootstrap aggregating) bootstrap quer dizer aleatoriamente gerar arvores e depois juntamos os resultados(aggregating)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "__________\n",
    "__________"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**13) Julgue a afirmativa a seguir como verdadeira ou falsa, justificando sua resposta se a afirmativa for falsa**\r\n",
    "\r\n",
    "> O Naive Bayes é um método muito rápido e escalável, dado que os cálculos realizados por ele (essencialmente contagem) são muito simples de serem feitos. No entanto, esta velocidade se deve a uma tremenda simplificação em seu procedimento, que é o que caracteriza o método como \"Naive\": assume-se independência condicional entre as features, de modo que a likelihood do teorema de Bayes é aproximada por um produto entre as probabilidades de cada feature condicionadas apenas no target, eliminando o condicionamento às demais features. Apesar desta simplificação, o modelo demonstra sucesso quando aplicado, sobretudo, a problemas de classificação de texto.\r\n",
    "\r\n",
    "(x ) Verdadeiro\r\n",
    "\r\n",
    "( ) Falso\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color=red>\n",
    "Justificativa aqui\n",
    "</font>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "__________\n",
    "__________"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**14) Julgue a afirmativa a seguir como verdadeira ou falsa, justificando sua resposta se a afirmativa for falsa**\r\n",
    "\r\n",
    "> O PCA é uma técnica não-supervisionada de redução de dimensionalidade. Quando aplicado às features originais, o método retorna as **componentes principais**, que são combinações lineares das features originais, representando as direções de maior explicabilidade das variações dos dados. As componentes principais são criadas de modo que sejam descorrelacionadas, e com grande parte da informação das features originais \"comprimidas\" nas primeiras componentes. Com isso, é possível que reduzamos o número de features (dimensões), considerando apenas algumas poucas componentes principais, com a esperança de que grande parte das informações originais estejam codificadas nelas.\r\n",
    "\r\n",
    "( x) Verdadeiro\r\n",
    "\r\n",
    "( ) Falso\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color=red>\n",
    "Justificativa aqui\n",
    "</font>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "__________\n",
    "__________"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**15) Julgue as afirmativas a seguir como verdadeiras ou falsas, justificando sua resposta para as afirmativas falsas, se houver alguma**\r\n",
    "\r\n",
    "> - 1 - O k-means é um método de clusterização que sempre produz exatamente k clusters com base na estrutura das features. Ele é um método iterativo, que consiste na atribuição de clusters aos pontos e sucessiva atualização dos centroides dos clusters, que são calculados a partir da média das posições dos pontos no respectivo cluster (daí o \"means\" que nomeia o método).\r\n",
    "\r\n",
    "> - 2 - O DBSCAN é um método de clusterização que, diferentemente do k-means, é baseado no conceito de densidade para gerar clusters como sendo regiões densas, separados entre si por regiões esparsas (vazias). Segundo este princípio, o método é capaz de identificar outliers.\r\n",
    "\r\n",
    "\r\n",
    "Julgando as afirmativas 1 e 2, temos, respectivamente:\r\n",
    "\r\n",
    "( x) Verdadeiro / Verdadeiro\r\n",
    "\r\n",
    "( ) Falso / Verdadeiro\r\n",
    "\r\n",
    "( ) Verdadeiro / Falso\r\n",
    "\r\n",
    "( ) Falso / Falso"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color=red>\n",
    "Justificativa aqui\n",
    "</font>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "__________\n",
    "__________"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**16) Julgue a afirmativa a seguir como verdadeira ou falsa, justificando sua resposta se a afirmativa for falsa**\r\n",
    "\r\n",
    "> Em todos os projetos em que decidamos aplicar métodos de ML, o importante é que tenhamos, no final, modelos com a melhor performance possível (no que diz respeito à generalização), mesmo que isso demande a utilização de métodos muito complexos e pouco interpretáveis, afinal, a interpretabilidade sempre é menos prioritária que a performance dos modelos.\r\n",
    "\r\n",
    "( ) Verdadeiro\r\n",
    "\r\n",
    "(x ) Falso\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color=red>Justificativa</font>\r\n",
    "\r\n",
    "Falso, todo modelo gerado precisa a interpretação de uma pessoa que conhece o processo. Só o especialista da area consegue dizer se o modelo faz sentido ou não."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "__________\n",
    "__________"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}