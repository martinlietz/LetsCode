{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><markdown translate=\"no\" mathjax=\"\" class=\"ng-tns-c364-40\"><h1 id=\"processamento-de-linguagem-natural-pln\"><strong>Processamento de Linguagem Natural (PLN)</strong></h1>\n",
    "<h2 id=\"pos-e-ner\"><strong>POS e NER</strong></h2>\n",
    "<h3 id=\"índice\">Índice</h3>\n",
    "<ul>\n",
    "<li>1) Objetivos</li>\n",
    "<li>2) POS Tags</li>\n",
    "<li>3) NER Tags</li>\n",
    "</ul>\n",
    "<h3 id=\"1-objetivos\"><strong>1) Objetivos</strong></h3>\n",
    "<p>Este material tem como objetivo apresentar:</p>\n",
    "<ul>\n",
    "<li>Conceitos sobre extração de Partes do Discurso (<strong>POS - Parts-of-Speech</strong>) usando spaCy em Python;</li>\n",
    "<li>Conceitos sobre Reconhecimento de Entidades (<strong>NER - Named Entity Recognition</strong>) usando spaCy em Python;</li>\n",
    "<li>Visualização de POS e NER.</li>\n",
    "</ul>\n",
    "<h3 id=\"2-pos-tags\"><strong>2) POS Tags</strong></h3>\n",
    "<p>Conforme discutido no material anterior, o objetivo do POS é classificar gramaticalmente os elementos constituintes do texto (tokens).</p>\n",
    "<p>Assim, o processo de POS atribui uma <strong>tag</strong> de classificação aos tokens.</p>\n",
    "<p>Existem, no entanto, dois níveis diferentes de tags:</p>\n",
    "<ul>\n",
    "<li><strong>Coarse-grained POS tags</strong>: são tags mais <strong>genéricas</strong>, representando as grandes classes gramaticais;<ul>\n",
    "<li>exemplo de tags: substantivos, verbos, adjetivos;</li>\n",
    "</ul>\n",
    "</li>\n",
    "<li><strong>Fine-grained POS tags</strong>: são tags mais <strong>específicas</strong>, contendo detalhes morfológicos do token;<ul>\n",
    "<li>exemplo de tags: substantivo no plural, verbo no futuro do pretérito, adjetivo superlativo.</li>\n",
    "</ul>\n",
    "</li>\n",
    "</ul>\n",
    "<h3 id=\"coarse-grained-part-of-speech-tags\"><strong>Coarse-grained Part-of-speech Tags</strong></h3>\n",
    "<p>A primeira classificação de POS é dada de forma mais macro, na chamada etapa de \"coarse-grained\", onde as tags são genéricas e pouco detalhadas, sendo utilizadas apenas para diferenciar as grandes classes gramaticais.</p>\n",
    "<p>Esta prmeira classificação é feita de acordo com a seguinte lista (POS em inglês):</p>\n",
    "<table><tbody><tr><th>POS</th><th>DESCRIPTION</th><th>EXAMPLES</th></tr>\n",
    "\n",
    "<tr><td>ADJ</td><td>adjective</td><td>*big, old, green, incomprehensible, first*</td></tr>\n",
    "<tr><td>ADP</td><td>adposition</td><td>*in, to, during*</td></tr>\n",
    "<tr><td>ADV</td><td>adverb</td><td>*very, tomorrow, down, where, there*</td></tr>\n",
    "<tr><td>AUX</td><td>auxiliary</td><td>*is, has (done), will (do), should (do)*</td></tr>\n",
    "<tr><td>CONJ</td><td>conjunction</td><td>*and, or, but*</td></tr>\n",
    "<tr><td>CCONJ</td><td>coordinating conjunction</td><td>*and, or, but*</td></tr>\n",
    "<tr><td>DET</td><td>determiner</td><td>*a, an, the*</td></tr>\n",
    "<tr><td>INTJ</td><td>interjection</td><td>*psst, ouch, bravo, hello*</td></tr>\n",
    "<tr><td>NOUN</td><td>noun</td><td>*girl, cat, tree, air, beauty*</td></tr>\n",
    "<tr><td>NUM</td><td>numeral</td><td>*1, 2017, one, seventy-seven, IV, MMXIV*</td></tr>\n",
    "<tr><td>PART</td><td>particle</td><td>*'s, not,*</td></tr>\n",
    "<tr><td>PRON</td><td>pronoun</td><td>*I, you, he, she, myself, themselves, somebody*</td></tr>\n",
    "<tr><td>PROPN</td><td>proper noun</td><td>*Mary, John, London, NATO, HBO*</td></tr>\n",
    "<tr><td>PUNCT</td><td>punctuation</td><td>*., (, ), ?*</td></tr>\n",
    "<tr><td>SCONJ</td><td>subordinating conjunction</td><td>*if, while, that*</td></tr>\n",
    "<tr><td>SYM</td><td>symbol</td><td>*$, %, §, ©, +, −, ×, ÷, =, :), ????*</td></tr>\n",
    "<tr><td>VERB</td><td>verb</td><td>*run, runs, running, eat, ate, eating*</td></tr>\n",
    "<tr><td>X</td><td>other</td><td>*sfpksdpsxmsa*</td></tr>\n",
    "<tr><td>SPACE</td><td>space</td></tr>\n",
    "</tbody></table>\n",
    "\n",
    "<h3 id=\"fine-grained-part-of-speech-tags\"><strong>Fine-grained Part-of-speech Tags</strong></h3>\n",
    "<p>Após a classificação inicial coarse-grained, ocorre uma segunda classificação, desta vez mais detalhada, determinada pela morfologia dos tokens. Esta classificação é chamada de \"fine-grained\", por proporcionar uma classificação mais detalhada. </p>\n",
    "<p>A atribuição de tags é dada de acordo com a seguinte tabela:</p>\n",
    "<table>\n",
    "<tbody><tr><th>POS</th><th>Description</th><th>Fine-grained Tag</th><th>Description</th><th>Morphology</th></tr>\n",
    "<tr><td>ADJ</td><td>adjective</td><td>AFX</td><td>affix</td><td>Hyph=yes</td></tr>\n",
    "<tr><td>ADJ</td><td></td><td>JJ</td><td>adjective</td><td>Degree=pos</td></tr>\n",
    "<tr><td>ADJ</td><td></td><td>JJR</td><td>adjective, comparative</td><td>Degree=comp</td></tr>\n",
    "<tr><td>ADJ</td><td></td><td>JJS</td><td>adjective, superlative</td><td>Degree=sup</td></tr>\n",
    "<tr><td>ADJ</td><td></td><td>PDT</td><td>predeterminer</td><td>AdjType=pdt PronType=prn</td></tr>\n",
    "<tr><td>ADJ</td><td></td><td>PRP\\$</td><td>pronoun, possessive</td><td>PronType=prs Poss=yes</td></tr>\n",
    "<tr><td>ADJ</td><td></td><td>WDT</td><td>wh-determiner</td><td>PronType=int rel</td></tr>\n",
    "<tr><td>ADJ</td><td></td><td>WP\\$</td><td>wh-pronoun, possessive</td><td>Poss=yes PronType=int rel</td></tr>\n",
    "<tr><td>ADP</td><td>adposition</td><td>IN</td><td>conjunction, subordinating or preposition</td><td></td></tr>\n",
    "<tr><td>ADV</td><td>adverb</td><td>EX</td><td>existential there</td><td>AdvType=ex</td></tr>\n",
    "<tr><td>ADV</td><td></td><td>RB</td><td>adverb</td><td>Degree=pos</td></tr>\n",
    "<tr><td>ADV</td><td></td><td>RBR</td><td>adverb, comparative</td><td>Degree=comp</td></tr>\n",
    "<tr><td>ADV</td><td></td><td>RBS</td><td>adverb, superlative</td><td>Degree=sup</td></tr>\n",
    "<tr><td>ADV</td><td></td><td>WRB</td><td>wh-adverb</td><td>PronType=int rel</td></tr>\n",
    "<tr><td>CONJ</td><td>conjunction</td><td>CC</td><td>conjunction, coordinating</td><td>ConjType=coor</td></tr>\n",
    "<tr><td>DET</td><td>determiner</td><td>DT</td><td>determiner</td><td></td></tr>\n",
    "<tr><td>INTJ</td><td>interjection</td><td>UH</td><td>interjection</td><td></td></tr>\n",
    "<tr><td>NOUN</td><td>noun</td><td>NN</td><td>noun, singular or mass</td><td>Number=sing</td></tr>\n",
    "<tr><td>NOUN</td><td></td><td>NNS</td><td>noun, plural</td><td>Number=plur</td></tr>\n",
    "<tr><td>NOUN</td><td></td><td>WP</td><td>wh-pronoun, personal</td><td>PronType=int rel</td></tr>\n",
    "<tr><td>NUM</td><td>numeral</td><td>CD</td><td>cardinal number</td><td>NumType=card</td></tr>\n",
    "<tr><td>PART</td><td>particle</td><td>POS</td><td>possessive ending</td><td>Poss=yes</td></tr>\n",
    "<tr><td>PART</td><td></td><td>RP</td><td>adverb, particle</td><td></td></tr>\n",
    "<tr><td>PART</td><td></td><td>TO</td><td>infinitival to</td><td>PartType=inf VerbForm=inf</td></tr>\n",
    "<tr><td>PRON</td><td>pronoun</td><td>PRP</td><td>pronoun, personal</td><td>PronType=prs</td></tr>\n",
    "<tr><td>PROPN</td><td>proper noun</td><td>NNP</td><td>noun, proper singular</td><td>NounType=prop Number=sign</td></tr>\n",
    "<tr><td>PROPN</td><td></td><td>NNPS</td><td>noun, proper plural</td><td>NounType=prop Number=plur</td></tr>\n",
    "<tr><td>PUNCT</td><td>punctuation</td><td>-LRB-</td><td>left round bracket</td><td>PunctType=brck PunctSide=ini</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>-RRB-</td><td>right round bracket</td><td>PunctType=brck PunctSide=fin</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>,</td><td>punctuation mark, comma</td><td>PunctType=comm</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>:</td><td>punctuation mark, colon or ellipsis</td><td></td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>.</td><td>punctuation mark, sentence closer</td><td>PunctType=peri</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>''</td><td>closing quotation mark</td><td>PunctType=quot PunctSide=fin</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>\"\"</td><td>closing quotation mark</td><td>PunctType=quot PunctSide=fin</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>``</td><td>opening quotation mark</td><td>PunctType=quot PunctSide=ini</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>HYPH</td><td>punctuation mark, hyphen</td><td>PunctType=dash</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>LS</td><td>list item marker</td><td>NumType=ord</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>NFP</td><td>superfluous punctuation</td><td></td></tr>\n",
    "<tr><td>SYM</td><td>symbol</td><td>#</td><td>symbol, number sign</td><td>SymType=numbersign</td></tr>\n",
    "<tr><td>SYM</td><td></td><td>\\$</td><td>symbol, currency</td><td>SymType=currency</td></tr>\n",
    "<tr><td>SYM</td><td></td><td>SYM</td><td>symbol</td><td></td></tr>\n",
    "<tr><td>VERB</td><td>verb</td><td>BES</td><td>auxiliary \"be\"</td><td></td></tr>\n",
    "<tr><td>VERB</td><td></td><td>HVS</td><td>forms of \"have\"</td><td></td></tr>\n",
    "<tr><td>VERB</td><td></td><td>MD</td><td>verb, modal auxiliary</td><td>VerbType=mod</td></tr>\n",
    "<tr><td>VERB</td><td></td><td>VB</td><td>verb, base form</td><td>VerbForm=inf</td></tr>\n",
    "<tr><td>VERB</td><td></td><td>VBD</td><td>verb, past tense</td><td>VerbForm=fin Tense=past</td></tr>\n",
    "<tr><td>VERB</td><td></td><td>VBG</td><td>verb, gerund or present participle</td><td>VerbForm=part Tense=pres Aspect=prog</td></tr>\n",
    "<tr><td>VERB</td><td></td><td>VBN</td><td>verb, past participle</td><td>VerbForm=part Tense=past Aspect=perf</td></tr>\n",
    "<tr><td>VERB</td><td></td><td>VBP</td><td>verb, non-3rd person singular present</td><td>VerbForm=fin Tense=pres</td></tr>\n",
    "<tr><td>VERB</td><td></td><td>VBZ</td><td>verb, 3rd person singular present</td><td>VerbForm=fin Tense=pres Number=sing Person=3</td></tr>\n",
    "<tr><td>X</td><td>other</td><td>ADD</td><td>email</td><td></td></tr>\n",
    "<tr><td>X</td><td></td><td>FW</td><td>foreign word</td><td>Foreign=yes</td></tr>\n",
    "<tr><td>X</td><td></td><td>GW</td><td>additional word in multi-word expression</td><td></td></tr>\n",
    "<tr><td>X</td><td></td><td>XX</td><td>unknown</td><td></td></tr>\n",
    "<tr><td>SPACE</td><td>space</td><td>_SP</td><td>space</td><td></td></tr>\n",
    "<tr><td></td><td></td><td>NIL</td><td>missing tag</td><td></td></tr>\n",
    "</tbody></table>\n",
    "\n",
    "<p>Vamos agora fazer alguns exemplos em Python utilizando a spacy!</p>\n",
    "<pre class=\" language-python\"><code class=\" language-python\"><span class=\"token comment\"># importando a spacy</span>\n",
    "<span class=\"token keyword\">import</span> spacy\n",
    "<span class=\"token comment\"># carrega um modelo linguístico multitarefa em inglês</span>\n",
    "<span class=\"token comment\"># este modelo contém ferramentas tanto para POS quanto para NER</span>\n",
    "nlp <span class=\"token operator\">=</span> spacy<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span><span class=\"token string\">'en_core_web_sm'</span><span class=\"token punctuation\">)</span>\n",
    "\n",
    "<span class=\"token comment\"># vamos definir um doc object, como sendo o texto a seguir em inglês</span>\n",
    "doc <span class=\"token operator\">=</span> nlp<span class=\"token punctuation\">(</span><span class=\"token string\">u'The quick brown fox jumped over the lazy dog\\'s back.'</span><span class=\"token punctuation\">)</span>\n",
    "\n",
    "<span class=\"token comment\"># exibindo o texto completo</span>\n",
    "<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>doc<span class=\"token punctuation\">.</span>text<span class=\"token punctuation\">)</span>\n",
    "<span class=\"token comment\"># [] The quick brown fox jumped over the lazy dog's back.</span>\n",
    "\n",
    "<span class=\"token comment\"># vamos pegar a palavra de índice 4, \"jumped\"</span>\n",
    "<span class=\"token comment\"># exibe a palavra</span>\n",
    "<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>doc<span class=\"token punctuation\">[</span><span class=\"token number\">4</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n",
    "<span class=\"token comment\"># exibe a coarse-grained tag (método \".pos_\")</span>\n",
    "<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>doc<span class=\"token punctuation\">[</span><span class=\"token number\">4</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>pos_<span class=\"token punctuation\">)</span>\n",
    "<span class=\"token comment\"># exbie a fine-grained tag (método \".tag_\")</span>\n",
    "<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>doc<span class=\"token punctuation\">[</span><span class=\"token number\">4</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>tag_<span class=\"token punctuation\">)</span>\n",
    "\n",
    "<span class=\"token comment\"># jumped</span>\n",
    "<span class=\"token comment\"># VERB</span>\n",
    "<span class=\"token comment\"># VBD</span></code></pre>\n",
    "<p>Conforme esperado, a coarse-grained tag retornou \"VERB\", indicando que a palavra é um verbo. E a fine-grained retornou \"VBD\", o que indica que a palavra é um verbo conjugado no tempo verbal \"past tense\". De fato, \"jumped\" é o passado do verbo \"jump\", que significa \"pular\".</p>\n",
    "<p>Podemos fazer a análise acima para todas as palavras do doc:</p>\n",
    "<pre class=\" language-python\"><code class=\" language-python\"><span class=\"token comment\"># exibe o cabecalho</span>\n",
    "<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span><span class=\"token string\">'Token'</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">{</span><span class=\"token number\">10</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">}</span></span><span class=\"token string\"> </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span><span class=\"token string\">'POS'</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">{</span><span class=\"token number\">10</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">}</span></span><span class=\"token string\"> </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span><span class=\"token string\">'TAG'</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">{</span><span class=\"token number\">10</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">}</span></span><span class=\"token string\"> </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span><span class=\"token string\">'Explicação'</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span>\n",
    "\n",
    "<span class=\"token comment\"># para cada token no doc</span>\n",
    "<span class=\"token keyword\">for</span> token <span class=\"token keyword\">in</span> doc<span class=\"token punctuation\">:</span>\n",
    "    <span class=\"token comment\"># vamos exibir:</span>\n",
    "    <span class=\"token comment\"># - o token (método \".text\"); </span>\n",
    "    <span class=\"token comment\"># - a coarse-grained tag (método \".pos_\");</span>\n",
    "    <span class=\"token comment\"># - a fine-grained tag (método \".tag_\");</span>\n",
    "    <span class=\"token comment\"># - a explicação da tag (função \"spacy.explain(token.tag_)\").</span>\n",
    "    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>token<span class=\"token punctuation\">.</span>text<span class=\"token punctuation\">:</span><span class=\"token punctuation\">{</span><span class=\"token number\">10</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">}</span></span><span class=\"token string\"> </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>token<span class=\"token punctuation\">.</span>pos_<span class=\"token punctuation\">:</span><span class=\"token punctuation\">{</span><span class=\"token number\">10</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">}</span></span><span class=\"token string\"> </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>token<span class=\"token punctuation\">.</span>tag_<span class=\"token punctuation\">:</span><span class=\"token punctuation\">{</span><span class=\"token number\">10</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">}</span></span><span class=\"token string\"> </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>spacy<span class=\"token punctuation\">.</span>explain<span class=\"token punctuation\">(</span>token<span class=\"token punctuation\">.</span>tag_<span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span>\n",
    "<span class=\"token comment\"># [] Token      POS        TAG        Explicação</span>\n",
    "<span class=\"token comment\"># The        DET        DT         determiner</span>\n",
    "<span class=\"token comment\"># quick      ADJ        JJ         adjective</span>\n",
    "<span class=\"token comment\"># brown      ADJ        JJ         adjective</span>\n",
    "<span class=\"token comment\"># fox        NOUN       NN         noun, singular or mass</span>\n",
    "<span class=\"token comment\"># jumped     VERB       VBD        verb, past tense</span>\n",
    "<span class=\"token comment\"># over       ADP        IN         conjunction, subordinating or preposition</span>\n",
    "<span class=\"token comment\"># the        DET        DT         determiner</span>\n",
    "<span class=\"token comment\"># lazy       ADJ        JJ         adjective</span>\n",
    "<span class=\"token comment\"># dog        NOUN       NN         noun, singular or mass</span>\n",
    "<span class=\"token comment\"># 's         PART       POS        possessive ending</span>\n",
    "<span class=\"token comment\"># back       NOUN       NN         noun, singular or mass</span>\n",
    "<span class=\"token comment\"># .          PUNCT      .          punctuation mark, sentence closer</span>\n",
    "</code></pre>\n",
    "<p>Diferentemente de quando utilizamos o POS em português, note que agora temos muito mais informações disponíveis, inclusive a explicação com a função <code>spacy.explain()</code>. Em geral, essa é uma realidade das ferramentas de PLN: há muito mais recursos para PLN em inglês do que em português.</p>\n",
    "<h3 id=\"contando-pos\"><strong>Contando POS</strong></h3>\n",
    "<p>Muitas vezes, pode ser interessante contar o número de aparições de cada classe gramatical em um texto. Para isso, utillizamos o método \".count_by\"</p>\n",
    "<pre class=\" language-python\"><code class=\" language-python\"><span class=\"token comment\"># conta o número de classes gramaticais no doc</span>\n",
    "<span class=\"token comment\"># o argumento é \"spacy.attrs.POS\", que se refere às tags de POS</span>\n",
    "POS_counts <span class=\"token operator\">=</span> doc<span class=\"token punctuation\">.</span>count_by<span class=\"token punctuation\">(</span>spacy<span class=\"token punctuation\">.</span>attrs<span class=\"token punctuation\">.</span>POS<span class=\"token punctuation\">)</span>\n",
    "<span class=\"token comment\"># exibe as contagens em termos dos índices das classes gramaticais</span>\n",
    "<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>POS_counts<span class=\"token punctuation\">)</span>\n",
    "<span class=\"token comment\"># [] {90: 2, 84: 3, 92: 3, 100: 1, 85: 1, 94: 1, 97: 1}</span>\n",
    "\n",
    "<span class=\"token comment\"># é para visualizarmos as classes em si</span>\n",
    "<span class=\"token comment\"># utilizamos \"doc.vocab[key].text\" para captar a descrição da tag em texto</span>\n",
    "<span class=\"token keyword\">for</span> key<span class=\"token punctuation\">,</span> value <span class=\"token keyword\">in</span> <span class=\"token builtin\">sorted</span><span class=\"token punctuation\">(</span>POS_counts<span class=\"token punctuation\">.</span>items<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n",
    "    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>key<span class=\"token punctuation\">:</span><span class=\"token punctuation\">{</span><span class=\"token number\">4</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">. </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>doc<span class=\"token punctuation\">.</span>vocab<span class=\"token punctuation\">[</span>key<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>text<span class=\"token punctuation\">:</span><span class=\"token punctuation\">{</span><span class=\"token number\">5</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">}</span></span><span class=\"token string\"> </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>value<span class=\"token punctuation\">}</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span>\n",
    "\n",
    "<span class=\"token comment\"># []   84. ADJ   3</span>\n",
    "<span class=\"token comment\">#  85. ADP   1</span>\n",
    "<span class=\"token comment\">#  90. DET   2</span>\n",
    "<span class=\"token comment\">#  92. NOUN  3</span>\n",
    "<span class=\"token comment\">#  94. PART  1</span>\n",
    "<span class=\"token comment\">#  97. PUNCT 1</span>\n",
    "<span class=\"token comment\"># 100. VERB  1</span></code></pre>\n",
    "<h3 id=\"visualizando-pos\"><strong>Visualizando POS</strong></h3>\n",
    "<p>Uma funcionalidade extremamente interessante da spacy é a função \"displacy\", que proporciona a visualização da estrutura gramatical da frase, ao criar uma estrutura de setas indicando a relação de referência entre as palavras da frase.</p>\n",
    "<pre class=\" language-python\"><code class=\" language-python\"><span class=\"token comment\"># opções do plot</span>\n",
    "options <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span><span class=\"token string\">'color'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'black'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'bg'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'000000'</span><span class=\"token punctuation\">}</span>\n",
    "<span class=\"token comment\"># função para o plot de relações.</span>\n",
    "<span class=\"token comment\"># o argumento style=\"dep\" garante a visualização do POS, mostrando a dependência entre tokens</span>\n",
    "spacy<span class=\"token punctuation\">.</span>displacy<span class=\"token punctuation\">.</span>render<span class=\"token punctuation\">(</span>doc<span class=\"token punctuation\">,</span> style<span class=\"token operator\">=</span><span class=\"token string\">'dep'</span><span class=\"token punctuation\">,</span> jupyter<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> options<span class=\"token operator\">=</span>options<span class=\"token punctuation\">)</span></code></pre>\n",
    "<p>A imagem gerada é:</p>\n",
    "<img src=\"https://i.imgur.com/WZilZ3k.png\" width=\"800/\">\n",
    "\n",
    "\n",
    "<h3 id=\"4-ner-tags\"><strong>4) NER Tags</strong></h3>\n",
    "<p>A spacy também pode ser utilizada para a determinação de entidades, através das técnicas de NER (Named Entity Recognition - NER).</p>\n",
    "<p>O objetivo deste tipo de análise é coletar elementos para classificar tokens em categorias pré definidas, como \"Pessoa\", \"Organização\", \"Tempo\", \"Valor\", etc.</p>\n",
    "<p>Este tipo de processamento é muitíssimo importante para quase todas as aplicações de PLN, pois a classificação de tokens em grupos com significado contextual é de enorme importância para a compreensão de linguaem natural.</p>\n",
    "<p>A imagem a seguir ilustra um mapa de relações para determinação de entidades em português:</p>\n",
    "<img src=\"https://miro.medium.com/max/1400/1*WZOuEBT5y_K0tvPznjr2Dw.jpeg\" width=\"500/\">\n",
    "\n",
    "\n",
    "<p>As tags de entidades são acessadas utilizando o método \".label_\" de uma entidade, e são dados de acordo com a seguinte tabela de NER em inglês:</p>\n",
    "<table>\n",
    "<tbody><tr><th>TYPE</th><th>DESCRIPTION</th><th>EXAMPLE</th></tr>\n",
    "<tr><td>`PERSON`</td><td>People, including fictional.</td><td>*Fred Flintstone*</td></tr>\n",
    "<tr><td>`NORP`</td><td>Nationalities or religious or political groups.</td><td>*The Republican Party*</td></tr>\n",
    "<tr><td>`FAC`</td><td>Buildings, airports, highways, bridges, etc.</td><td>*Logan International Airport, The Golden Gate*</td></tr>\n",
    "<tr><td>`ORG`</td><td>Companies, agencies, institutions, etc.</td><td>*Microsoft, FBI, MIT*</td></tr>\n",
    "<tr><td>`GPE`</td><td>Countries, cities, states.</td><td>*France, UAR, Chicago, Idaho*</td></tr>\n",
    "<tr><td>`LOC`</td><td>Non-GPE locations, mountain ranges, bodies of water.</td><td>*Europe, Nile River, Midwest*</td></tr>\n",
    "<tr><td>`PRODUCT`</td><td>Objects, vehicles, foods, etc. (Not services.)</td><td>*Formula 1*</td></tr>\n",
    "<tr><td>`EVENT`</td><td>Named hurricanes, battles, wars, sports events, etc.</td><td>*Olympic Games*</td></tr>\n",
    "<tr><td>`WORK_OF_ART`</td><td>Titles of books, songs, etc.</td><td>*The Mona Lisa*</td></tr>\n",
    "<tr><td>`LAW`</td><td>Named documents made into laws.</td><td>*Roe v. Wade*</td></tr>\n",
    "<tr><td>`LANGUAGE`</td><td>Any named language.</td><td>*English*</td></tr>\n",
    "<tr><td>`DATE`</td><td>Absolute or relative dates or periods.</td><td>*20 July 1969*</td></tr>\n",
    "<tr><td>`TIME`</td><td>Times smaller than a day.</td><td>*Four hours*</td></tr>\n",
    "<tr><td>`PERCENT`</td><td>Percentage, including \"%\".</td><td>*Eighty percent*</td></tr>\n",
    "<tr><td>`MONEY`</td><td>Monetary values, including unit.</td><td>*Twenty Cents*</td></tr>\n",
    "<tr><td>`QUANTITY`</td><td>Measurements, as of weight or distance.</td><td>*Several kilometers, 55kg*</td></tr>\n",
    "<tr><td>`ORDINAL`</td><td>\"first\", \"second\", etc.</td><td>*9th, Ninth*</td></tr>\n",
    "<tr><td>`CARDINAL`</td><td>Numerals that do not fall under another type.</td><td>*2, Two, Fifty-two*</td></tr>\n",
    "</tbody></table>\n",
    "\n",
    "<p>Um exemplo em Python:</p>\n",
    "<pre class=\" language-python\"><code class=\" language-python\"><span class=\"token comment\"># definindo a função para determinação de entidades</span>\n",
    "<span class=\"token keyword\">def</span> <span class=\"token function\">show_ents</span><span class=\"token punctuation\">(</span>doc<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n",
    "    <span class=\"token comment\"># se houve entidades detectadas no texto</span>\n",
    "    <span class=\"token keyword\">if</span> doc<span class=\"token punctuation\">.</span>ents<span class=\"token punctuation\">:</span>\n",
    "        <span class=\"token comment\"># para cada entidade</span>\n",
    "        <span class=\"token keyword\">for</span> ent <span class=\"token keyword\">in</span> doc<span class=\"token punctuation\">.</span>ents<span class=\"token punctuation\">:</span>\n",
    "            <span class=\"token comment\"># exiba:</span>\n",
    "            <span class=\"token comment\"># - o token identificado como entidade (método \".text\");</span>\n",
    "            <span class=\"token comment\"># - a label da respectiva entidade (método \".label_\");</span>\n",
    "            <span class=\"token comment\"># - a explicação para a atribuição da label da entidade (função \"spacy.explain(ent.label_)\")</span>\n",
    "            <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>ent<span class=\"token punctuation\">.</span>text<span class=\"token punctuation\">}</span></span><span class=\"token string\"> - </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>ent<span class=\"token punctuation\">.</span>label_<span class=\"token punctuation\">}</span></span><span class=\"token string\"> - </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>spacy<span class=\"token punctuation\">.</span>explain<span class=\"token punctuation\">(</span>ent<span class=\"token punctuation\">.</span>label_<span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span>\n",
    "    <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n",
    "        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Entidades não encontradas\"</span><span class=\"token punctuation\">)</span>\n",
    "\n",
    "<span class=\"token comment\"># testando com um texto simples </span>\n",
    "doc <span class=\"token operator\">=</span> nlp<span class=\"token punctuation\">(</span><span class=\"token string\">u'Hi how are you?'</span><span class=\"token punctuation\">)</span>\n",
    "show_ents<span class=\"token punctuation\">(</span>doc<span class=\"token punctuation\">)</span>\n",
    "<span class=\"token comment\"># [] Entidades não encontradas</span>\n",
    "\n",
    "<span class=\"token comment\">#textando com um texto mais elaborado</span>\n",
    "doc <span class=\"token operator\">=</span> nlp<span class=\"token punctuation\">(</span><span class=\"token string\">u\"May I go to Washington, DC next May to see the Washington Monument?\"</span><span class=\"token punctuation\">)</span>\n",
    "show_ents<span class=\"token punctuation\">(</span>doc<span class=\"token punctuation\">)</span>\n",
    "<span class=\"token comment\"># [] Washington - GPE - Countries, cities, states</span>\n",
    "<span class=\"token comment\"># next May - DATE - Absolute or relative dates or periods</span>\n",
    "<span class=\"token comment\"># the Washington Monument - ORG - Companies, agencies, institutions, etc.</span>\n",
    "<span class=\"token comment\"># Entidades não encontradas</span></code></pre>\n",
    "<h3 id=\"como-adicionar-uma-entidade\"><strong>Como adicionar uma entidade?</strong></h3>\n",
    "<p>Ao trabalhar com uma base de dados real, é provável que tenhamos entidades que não foram pré classificadas pelo modelo linguístico previamente carregado.</p>\n",
    "<p>Neste caso, temos de adicionar novas entidades. Fazemos isso da seguinte forma, com o uso da função \"Span\":</p>\n",
    "<pre class=\" language-python\"><code class=\" language-python\"><span class=\"token comment\"># define o doc</span>\n",
    "doc <span class=\"token operator\">=</span> nlp<span class=\"token punctuation\">(</span><span class=\"token string\">u'Let\\'s code will impact the education market in 2020.'</span><span class=\"token punctuation\">)</span>\n",
    "<span class=\"token comment\"># exibe as entidades, se tiver alguma</span>\n",
    "show_ents<span class=\"token punctuation\">(</span>doc<span class=\"token punctuation\">)</span>\n",
    "<span class=\"token comment\"># [] 2020 - DATE - Absolute or relative dates or periods</span>\n",
    "<span class=\"token comment\"># Entidades não encontradas</span>\n",
    "\n",
    "<span class=\"token comment\"># importa a função Span</span>\n",
    "<span class=\"token keyword\">from</span> spacy<span class=\"token punctuation\">.</span>tokens <span class=\"token keyword\">import</span> Span\n",
    "\n",
    "<span class=\"token comment\"># tomamos a label \"ORG\" </span>\n",
    "ORG <span class=\"token operator\">=</span> doc<span class=\"token punctuation\">.</span>vocab<span class=\"token punctuation\">.</span>strings<span class=\"token punctuation\">[</span><span class=\"token string\">u\"ORG\"</span><span class=\"token punctuation\">]</span>\n",
    "\n",
    "<span class=\"token comment\"># criamos uma nova entidade, do indice 0 até 3 ([Let, ', s, code] = \"Let's code\")</span>\n",
    "<span class=\"token comment\"># usamos a função \"Span\" com os argumentos que identificam a entidade (doc e indices da entidade)</span>\n",
    "<span class=\"token comment\"># e também atribuímos à esta entidade a label \"ORG\" (atributo \"label=ORG\")</span>\n",
    "new_ent <span class=\"token operator\">=</span> Span<span class=\"token punctuation\">(</span>doc<span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span>label<span class=\"token operator\">=</span>ORG<span class=\"token punctuation\">)</span>\n",
    "\n",
    "<span class=\"token comment\"># adicionamos a nova entidade à lista de entidades</span>\n",
    "doc<span class=\"token punctuation\">.</span>ents <span class=\"token operator\">=</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>doc<span class=\"token punctuation\">.</span>ents<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> <span class=\"token punctuation\">[</span>new_ent<span class=\"token punctuation\">]</span>\n",
    "\n",
    "<span class=\"token comment\"># agora, chamamos novamente a função de classificação das entidades</span>\n",
    "<span class=\"token comment\"># note que dessa vez \"Let's code\" será classificada como \"ORG\"!</span>\n",
    "show_ents<span class=\"token punctuation\">(</span>doc<span class=\"token punctuation\">)</span>\n",
    "<span class=\"token comment\"># [] Let's code - ORG - Companies, agencies, institutions, etc.</span>\n",
    "<span class=\"token comment\"># 2020 - DATE - Absolute or relative dates or periods</span>\n",
    "<span class=\"token comment\"># Entidades não encontradas</span></code></pre>\n",
    "<h3 id=\"e-quando-precisar-adicionar-muitas-entidades-a-partir-do-doc\"><strong>E quando precisar adicionar muitas entidades a partir do doc?</strong></h3>\n",
    "<p>Neste caso, utilizamos a função \"PhraseMatcher\" </p>\n",
    "<pre class=\" language-python\"><code class=\" language-python\"><span class=\"token comment\"># importamos a função</span>\n",
    "<span class=\"token keyword\">from</span> spacy<span class=\"token punctuation\">.</span>matcher <span class=\"token keyword\">import</span> PhraseMatcher\n",
    "<span class=\"token comment\"># instanciamos o objeto utilizando o vocabulario nlp.vocab</span>\n",
    "matcher <span class=\"token operator\">=</span> PhraseMatcher<span class=\"token punctuation\">(</span>nlp<span class=\"token punctuation\">.</span>vocab<span class=\"token punctuation\">)</span>\n",
    "\n",
    "<span class=\"token comment\"># definindo o doc</span>\n",
    "doc <span class=\"token operator\">=</span> nlp<span class=\"token punctuation\">(</span><span class=\"token string\">u\"Our company created a brand new vacuum cleaner.\"</span>\n",
    "        <span class=\"token string\">u\"This new vacuum-cleaner is the best in show\"</span><span class=\"token punctuation\">)</span>\n",
    "\n",
    "<span class=\"token comment\"># criamos lista de palavrasa serem classificadas como entidades</span>\n",
    "phrase_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'vacuum cleaner'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'vacuum-cleaner'</span><span class=\"token punctuation\">]</span>\n",
    "<span class=\"token comment\"># para cada string na lista acima, tome o nlp(text)</span>\n",
    "phrase_patterns <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>nlp<span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> text <span class=\"token keyword\">in</span> phrase_list<span class=\"token punctuation\">]</span>\n",
    "<span class=\"token comment\"># adicione a lista àcima ao matcher</span>\n",
    "matcher<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span><span class=\"token string\">'newproduct'</span><span class=\"token punctuation\">,</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">*</span>phrase_patterns<span class=\"token punctuation\">)</span>\n",
    "\n",
    "<span class=\"token comment\"># veja quais elementos do doc foram encontrados no matcher</span>\n",
    "found_matches <span class=\"token operator\">=</span> matcher<span class=\"token punctuation\">(</span>doc<span class=\"token punctuation\">)</span>\n",
    "<span class=\"token comment\"># como visto abaixo, ambos os elementos foram encontrados!</span>\n",
    "<span class=\"token comment\"># os indices grandes indicam que as palavras são bem raras no vocabulário, aparecendo bem depois</span>\n",
    "<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>found_matches<span class=\"token punctuation\">)</span>\n",
    "<span class=\"token comment\"># [] [(2689272359382549672, 6, 8), (2689272359382549672, 11, 14)]</span>\n",
    "\n",
    "<span class=\"token comment\"># tomamos a label \"PRODUCT\"</span>\n",
    "PROD <span class=\"token operator\">=</span> doc<span class=\"token punctuation\">.</span>vocab<span class=\"token punctuation\">.</span>strings<span class=\"token punctuation\">[</span><span class=\"token string\">u\"PRODUCT\"</span><span class=\"token punctuation\">]</span>\n",
    "<span class=\"token comment\"># atribuímos a label acima às palavras com match, o que finaliza a classificação das entidades!</span>\n",
    "new_ents <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>Span<span class=\"token punctuation\">(</span>doc<span class=\"token punctuation\">,</span> match<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> match<span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span>PROD<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> match <span class=\"token keyword\">in</span> found_matches<span class=\"token punctuation\">]</span>\n",
    "\n",
    "<span class=\"token comment\"># adicionamos as novas entidades à lista de entidades</span>\n",
    "doc<span class=\"token punctuation\">.</span>ents <span class=\"token operator\">=</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>doc<span class=\"token punctuation\">.</span>ents<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> new_ents\n",
    "<span class=\"token comment\"># chamamos a função: os produtos foram classificados como entidades!</span>\n",
    "show_ents<span class=\"token punctuation\">(</span>doc<span class=\"token punctuation\">)</span>\n",
    "\n",
    "<span class=\"token comment\"># [] vacuum cleaner - PRODUCT - Objects, vehicles, foods, etc. (not services)</span>\n",
    "<span class=\"token comment\"># vacuum-cleaner - PRODUCT - Objects, vehicles, foods, etc. (not services)</span></code></pre>\n",
    "<h3 id=\"visualizando-ner\"><strong>Visualizando NER</strong></h3>\n",
    "<p>Por fim, bem como visualizamos o POS, tamvbém é possível visualizar o NER com a função \"displacy\".</p>\n",
    "<p>Este tipo de visualização destaca as entidades com as respectivas labels nas frases do doc:</p>\n",
    "<pre class=\" language-python\"><code class=\" language-python\"><span class=\"token comment\"># definindo o doc</span>\n",
    "doc <span class=\"token operator\">=</span> nlp<span class=\"token punctuation\">(</span><span class=\"token string\">u\"Over the last quarter Apple sold nearly 20 thousand iPods for a profit of $6 million.\"</span>\n",
    "        <span class=\"token string\">u\"By contrast, Sony only sold 8 thousand Walkman music players\"</span><span class=\"token punctuation\">)</span>\n",
    "\n",
    "<span class=\"token comment\"># plotando a visualização do NER</span>\n",
    "<span class=\"token comment\"># o argumento style=\"ent\" garante a visualização de NER, destacando as entidades</span>\n",
    "spacy<span class=\"token punctuation\">.</span>displacy<span class=\"token punctuation\">.</span>render<span class=\"token punctuation\">(</span>doc<span class=\"token punctuation\">,</span> style<span class=\"token operator\">=</span><span class=\"token string\">'ent'</span><span class=\"token punctuation\">,</span> jupyter<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span></code></pre>\n",
    "<img src=\"https://i.imgur.com/KDKyFvr.png\" width=\"800/\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</markdown></p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.8 32-bit",
   "metadata": {
    "interpreter": {
     "hash": "04635d289a519a1410467dd0afb0db42f9184808881ca68b2eb5a687a20a5a94"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
