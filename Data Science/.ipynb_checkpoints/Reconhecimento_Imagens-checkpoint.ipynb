{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura e reconhecimento de imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_lfw_people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = fetch_lfw_people(min_faces_per_person=70, resize=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[254.      , 254.      , 251.66667 , ...,  87.333336,  88.666664,\n",
       "          86.666664],\n",
       "        [ 39.666668,  50.333332,  47.      , ..., 117.666664, 115.      ,\n",
       "         133.66667 ],\n",
       "        [ 89.333336, 104.      , 126.      , ..., 175.33333 , 183.33333 ,\n",
       "         183.      ],\n",
       "        ...,\n",
       "        [ 86.      ,  80.333336,  74.666664, ...,  44.      ,  49.666668,\n",
       "          44.666668],\n",
       "        [ 50.333332,  65.666664,  88.      , ..., 197.      , 179.33333 ,\n",
       "         166.33333 ],\n",
       "        [ 30.      ,  27.      ,  32.666668, ...,  35.      ,  35.333332,\n",
       "          61.      ]], dtype=float32),\n",
       " 'images': array([[[254.      , 254.      , 251.66667 , ...,  65.333336,\n",
       "           50.666668,  40.333332],\n",
       "         [253.33333 , 251.33333 , 247.33333 , ...,  66.666664,\n",
       "           52.      ,  42.666668],\n",
       "         [240.66667 , 231.66667 , 211.66667 , ...,  62.      ,\n",
       "           49.      ,  42.      ],\n",
       "         ...,\n",
       "         [ 74.333336,  54.      ,  31.666666, ...,  97.666664,\n",
       "           93.      ,  90.      ],\n",
       "         [ 65.333336,  47.      ,  30.333334, ...,  91.666664,\n",
       "           92.      ,  86.333336],\n",
       "         [ 59.333332,  44.333332,  32.333332, ...,  87.333336,\n",
       "           88.666664,  86.666664]],\n",
       " \n",
       "        [[ 39.666668,  50.333332,  47.      , ...,  61.333332,\n",
       "           51.      ,  38.666668],\n",
       "         [ 47.666668,  63.      ,  65.333336, ...,  57.666668,\n",
       "           55.      ,  44.666668],\n",
       "         [ 55.333332,  76.666664,  86.333336, ...,  71.      ,\n",
       "           48.333332,  43.666668],\n",
       "         ...,\n",
       "         [ 73.666664,  75.666664,  75.333336, ..., 125.666664,\n",
       "          119.666664, 115.333336],\n",
       "         [ 75.333336,  76.333336,  77.      , ..., 124.      ,\n",
       "          116.      , 116.333336],\n",
       "         [ 77.333336,  76.333336,  75.666664, ..., 117.666664,\n",
       "          115.      , 133.66667 ]],\n",
       " \n",
       "        [[ 89.333336, 104.      , 126.      , ..., 150.      ,\n",
       "          150.33333 , 149.      ],\n",
       "         [100.      , 128.      , 143.66667 , ..., 159.33333 ,\n",
       "          151.33333 , 147.33333 ],\n",
       "         [123.666664, 142.66667 , 146.66667 , ..., 161.      ,\n",
       "          152.66667 , 147.33333 ],\n",
       "         ...,\n",
       "         [ 75.666664,  73.666664,  74.      , ..., 123.      ,\n",
       "          168.66667 , 179.      ],\n",
       "         [ 73.      ,  68.666664,  69.333336, ..., 150.      ,\n",
       "          182.      , 181.33333 ],\n",
       "         [ 78.666664,  66.      ,  65.666664, ..., 175.33333 ,\n",
       "          183.33333 , 183.      ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 86.      ,  80.333336,  74.666664, ...,  35.      ,\n",
       "           35.      ,  39.333332],\n",
       "         [ 84.666664,  75.      ,  79.666664, ...,  37.      ,\n",
       "           35.      ,  37.      ],\n",
       "         [ 71.666664,  65.666664,  94.666664, ...,  41.333332,\n",
       "           37.      ,  36.666668],\n",
       "         ...,\n",
       "         [ 92.      ,  88.333336,  87.333336, ...,  66.666664,\n",
       "           79.333336,  94.      ],\n",
       "         [ 86.333336,  86.      ,  88.666664, ...,  46.666668,\n",
       "           58.666668,  64.333336],\n",
       "         [ 77.333336,  78.666664,  81.333336, ...,  44.      ,\n",
       "           49.666668,  44.666668]],\n",
       " \n",
       "        [[ 50.333332,  65.666664,  88.      , ..., 159.      ,\n",
       "          158.66667 , 152.      ],\n",
       "         [ 59.666668,  83.      ,  99.333336, ..., 157.66667 ,\n",
       "          150.66667 , 149.66667 ],\n",
       "         [ 62.      ,  90.666664,  94.333336, ..., 157.33333 ,\n",
       "          145.      , 144.      ],\n",
       "         ...,\n",
       "         [ 59.666668,  60.666668,  62.      , ..., 151.66667 ,\n",
       "          166.66667 , 164.66667 ],\n",
       "         [ 60.333332,  61.333332,  63.      , ..., 187.33333 ,\n",
       "          176.33333 , 167.      ],\n",
       "         [ 61.333332,  61.333332,  62.333332, ..., 197.      ,\n",
       "          179.33333 , 166.33333 ]],\n",
       " \n",
       "        [[ 30.      ,  27.      ,  32.666668, ...,  89.666664,\n",
       "           53.333332,  46.666668],\n",
       "         [ 31.333334,  32.      ,  37.333332, ..., 104.      ,\n",
       "           56.333332,  42.666668],\n",
       "         [ 33.666668,  33.666668,  39.      , ..., 122.666664,\n",
       "           71.333336,  52.      ],\n",
       "         ...,\n",
       "         [ 45.666668,  44.      ,  43.333332, ...,  23.333334,\n",
       "           20.      ,  34.333332],\n",
       "         [ 42.333332,  42.      ,  44.333332, ...,  24.333334,\n",
       "           27.      ,  44.      ],\n",
       "         [ 45.666668,  49.333332,  51.333332, ...,  35.      ,\n",
       "           35.333332,  61.      ]]], dtype=float32),\n",
       " 'target': array([5, 6, 3, ..., 5, 3, 5], dtype=int64),\n",
       " 'target_names': array(['Ariel Sharon', 'Colin Powell', 'Donald Rumsfeld', 'George W Bush',\n",
       "        'Gerhard Schroeder', 'Hugo Chavez', 'Tony Blair'], dtype='<U17'),\n",
       " 'DESCR': \".. _labeled_faces_in_the_wild_dataset:\\n\\nThe Labeled Faces in the Wild face recognition dataset\\n------------------------------------------------------\\n\\nThis dataset is a collection of JPEG pictures of famous people collected\\nover the internet, all details are available on the official website:\\n\\n    http://vis-www.cs.umass.edu/lfw/\\n\\nEach picture is centered on a single face. The typical task is called\\nFace Verification: given a pair of two pictures, a binary classifier\\nmust predict whether the two images are from the same person.\\n\\nAn alternative task, Face Recognition or Face Identification is:\\ngiven the picture of the face of an unknown person, identify the name\\nof the person by referring to a gallery of previously seen pictures of\\nidentified persons.\\n\\nBoth Face Verification and Face Recognition are tasks that are typically\\nperformed on the output of a model trained to perform Face Detection. The\\nmost popular model for Face Detection is called Viola-Jones and is\\nimplemented in the OpenCV library. The LFW faces were extracted by this\\nface detector from various online websites.\\n\\n**Data Set Characteristics:**\\n\\n    =================   =======================\\n    Classes                                5749\\n    Samples total                         13233\\n    Dimensionality                         5828\\n    Features            real, between 0 and 255\\n    =================   =======================\\n\\nUsage\\n~~~~~\\n\\n``scikit-learn`` provides two loaders that will automatically download,\\ncache, parse the metadata files, decode the jpeg and convert the\\ninteresting slices into memmapped numpy arrays. This dataset size is more\\nthan 200 MB. The first load typically takes more than a couple of minutes\\nto fully decode the relevant part of the JPEG files into numpy arrays. If\\nthe dataset has  been loaded once, the following times the loading times\\nless than 200ms by using a memmapped version memoized on the disk in the\\n``~/scikit_learn_data/lfw_home/`` folder using ``joblib``.\\n\\nThe first loader is used for the Face Identification task: a multi-class\\nclassification task (hence supervised learning)::\\n\\n  >>> from sklearn.datasets import fetch_lfw_people\\n  >>> lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\\n\\n  >>> for name in lfw_people.target_names:\\n  ...     print(name)\\n  ...\\n  Ariel Sharon\\n  Colin Powell\\n  Donald Rumsfeld\\n  George W Bush\\n  Gerhard Schroeder\\n  Hugo Chavez\\n  Tony Blair\\n\\nThe default slice is a rectangular shape around the face, removing\\nmost of the background::\\n\\n  >>> lfw_people.data.dtype\\n  dtype('float32')\\n\\n  >>> lfw_people.data.shape\\n  (1288, 1850)\\n\\n  >>> lfw_people.images.shape\\n  (1288, 50, 37)\\n\\nEach of the ``1140`` faces is assigned to a single person id in the ``target``\\narray::\\n\\n  >>> lfw_people.target.shape\\n  (1288,)\\n\\n  >>> list(lfw_people.target[:10])\\n  [5, 6, 3, 1, 0, 1, 3, 4, 3, 0]\\n\\nThe second loader is typically used for the face verification task: each sample\\nis a pair of two picture belonging or not to the same person::\\n\\n  >>> from sklearn.datasets import fetch_lfw_pairs\\n  >>> lfw_pairs_train = fetch_lfw_pairs(subset='train')\\n\\n  >>> list(lfw_pairs_train.target_names)\\n  ['Different persons', 'Same person']\\n\\n  >>> lfw_pairs_train.pairs.shape\\n  (2200, 2, 62, 47)\\n\\n  >>> lfw_pairs_train.data.shape\\n  (2200, 5828)\\n\\n  >>> lfw_pairs_train.target.shape\\n  (2200,)\\n\\nBoth for the :func:`sklearn.datasets.fetch_lfw_people` and\\n:func:`sklearn.datasets.fetch_lfw_pairs` function it is\\npossible to get an additional dimension with the RGB color channels by\\npassing ``color=True``, in that case the shape will be\\n``(2200, 2, 62, 47, 3)``.\\n\\nThe :func:`sklearn.datasets.fetch_lfw_pairs` datasets is subdivided into\\n3 subsets: the development ``train`` set, the development ``test`` set and\\nan evaluation ``10_folds`` set meant to compute performance metrics using a\\n10-folds cross validation scheme.\\n\\n.. topic:: References:\\n\\n * `Labeled Faces in the Wild: A Database for Studying Face Recognition\\n   in Unconstrained Environments.\\n   <http://vis-www.cs.umass.edu/lfw/lfw.pdf>`_\\n   Gary B. Huang, Manu Ramesh, Tamara Berg, and Erik Learned-Miller.\\n   University of Massachusetts, Amherst, Technical Report 07-49, October, 2007.\\n\\n\\nExamples\\n~~~~~~~~\\n\\n:ref:`sphx_glr_auto_examples_applications_plot_face_recognition.py`\\n\"}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_lfw_people, load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 5620\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n"
     ]
    }
   ],
   "source": [
    "print (digits.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.],\n",
       "       [ 0.,  0., 13., 15., 10., 15.,  5.,  0.],\n",
       "       [ 0.,  3., 15.,  2.,  0., 11.,  8.,  0.],\n",
       "       [ 0.,  4., 12.,  0.,  0.,  8.,  8.,  0.],\n",
       "       [ 0.,  5.,  8.,  0.,  0.,  9.,  8.,  0.],\n",
       "       [ 0.,  4., 11.,  0.,  1., 12.,  7.,  0.],\n",
       "       [ 0.,  2., 14.,  5., 10., 12.,  0.,  0.],\n",
       "       [ 0.,  0.,  6., 13., 10.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
